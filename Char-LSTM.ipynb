{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hdilab/hpm/blob/master/Char-LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rR0MzkS3ewoT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "Colab = False\n",
    "NumOnBits = 10\n",
    "NumBits = 512\n",
    "Seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "vawrva3tf9qd",
    "outputId": "0bdd8846-26f2-4302-9d6d-e9edef4b674b"
   },
   "outputs": [],
   "source": [
    "if Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    with open('/content/drive/My Drive/Colab/data/short.txt','r') as f:\n",
    "        text = f.read()\n",
    "else:\n",
    "    with open('data/1342.txt','r') as f:\n",
    "        text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ZMwUVQ4aewoe",
    "outputId": "f17718fb-04ad-4cb1-b2bd-df7acbe54fac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg EBook of Pride and Prejudice, by Jane Austen\\n\\nThis eBook is for the use of any'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "357wL-v5ewoj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 84, 104, 101,  32,  80, 114, 111, 106, 101,  99, 116,  32,  71,\n",
       "       117, 116, 101, 110,  98, 101, 114, 103,  32,  69,  66, 111, 111,\n",
       "       107,  32, 111, 102,  32,  80, 114, 105, 100, 101,  32,  97, 110,\n",
       "       100,  32,  80, 114, 101, 106, 117, 100, 105,  99, 101,  44,  32,\n",
       "        98, 121,  32,  74,  97, 110, 101,  32,  65, 117, 115, 116, 101,\n",
       "       110,  10,  10,  84, 104, 105, 115,  32, 101,  66, 111, 111, 107,\n",
       "        32, 105, 115,  32, 102, 111, 114,  32, 116, 104, 101,  32, 117,\n",
       "       115, 101,  32, 111, 102,  32,  97, 110, 121])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_chars = [chr(i) for i in range(128)]\n",
    "chars = tuple(asc_chars)\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {c:i for i, c in int2char.items()}\n",
    "\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SDR class\n",
    "Handles issues with SDR\n",
    "Given a char input, generate SDR\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class SDR(object):\n",
    "    \"\"\"\n",
    "      Class implementing the SDR.\n",
    "\n",
    "      :param input_list: (List) List for input_values.\n",
    "            For ASCII it will be [chr(0), chr(1), ... chr(127)]\n",
    "\n",
    "      :param numBits: (int) Number of bits for SDR. Default value ``512``\n",
    "\n",
    "      :param numOnBits: (int) Number of Active bits for SDR. Default value ``10``.\n",
    "            It is 2% sparcity for 512 bit\n",
    "\n",
    "      :param seed: (int) Seed for the random number generator. Default value ``42``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_list,\n",
    "                 numBits=512,\n",
    "                 numOnBits=10,\n",
    "                 seed=42,\n",
    "                 inputNoise=0.1):\n",
    "\n",
    "        random.seed(seed)\n",
    "        self.population = [i for i in range(numBits)]\n",
    "        self.numOnBits = numOnBits\n",
    "        self.inputNoise = inputNoise\n",
    "        self.sdr_dict = {i:random.sample(self.population, numOnBits) for i in input_list}\n",
    "\n",
    "\n",
    "    def getSDR(self, input):\n",
    "        return self.sdr_dict[input]\n",
    "\n",
    "\n",
    "    def getNoisySDR(self, input):\n",
    "        inputSDR = self.sdr_dict[input]\n",
    "        inputSDR = [i for i in inputSDR if random.random() > self.inputNoise]\n",
    "        noise = random.sample(self.population, int(self.numOnBits * self.inputNoise))\n",
    "        return inputSDR + noise\n",
    "\n",
    "\n",
    "\n",
    "    def getInput(self, sdr):\n",
    "        \"\"\"\n",
    "        Need to implement the function which returns the corresponding input from SDR\n",
    "        This requires a probabilistic approach. Count the number of overlapping bit and nonoverlapping field.\n",
    "        \"\"\"\n",
    "        return 0\n",
    "\n",
    "    def getCollisionProb(self, n, a, s, theta):\n",
    "        \"\"\"\n",
    "        Calculating the probability for the cases where more than theta synapses are activated\n",
    "        for different cell activation pattern\n",
    "        :param n: Number of cells\n",
    "        :param a: Number of active cells\n",
    "        :param s: Number of synapses\n",
    "        :param theta: Threshold for the dendritic activation\n",
    "        :return: The probability where dendritic activation for the different cell activation pattern\n",
    "        \"\"\"\n",
    "        numerator = 0\n",
    "        for b in range(theta, s+1):\n",
    "            numerator += combinatorial(s, b) * combinatorial(n-s, a-b)\n",
    "\n",
    "        denominator = combinatorial(n, a)\n",
    "\n",
    "        return numerator*1.0/denominator\n",
    "\n",
    "    def getRandomSDR(self):\n",
    "        noise = random.sample(self.population, numOnBits)\n",
    "        return noise\n",
    "\n",
    "\n",
    "def combinatorial(a,b):\n",
    "    return factorial(a)*1.0/factorial(a-b)/factorial(a)\n",
    "\n",
    "def factorial(a):\n",
    "    if a == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return a*factorial(a-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_sdr = SDR(asc_chars,\n",
    "                numBits=NumBits,\n",
    "                numOnBits=NumOnBits,\n",
    "                seed=Seed,\n",
    "                inputNoise=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDQ9Mcvjewon"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(arr, n_labels):\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1. \n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    return one_hot\n",
    "\n",
    "def multi_hot_encoder(arr, n_labels):\n",
    "    multi_hot = np.zeros((arr.shape[0], arr.shape[1], n_labels), dtype=np.float32)\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in range(arr.shape[1]):\n",
    "            sdr = char_sdr.getNoisySDR(int2char[arr[i][j]])\n",
    "            multi_hot[i][j][np.array(sdr)] = 1  \n",
    "    return multi_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFxKuXihewor"
   },
   "outputs": [],
   "source": [
    "test_seq = np.array([[3,5,1]])\n",
    "one_hot=one_hot_encoder(test_seq, 8)\n",
    "multi_hot = multi_hot_encoder(test_seq, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFxKuXihewor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print (test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CGG5XMZQewov",
    "outputId": "f82b60dc-a223-4dbc-d757-74749f69ae78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "B4yc-2i9ewoz",
    "outputId": "9c436133-58e5-4d23-df2e-a18ce7649484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 512)\n"
     ]
    }
   ],
   "source": [
    "print(multi_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8zmNspPrewo5",
    "outputId": "81be1056-104f-49a6-cbef-71e7c27f6340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 95, 223, 238, 27, 203, 429, 225, 459, 284, 44]\n",
      "[[ 27]\n",
      " [ 30]\n",
      " [ 38]\n",
      " [ 95]\n",
      " [203]\n",
      " [223]\n",
      " [225]\n",
      " [238]\n",
      " [284]\n",
      " [429]\n",
      " [459]]\n"
     ]
    }
   ],
   "source": [
    "sdr = char_sdr.getNoisySDR(int2char[1])\n",
    "a = np.zeros((3,512))\n",
    "a[1][np.array(sdr)] = 1\n",
    "print (sdr)\n",
    "print(np.argwhere(multi_hot[0,2]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EuoOhevSewo9"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "    \n",
    "    batch_size_total = batch_size * seq_length\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "    \n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        x = arr[:, n:n+seq_length]\n",
    "        y = np.zeros_like(x) \n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:,1:], arr[:, n+seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:,1:], arr[:,0] \n",
    "        yield x, y \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeUK4w9ZewpB"
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 8, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h42OA4H6ewpG",
    "outputId": "00fc1014-24ba-4e57-8abb-d0d19e0ea8ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjxsXcfTewpM"
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden=612, n_layers=4, drop_prob=0.5, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch:ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        self.lstm = nn.LSTM(NumBits, n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc = nn.Linear(n_hidden, NumBits)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        r_output, hidden = self.lstm(x,hidden)\n",
    "        \n",
    "        out = self.dropout(r_output)\n",
    "        \n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Flrh6R7-ewpR"
   },
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
    "    ''' Training a network \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        net: CharRNN network\n",
    "        data: text data to train the network\n",
    "        epochs: Number of epochs to train\n",
    "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
    "        seq_length: Number of character steps per mini-batch\n",
    "        lr: learning rate\n",
    "        clip: gradient clipping\n",
    "        val_frac: Fraction of data to hold out for validation\n",
    "        print_every: Number of steps for printing training and validation loss\n",
    "    \n",
    "    '''\n",
    "    net.train()\n",
    "    \n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # create training and validation data\n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = NumBits\n",
    "    for e in range(epochs):\n",
    "        # initialize hidden state\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        for x, y in get_batches(data, batch_size, seq_length):\n",
    "            counter += 1\n",
    "            \n",
    "            # One-hot encode our data and make them Torch tensors\n",
    "            x = multi_hot_encoder(x, n_chars)\n",
    "            y = multi_hot_encoder(y, n_chars)\n",
    "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "            \n",
    "            if(train_on_gpu):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # Creating new variables for the hidden state, otherwise\n",
    "            # we'd backprop through the entire training history\n",
    "            h = tuple([each.data for each in h])\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "            \n",
    "            # get the output from the model\n",
    "            output, h = net(inputs, h)\n",
    "            \n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output, targets.view(batch_size*seq_length, NumBits))\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "            \n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(batch_size)\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for x, y in get_batches(val_data, batch_size, seq_length):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = multi_hot_encoder(x, n_chars)\n",
    "                    y = multi_hot_encoder(y, n_chars)\n",
    "                    x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "                    \n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h = tuple([each.data for each in val_h])\n",
    "                    \n",
    "                    inputs, targets = x, y\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                    output, val_h = net(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(batch_size*seq_length, NumBits))\n",
    "                \n",
    "                    val_losses.append(val_loss.item())\n",
    "                \n",
    "                net.train() # reset to train mode after iterationg through validation data\n",
    "                \n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "AS5Ik3cvewpa",
    "outputId": "43630bc3-427f-46b9-f160-7ade6330efff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (lstm): LSTM(512, 1024, num_layers=4, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define and print the net\n",
    "n_hidden=1024\n",
    "n_layers=4\n",
    "\n",
    "net = CharRNN(chars, n_hidden, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HzJPMVdJewpe",
    "outputId": "135bf543-60fd-4e22-beb4-798a939d0b6a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000... Step: 10... Loss: 0.0878... Val Loss: 0.0872\n",
      "Epoch: 1/5000... Step: 20... Loss: 0.0864... Val Loss: 0.0851\n",
      "Epoch: 1/5000... Step: 30... Loss: 0.0850... Val Loss: 0.0832\n",
      "Epoch: 1/5000... Step: 40... Loss: 0.0833... Val Loss: 0.0819\n",
      "Epoch: 1/5000... Step: 50... Loss: 0.0822... Val Loss: 0.0805\n",
      "Epoch: 1/5000... Step: 60... Loss: 0.0813... Val Loss: 0.0796\n",
      "Epoch: 2/5000... Step: 70... Loss: 0.0806... Val Loss: 0.0791\n",
      "Epoch: 2/5000... Step: 80... Loss: 0.0801... Val Loss: 0.0789\n",
      "Epoch: 2/5000... Step: 90... Loss: 0.0803... Val Loss: 0.0789\n",
      "Epoch: 2/5000... Step: 100... Loss: 0.0801... Val Loss: 0.0789\n",
      "Epoch: 2/5000... Step: 110... Loss: 0.0801... Val Loss: 0.0789\n",
      "Epoch: 2/5000... Step: 120... Loss: 0.0799... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 130... Loss: 0.0799... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 140... Loss: 0.0794... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 150... Loss: 0.0797... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 160... Loss: 0.0797... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 170... Loss: 0.0796... Val Loss: 0.0788\n",
      "Epoch: 3/5000... Step: 180... Loss: 0.0793... Val Loss: 0.0788\n",
      "Epoch: 4/5000... Step: 190... Loss: 0.0793... Val Loss: 0.0788\n",
      "Epoch: 4/5000... Step: 200... Loss: 0.0790... Val Loss: 0.0787\n",
      "Epoch: 4/5000... Step: 210... Loss: 0.0792... Val Loss: 0.0787\n",
      "Epoch: 4/5000... Step: 220... Loss: 0.0792... Val Loss: 0.0788\n",
      "Epoch: 4/5000... Step: 230... Loss: 0.0792... Val Loss: 0.0787\n",
      "Epoch: 4/5000... Step: 240... Loss: 0.0791... Val Loss: 0.0788\n",
      "Epoch: 5/5000... Step: 250... Loss: 0.0790... Val Loss: 0.0787\n",
      "Epoch: 5/5000... Step: 260... Loss: 0.0792... Val Loss: 0.0787\n",
      "Epoch: 5/5000... Step: 270... Loss: 0.0791... Val Loss: 0.0787\n",
      "Epoch: 5/5000... Step: 280... Loss: 0.0792... Val Loss: 0.0787\n",
      "Epoch: 5/5000... Step: 290... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 5/5000... Step: 300... Loss: 0.0790... Val Loss: 0.0788\n",
      "Epoch: 6/5000... Step: 310... Loss: 0.0791... Val Loss: 0.0787\n",
      "Epoch: 6/5000... Step: 320... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 6/5000... Step: 330... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 6/5000... Step: 340... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 6/5000... Step: 350... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 6/5000... Step: 360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 370... Loss: 0.0791... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 380... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 390... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 400... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 410... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 7/5000... Step: 420... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 8/5000... Step: 430... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 8/5000... Step: 440... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 8/5000... Step: 450... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 8/5000... Step: 460... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 8/5000... Step: 470... Loss: 0.0787... Val Loss: 0.0788\n",
      "Epoch: 8/5000... Step: 480... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 9/5000... Step: 490... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 9/5000... Step: 500... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 9/5000... Step: 510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 9/5000... Step: 520... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 9/5000... Step: 530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 9/5000... Step: 540... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 10/5000... Step: 550... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 10/5000... Step: 560... Loss: 0.0790... Val Loss: 0.0786\n",
      "Epoch: 10/5000... Step: 570... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 10/5000... Step: 580... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 10/5000... Step: 590... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 10/5000... Step: 600... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 10/5000... Step: 610... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 11/5000... Step: 620... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 11/5000... Step: 630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 11/5000... Step: 640... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 11/5000... Step: 650... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 11/5000... Step: 660... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 11/5000... Step: 670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 12/5000... Step: 680... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 12/5000... Step: 690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 12/5000... Step: 700... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 12/5000... Step: 710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 12/5000... Step: 720... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 12/5000... Step: 730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 13/5000... Step: 740... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 13/5000... Step: 750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 13/5000... Step: 760... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 13/5000... Step: 770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 13/5000... Step: 780... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 13/5000... Step: 790... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 14/5000... Step: 800... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 14/5000... Step: 810... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 14/5000... Step: 820... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 14/5000... Step: 830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 14/5000... Step: 840... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 14/5000... Step: 850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 860... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 880... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 890... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 900... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 15/5000... Step: 910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 16/5000... Step: 920... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 16/5000... Step: 930... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 16/5000... Step: 940... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 16/5000... Step: 950... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 16/5000... Step: 960... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 16/5000... Step: 970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 17/5000... Step: 980... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 17/5000... Step: 990... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 17/5000... Step: 1000... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 17/5000... Step: 1010... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 17/5000... Step: 1020... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 17/5000... Step: 1030... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 18/5000... Step: 1040... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 18/5000... Step: 1050... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 18/5000... Step: 1060... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 18/5000... Step: 1070... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 22/5000... Step: 1340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 23/5000... Step: 1350... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 23/5000... Step: 1360... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 23/5000... Step: 1370... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 23/5000... Step: 1380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 23/5000... Step: 1390... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 23/5000... Step: 1400... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 24/5000... Step: 1410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 24/5000... Step: 1420... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 24/5000... Step: 1430... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 24/5000... Step: 1440... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 24/5000... Step: 1450... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 24/5000... Step: 1460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 25/5000... Step: 1470... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 25/5000... Step: 1480... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 25/5000... Step: 1490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 25/5000... Step: 1500... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 25/5000... Step: 1510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 25/5000... Step: 1520... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 26/5000... Step: 1530... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 26/5000... Step: 1540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 26/5000... Step: 1550... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/5000... Step: 1560... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 26/5000... Step: 1570... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 26/5000... Step: 1580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 27/5000... Step: 1590... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 27/5000... Step: 1600... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 27/5000... Step: 1610... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 27/5000... Step: 1620... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 27/5000... Step: 1630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 27/5000... Step: 1640... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 28/5000... Step: 1650... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 28/5000... Step: 1660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 28/5000... Step: 1670... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 28/5000... Step: 1680... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 28/5000... Step: 1690... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 28/5000... Step: 1700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 29/5000... Step: 1710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 29/5000... Step: 1720... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 29/5000... Step: 1730... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 29/5000... Step: 1740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 29/5000... Step: 1750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 29/5000... Step: 1760... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 30/5000... Step: 1770... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 30/5000... Step: 1780... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 30/5000... Step: 1790... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 30/5000... Step: 1800... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 30/5000... Step: 1810... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 30/5000... Step: 1820... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 30/5000... Step: 1830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1860... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1870... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1880... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 31/5000... Step: 1890... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 32/5000... Step: 1900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 32/5000... Step: 1910... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 32/5000... Step: 1920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 32/5000... Step: 1930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 32/5000... Step: 1940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 32/5000... Step: 1950... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 33/5000... Step: 1960... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 33/5000... Step: 1970... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 33/5000... Step: 1980... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 33/5000... Step: 1990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 33/5000... Step: 2000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 33/5000... Step: 2010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 34/5000... Step: 2020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 34/5000... Step: 2030... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 34/5000... Step: 2040... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 34/5000... Step: 2050... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 34/5000... Step: 2060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 34/5000... Step: 2070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 35/5000... Step: 2080... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 35/5000... Step: 2090... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 35/5000... Step: 2100... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 35/5000... Step: 2110... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 35/5000... Step: 2120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 35/5000... Step: 2130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 36/5000... Step: 2140... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 36/5000... Step: 2150... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 36/5000... Step: 2160... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 36/5000... Step: 2170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 36/5000... Step: 2180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 36/5000... Step: 2190... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 37/5000... Step: 2200... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 37/5000... Step: 2210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 37/5000... Step: 2220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 37/5000... Step: 2230... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 37/5000... Step: 2240... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 37/5000... Step: 2250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 38/5000... Step: 2260... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 38/5000... Step: 2270... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 38/5000... Step: 2280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 38/5000... Step: 2290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 38/5000... Step: 2300... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 38/5000... Step: 2310... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 39/5000... Step: 2320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 39/5000... Step: 2330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 39/5000... Step: 2340... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 39/5000... Step: 2350... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 39/5000... Step: 2360... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 39/5000... Step: 2370... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2380... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2390... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2410... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2420... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 40/5000... Step: 2430... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 40/5000... Step: 2440... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 41/5000... Step: 2450... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 41/5000... Step: 2460... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 41/5000... Step: 2470... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 41/5000... Step: 2480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 41/5000... Step: 2490... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 41/5000... Step: 2500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 42/5000... Step: 2510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 42/5000... Step: 2520... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 42/5000... Step: 2530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 42/5000... Step: 2540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 42/5000... Step: 2550... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 42/5000... Step: 2560... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 43/5000... Step: 2570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 43/5000... Step: 2580... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 43/5000... Step: 2590... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 43/5000... Step: 2600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 43/5000... Step: 2610... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 43/5000... Step: 2620... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 44/5000... Step: 2630... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 44/5000... Step: 2640... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 44/5000... Step: 2650... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 44/5000... Step: 2660... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 44/5000... Step: 2670... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 44/5000... Step: 2680... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 45/5000... Step: 2690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 45/5000... Step: 2700... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 45/5000... Step: 2710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 45/5000... Step: 2720... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 45/5000... Step: 2730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 45/5000... Step: 2740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 46/5000... Step: 2750... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 46/5000... Step: 2760... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 46/5000... Step: 2770... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 46/5000... Step: 2780... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 46/5000... Step: 2790... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 46/5000... Step: 2800... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 47/5000... Step: 2810... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 47/5000... Step: 2820... Loss: 0.0783... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/5000... Step: 2830... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 47/5000... Step: 2840... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 47/5000... Step: 2850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 47/5000... Step: 2860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 48/5000... Step: 2870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 48/5000... Step: 2880... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 48/5000... Step: 2890... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 48/5000... Step: 2900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 48/5000... Step: 2910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 48/5000... Step: 2920... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 49/5000... Step: 2930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 49/5000... Step: 2940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 49/5000... Step: 2950... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 49/5000... Step: 2960... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 49/5000... Step: 2970... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 49/5000... Step: 2980... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 50/5000... Step: 2990... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 50/5000... Step: 3000... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 50/5000... Step: 3010... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 50/5000... Step: 3020... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 50/5000... Step: 3030... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 50/5000... Step: 3040... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 50/5000... Step: 3050... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 51/5000... Step: 3060... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 51/5000... Step: 3070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 51/5000... Step: 3080... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 51/5000... Step: 3090... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 51/5000... Step: 3100... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 51/5000... Step: 3110... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 52/5000... Step: 3120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 52/5000... Step: 3130... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 52/5000... Step: 3140... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 52/5000... Step: 3150... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 52/5000... Step: 3160... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 52/5000... Step: 3170... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 53/5000... Step: 3180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 53/5000... Step: 3190... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 53/5000... Step: 3200... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 53/5000... Step: 3210... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 53/5000... Step: 3220... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 53/5000... Step: 3230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 54/5000... Step: 3240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 54/5000... Step: 3250... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 54/5000... Step: 3260... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 54/5000... Step: 3270... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 54/5000... Step: 3280... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 54/5000... Step: 3290... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 55/5000... Step: 3300... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 55/5000... Step: 3310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 55/5000... Step: 3320... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 55/5000... Step: 3330... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 55/5000... Step: 3340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 55/5000... Step: 3350... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3360... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3370... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3380... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3390... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3400... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 56/5000... Step: 3410... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 57/5000... Step: 3420... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 57/5000... Step: 3430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 57/5000... Step: 3440... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 57/5000... Step: 3450... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 57/5000... Step: 3460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 57/5000... Step: 3470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 58/5000... Step: 3480... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 58/5000... Step: 3490... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 58/5000... Step: 3500... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 58/5000... Step: 3510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 58/5000... Step: 3520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 58/5000... Step: 3530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 59/5000... Step: 3540... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 59/5000... Step: 3550... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 59/5000... Step: 3560... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 59/5000... Step: 3570... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 59/5000... Step: 3580... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 59/5000... Step: 3590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 60/5000... Step: 3600... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 60/5000... Step: 3610... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 60/5000... Step: 3620... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 60/5000... Step: 3630... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 60/5000... Step: 3640... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 60/5000... Step: 3650... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 60/5000... Step: 3660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3670... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3680... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3690... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3700... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3710... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 61/5000... Step: 3720... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 62/5000... Step: 3730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 62/5000... Step: 3740... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 62/5000... Step: 3750... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 62/5000... Step: 3760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 62/5000... Step: 3770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 62/5000... Step: 3780... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 63/5000... Step: 3790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 63/5000... Step: 3800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 63/5000... Step: 3810... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 63/5000... Step: 3820... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 63/5000... Step: 3830... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 63/5000... Step: 3840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 64/5000... Step: 3850... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 64/5000... Step: 3860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 64/5000... Step: 3870... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 64/5000... Step: 3880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 64/5000... Step: 3890... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 64/5000... Step: 3900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 65/5000... Step: 3910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 65/5000... Step: 3920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 65/5000... Step: 3930... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 65/5000... Step: 3940... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 65/5000... Step: 3950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 65/5000... Step: 3960... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 66/5000... Step: 3970... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 66/5000... Step: 3980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 66/5000... Step: 3990... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 66/5000... Step: 4000... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 66/5000... Step: 4010... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 66/5000... Step: 4020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 67/5000... Step: 4030... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 67/5000... Step: 4040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 67/5000... Step: 4050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 67/5000... Step: 4060... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 67/5000... Step: 4070... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 67/5000... Step: 4080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 68/5000... Step: 4090... Loss: 0.0786... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/5000... Step: 4100... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 68/5000... Step: 4110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 68/5000... Step: 4120... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 68/5000... Step: 4130... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 68/5000... Step: 4140... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 69/5000... Step: 4150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 69/5000... Step: 4160... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 69/5000... Step: 4170... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 69/5000... Step: 4180... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 69/5000... Step: 4190... Loss: 0.0783... Val Loss: 0.0788\n",
      "Epoch: 69/5000... Step: 4200... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 70/5000... Step: 4210... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 70/5000... Step: 4220... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 70/5000... Step: 4230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 70/5000... Step: 4240... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 70/5000... Step: 4250... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 70/5000... Step: 4260... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 70/5000... Step: 4270... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 71/5000... Step: 4280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 71/5000... Step: 4290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 71/5000... Step: 4300... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 71/5000... Step: 4310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 71/5000... Step: 4320... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 71/5000... Step: 4330... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 72/5000... Step: 4340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 72/5000... Step: 4350... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 72/5000... Step: 4360... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 72/5000... Step: 4370... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 72/5000... Step: 4380... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 72/5000... Step: 4390... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 73/5000... Step: 4400... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 73/5000... Step: 4410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 73/5000... Step: 4420... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 73/5000... Step: 4430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 73/5000... Step: 4440... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 73/5000... Step: 4450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 74/5000... Step: 4460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 74/5000... Step: 4470... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 74/5000... Step: 4480... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 74/5000... Step: 4490... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 74/5000... Step: 4500... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 74/5000... Step: 4510... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 75/5000... Step: 4520... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 75/5000... Step: 4530... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 75/5000... Step: 4540... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 75/5000... Step: 4550... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 75/5000... Step: 4560... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 75/5000... Step: 4570... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 76/5000... Step: 4580... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 76/5000... Step: 4590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 76/5000... Step: 4600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 76/5000... Step: 4610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 76/5000... Step: 4620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 76/5000... Step: 4630... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 77/5000... Step: 4640... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 77/5000... Step: 4650... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 77/5000... Step: 4660... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 77/5000... Step: 4670... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 77/5000... Step: 4680... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 77/5000... Step: 4690... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 78/5000... Step: 4700... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 78/5000... Step: 4710... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 78/5000... Step: 4720... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 78/5000... Step: 4730... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 78/5000... Step: 4740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 78/5000... Step: 4750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 79/5000... Step: 4760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 79/5000... Step: 4770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 79/5000... Step: 4780... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 79/5000... Step: 4790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 79/5000... Step: 4800... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 79/5000... Step: 4810... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 80/5000... Step: 4820... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 80/5000... Step: 4830... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 80/5000... Step: 4840... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 80/5000... Step: 4850... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 80/5000... Step: 4860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 80/5000... Step: 4870... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 80/5000... Step: 4880... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 81/5000... Step: 4890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 81/5000... Step: 4900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 81/5000... Step: 4910... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 81/5000... Step: 4920... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 81/5000... Step: 4930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 81/5000... Step: 4940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 82/5000... Step: 4950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 82/5000... Step: 4960... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 82/5000... Step: 4970... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 82/5000... Step: 4980... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 82/5000... Step: 4990... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 82/5000... Step: 5000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 83/5000... Step: 5010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 83/5000... Step: 5020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 83/5000... Step: 5030... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 83/5000... Step: 5040... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 83/5000... Step: 5050... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 83/5000... Step: 5060... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 84/5000... Step: 5070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 84/5000... Step: 5080... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 84/5000... Step: 5090... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 84/5000... Step: 5100... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 84/5000... Step: 5110... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 84/5000... Step: 5120... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 85/5000... Step: 5130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 85/5000... Step: 5140... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 85/5000... Step: 5150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 85/5000... Step: 5160... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 85/5000... Step: 5170... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 85/5000... Step: 5180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 86/5000... Step: 5190... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 86/5000... Step: 5200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 86/5000... Step: 5210... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 86/5000... Step: 5220... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 86/5000... Step: 5230... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 86/5000... Step: 5240... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 87/5000... Step: 5250... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 87/5000... Step: 5260... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 87/5000... Step: 5270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 87/5000... Step: 5280... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 87/5000... Step: 5290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 87/5000... Step: 5300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 88/5000... Step: 5310... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 88/5000... Step: 5320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 88/5000... Step: 5330... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 88/5000... Step: 5340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 88/5000... Step: 5350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 88/5000... Step: 5360... Loss: 0.0786... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/5000... Step: 5370... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 89/5000... Step: 5380... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 89/5000... Step: 5390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 89/5000... Step: 5400... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 89/5000... Step: 5410... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 89/5000... Step: 5420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 90/5000... Step: 5430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 90/5000... Step: 5440... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 90/5000... Step: 5450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 90/5000... Step: 5460... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 90/5000... Step: 5470... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 90/5000... Step: 5480... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 90/5000... Step: 5490... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 91/5000... Step: 5500... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 91/5000... Step: 5510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 91/5000... Step: 5520... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 91/5000... Step: 5530... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 91/5000... Step: 5540... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 91/5000... Step: 5550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 92/5000... Step: 5560... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 92/5000... Step: 5570... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 92/5000... Step: 5580... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 92/5000... Step: 5590... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 92/5000... Step: 5600... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 92/5000... Step: 5610... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 93/5000... Step: 5620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 93/5000... Step: 5630... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 93/5000... Step: 5640... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 93/5000... Step: 5650... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 93/5000... Step: 5660... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 93/5000... Step: 5670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 94/5000... Step: 5680... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 94/5000... Step: 5690... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 94/5000... Step: 5700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 94/5000... Step: 5710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 94/5000... Step: 5720... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 94/5000... Step: 5730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 95/5000... Step: 5740... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 95/5000... Step: 5750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 95/5000... Step: 5760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 95/5000... Step: 5770... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 95/5000... Step: 5780... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 95/5000... Step: 5790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 96/5000... Step: 5800... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 96/5000... Step: 5810... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 96/5000... Step: 5820... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 96/5000... Step: 5830... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 96/5000... Step: 5840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 96/5000... Step: 5850... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 97/5000... Step: 5860... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 97/5000... Step: 5870... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 97/5000... Step: 5880... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 97/5000... Step: 5890... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 97/5000... Step: 5900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 97/5000... Step: 5910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 98/5000... Step: 5920... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 98/5000... Step: 5930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 98/5000... Step: 5940... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 98/5000... Step: 5950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 98/5000... Step: 5960... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 98/5000... Step: 5970... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 99/5000... Step: 5980... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 99/5000... Step: 5990... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 99/5000... Step: 6000... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 99/5000... Step: 6010... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 99/5000... Step: 6020... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 99/5000... Step: 6030... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 100/5000... Step: 6040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 100/5000... Step: 6050... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 100/5000... Step: 6060... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 100/5000... Step: 6070... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 100/5000... Step: 6080... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 100/5000... Step: 6090... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 100/5000... Step: 6100... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 101/5000... Step: 6110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 101/5000... Step: 6120... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 101/5000... Step: 6130... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 101/5000... Step: 6140... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 101/5000... Step: 6150... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 101/5000... Step: 6160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 102/5000... Step: 6170... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 102/5000... Step: 6180... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 102/5000... Step: 6190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 102/5000... Step: 6200... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 102/5000... Step: 6210... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 102/5000... Step: 6220... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 103/5000... Step: 6230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 103/5000... Step: 6240... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 103/5000... Step: 6250... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 103/5000... Step: 6260... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 103/5000... Step: 6270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 103/5000... Step: 6280... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 104/5000... Step: 6290... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 104/5000... Step: 6300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 104/5000... Step: 6310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 104/5000... Step: 6320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 104/5000... Step: 6330... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 104/5000... Step: 6340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 105/5000... Step: 6350... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 105/5000... Step: 6360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 105/5000... Step: 6370... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 105/5000... Step: 6380... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 105/5000... Step: 6390... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 105/5000... Step: 6400... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 106/5000... Step: 6410... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 106/5000... Step: 6420... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 106/5000... Step: 6430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 106/5000... Step: 6440... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 106/5000... Step: 6450... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 106/5000... Step: 6460... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 107/5000... Step: 6470... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 107/5000... Step: 6480... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 107/5000... Step: 6490... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 107/5000... Step: 6500... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 107/5000... Step: 6510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 107/5000... Step: 6520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 108/5000... Step: 6530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 108/5000... Step: 6540... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 108/5000... Step: 6550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 108/5000... Step: 6560... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 108/5000... Step: 6570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 108/5000... Step: 6580... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 109/5000... Step: 6590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 109/5000... Step: 6600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 109/5000... Step: 6610... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 109/5000... Step: 6620... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/5000... Step: 6630... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 109/5000... Step: 6640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6650... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6660... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6680... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6690... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 110/5000... Step: 6700... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 110/5000... Step: 6710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 111/5000... Step: 6720... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 111/5000... Step: 6730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 111/5000... Step: 6740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 111/5000... Step: 6750... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 111/5000... Step: 6760... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 111/5000... Step: 6770... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 112/5000... Step: 6780... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 112/5000... Step: 6790... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 112/5000... Step: 6800... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 112/5000... Step: 6810... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 112/5000... Step: 6820... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 112/5000... Step: 6830... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 113/5000... Step: 6840... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 113/5000... Step: 6850... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 113/5000... Step: 6860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 113/5000... Step: 6870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 113/5000... Step: 6880... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 113/5000... Step: 6890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 114/5000... Step: 6900... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 114/5000... Step: 6910... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 114/5000... Step: 6920... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 114/5000... Step: 6930... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 114/5000... Step: 6940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 114/5000... Step: 6950... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 115/5000... Step: 6960... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 115/5000... Step: 6970... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 115/5000... Step: 6980... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 115/5000... Step: 6990... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 115/5000... Step: 7000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 115/5000... Step: 7010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 116/5000... Step: 7020... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 116/5000... Step: 7030... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 116/5000... Step: 7040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 116/5000... Step: 7050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 116/5000... Step: 7060... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 116/5000... Step: 7070... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 117/5000... Step: 7080... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 117/5000... Step: 7090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 117/5000... Step: 7100... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 117/5000... Step: 7110... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 117/5000... Step: 7120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 117/5000... Step: 7130... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 118/5000... Step: 7140... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 118/5000... Step: 7150... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 118/5000... Step: 7160... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 118/5000... Step: 7170... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 118/5000... Step: 7180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 118/5000... Step: 7190... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 119/5000... Step: 7200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 119/5000... Step: 7210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 119/5000... Step: 7220... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 119/5000... Step: 7230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 119/5000... Step: 7240... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 119/5000... Step: 7250... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 120/5000... Step: 7260... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 120/5000... Step: 7270... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 120/5000... Step: 7280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 120/5000... Step: 7290... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 120/5000... Step: 7300... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 120/5000... Step: 7310... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 120/5000... Step: 7320... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 121/5000... Step: 7330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 121/5000... Step: 7340... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 121/5000... Step: 7350... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 121/5000... Step: 7360... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 121/5000... Step: 7370... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 121/5000... Step: 7380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 122/5000... Step: 7390... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 122/5000... Step: 7400... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 122/5000... Step: 7410... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 122/5000... Step: 7420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 122/5000... Step: 7430... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 122/5000... Step: 7440... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 123/5000... Step: 7450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 123/5000... Step: 7460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 123/5000... Step: 7470... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 123/5000... Step: 7480... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 123/5000... Step: 7490... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 123/5000... Step: 7500... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 124/5000... Step: 7510... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 124/5000... Step: 7520... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 124/5000... Step: 7530... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 124/5000... Step: 7540... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 124/5000... Step: 7550... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 124/5000... Step: 7560... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 125/5000... Step: 7570... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 125/5000... Step: 7580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 125/5000... Step: 7590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 125/5000... Step: 7600... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 125/5000... Step: 7610... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 125/5000... Step: 7620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7630... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7650... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7660... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7670... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 126/5000... Step: 7680... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 127/5000... Step: 7690... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 127/5000... Step: 7700... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 127/5000... Step: 7710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 127/5000... Step: 7720... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 127/5000... Step: 7730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 127/5000... Step: 7740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 128/5000... Step: 7750... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 128/5000... Step: 7760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 128/5000... Step: 7770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 128/5000... Step: 7780... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 128/5000... Step: 7790... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 128/5000... Step: 7800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 129/5000... Step: 7810... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 129/5000... Step: 7820... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 129/5000... Step: 7830... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 129/5000... Step: 7840... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 129/5000... Step: 7850... Loss: 0.0783... Val Loss: 0.0788\n",
      "Epoch: 129/5000... Step: 7860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 130/5000... Step: 7870... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130/5000... Step: 7880... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 130/5000... Step: 7890... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 130/5000... Step: 7900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 130/5000... Step: 7910... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 130/5000... Step: 7920... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 130/5000... Step: 7930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 131/5000... Step: 7940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 131/5000... Step: 7950... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 131/5000... Step: 7960... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 131/5000... Step: 7970... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 131/5000... Step: 7980... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 131/5000... Step: 7990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 132/5000... Step: 8000... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 132/5000... Step: 8010... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 132/5000... Step: 8020... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 132/5000... Step: 8030... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 132/5000... Step: 8040... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 132/5000... Step: 8050... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 133/5000... Step: 8060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 133/5000... Step: 8070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 133/5000... Step: 8080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 133/5000... Step: 8090... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 133/5000... Step: 8100... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 133/5000... Step: 8110... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 134/5000... Step: 8120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 134/5000... Step: 8130... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 134/5000... Step: 8140... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 134/5000... Step: 8150... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 134/5000... Step: 8160... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 134/5000... Step: 8170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 135/5000... Step: 8180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 135/5000... Step: 8190... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 135/5000... Step: 8200... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 135/5000... Step: 8210... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 135/5000... Step: 8220... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 135/5000... Step: 8230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 136/5000... Step: 8240... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 136/5000... Step: 8250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 136/5000... Step: 8260... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 136/5000... Step: 8270... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 136/5000... Step: 8280... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 136/5000... Step: 8290... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8300... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8320... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8330... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 137/5000... Step: 8350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 138/5000... Step: 8360... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 138/5000... Step: 8370... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 138/5000... Step: 8380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 138/5000... Step: 8390... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 138/5000... Step: 8400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 138/5000... Step: 8410... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 139/5000... Step: 8420... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 139/5000... Step: 8430... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 139/5000... Step: 8440... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 139/5000... Step: 8450... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 139/5000... Step: 8460... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 139/5000... Step: 8470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8480... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8490... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8510... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8520... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 140/5000... Step: 8530... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 140/5000... Step: 8540... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 141/5000... Step: 8550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 141/5000... Step: 8560... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 141/5000... Step: 8570... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 141/5000... Step: 8580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 141/5000... Step: 8590... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 141/5000... Step: 8600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 142/5000... Step: 8610... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 142/5000... Step: 8620... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 142/5000... Step: 8630... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 142/5000... Step: 8640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 142/5000... Step: 8650... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 142/5000... Step: 8660... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 143/5000... Step: 8670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 143/5000... Step: 8680... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 143/5000... Step: 8690... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 143/5000... Step: 8700... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 143/5000... Step: 8710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 143/5000... Step: 8720... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 144/5000... Step: 8730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 144/5000... Step: 8740... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 144/5000... Step: 8750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 144/5000... Step: 8760... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 144/5000... Step: 8770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 144/5000... Step: 8780... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 145/5000... Step: 8790... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 145/5000... Step: 8800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 145/5000... Step: 8810... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 145/5000... Step: 8820... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 145/5000... Step: 8830... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 145/5000... Step: 8840... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 146/5000... Step: 8850... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 146/5000... Step: 8860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 146/5000... Step: 8870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 146/5000... Step: 8880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 146/5000... Step: 8890... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 146/5000... Step: 8900... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 147/5000... Step: 8910... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 147/5000... Step: 8920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 147/5000... Step: 8930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 147/5000... Step: 8940... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 147/5000... Step: 8950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 147/5000... Step: 8960... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 148/5000... Step: 8970... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 148/5000... Step: 8980... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 148/5000... Step: 8990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 148/5000... Step: 9000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 148/5000... Step: 9010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 148/5000... Step: 9020... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 149/5000... Step: 9030... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 149/5000... Step: 9040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 149/5000... Step: 9050... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 149/5000... Step: 9060... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 149/5000... Step: 9070... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 149/5000... Step: 9080... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 150/5000... Step: 9090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 150/5000... Step: 9100... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 150/5000... Step: 9110... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 150/5000... Step: 9120... Loss: 0.0783... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/5000... Step: 9130... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 150/5000... Step: 9140... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 150/5000... Step: 9150... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 151/5000... Step: 9160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 151/5000... Step: 9170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 151/5000... Step: 9180... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 151/5000... Step: 9190... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 151/5000... Step: 9200... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 151/5000... Step: 9210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 152/5000... Step: 9220... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 152/5000... Step: 9230... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 152/5000... Step: 9240... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 152/5000... Step: 9250... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 152/5000... Step: 9260... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 152/5000... Step: 9270... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 153/5000... Step: 9280... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 153/5000... Step: 9290... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 153/5000... Step: 9300... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 153/5000... Step: 9310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 153/5000... Step: 9320... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 153/5000... Step: 9330... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 154/5000... Step: 9340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 154/5000... Step: 9350... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 154/5000... Step: 9360... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 154/5000... Step: 9370... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 154/5000... Step: 9380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 154/5000... Step: 9390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 155/5000... Step: 9400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 155/5000... Step: 9410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 155/5000... Step: 9420... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 155/5000... Step: 9430... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 155/5000... Step: 9440... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 155/5000... Step: 9450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9460... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9490... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9500... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 156/5000... Step: 9510... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 157/5000... Step: 9520... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 157/5000... Step: 9530... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 157/5000... Step: 9540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 157/5000... Step: 9550... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 157/5000... Step: 9560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 157/5000... Step: 9570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 158/5000... Step: 9580... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 158/5000... Step: 9590... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 158/5000... Step: 9600... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 158/5000... Step: 9610... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 158/5000... Step: 9620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 158/5000... Step: 9630... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 159/5000... Step: 9640... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 159/5000... Step: 9650... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 159/5000... Step: 9660... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 159/5000... Step: 9670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 159/5000... Step: 9680... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 159/5000... Step: 9690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 160/5000... Step: 9700... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9710... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9720... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9740... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 160/5000... Step: 9760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 161/5000... Step: 9770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 161/5000... Step: 9780... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 161/5000... Step: 9790... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 161/5000... Step: 9800... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 161/5000... Step: 9810... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 161/5000... Step: 9820... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 162/5000... Step: 9830... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 162/5000... Step: 9840... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 162/5000... Step: 9850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 162/5000... Step: 9860... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 162/5000... Step: 9870... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 162/5000... Step: 9880... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 163/5000... Step: 9890... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 163/5000... Step: 9900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 163/5000... Step: 9910... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 163/5000... Step: 9920... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 163/5000... Step: 9930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 163/5000... Step: 9940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 164/5000... Step: 9950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 164/5000... Step: 9960... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 164/5000... Step: 9970... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 164/5000... Step: 9980... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 164/5000... Step: 9990... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 164/5000... Step: 10000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 165/5000... Step: 10010... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 165/5000... Step: 10020... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 165/5000... Step: 10030... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 165/5000... Step: 10040... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 165/5000... Step: 10050... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 165/5000... Step: 10060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 166/5000... Step: 10070... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 166/5000... Step: 10080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 166/5000... Step: 10090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 166/5000... Step: 10100... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 166/5000... Step: 10110... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 166/5000... Step: 10120... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 167/5000... Step: 10130... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 167/5000... Step: 10140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 167/5000... Step: 10150... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 167/5000... Step: 10160... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 167/5000... Step: 10170... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 167/5000... Step: 10180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10190... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 168/5000... Step: 10240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 169/5000... Step: 10250... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 169/5000... Step: 10260... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 169/5000... Step: 10270... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 169/5000... Step: 10280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 169/5000... Step: 10290... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 169/5000... Step: 10300... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 170/5000... Step: 10310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 170/5000... Step: 10320... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 170/5000... Step: 10330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 170/5000... Step: 10340... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 170/5000... Step: 10350... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 170/5000... Step: 10360... Loss: 0.0788... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170/5000... Step: 10370... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 171/5000... Step: 10380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 171/5000... Step: 10390... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 171/5000... Step: 10400... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 171/5000... Step: 10410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 171/5000... Step: 10420... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 171/5000... Step: 10430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10440... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10450... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10460... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 172/5000... Step: 10490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 173/5000... Step: 10500... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 173/5000... Step: 10510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 173/5000... Step: 10520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 173/5000... Step: 10530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 173/5000... Step: 10540... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 173/5000... Step: 10550... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 174/5000... Step: 10560... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 174/5000... Step: 10570... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 174/5000... Step: 10580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 174/5000... Step: 10590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 174/5000... Step: 10600... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 174/5000... Step: 10610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 175/5000... Step: 10620... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 175/5000... Step: 10630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 175/5000... Step: 10640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 175/5000... Step: 10650... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 175/5000... Step: 10660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 175/5000... Step: 10670... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 176/5000... Step: 10680... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 176/5000... Step: 10690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 176/5000... Step: 10700... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 176/5000... Step: 10710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 176/5000... Step: 10720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 176/5000... Step: 10730... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 177/5000... Step: 10740... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 177/5000... Step: 10750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 177/5000... Step: 10760... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 177/5000... Step: 10770... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 177/5000... Step: 10780... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 177/5000... Step: 10790... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 178/5000... Step: 10800... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 178/5000... Step: 10810... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 178/5000... Step: 10820... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 178/5000... Step: 10830... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 178/5000... Step: 10840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 178/5000... Step: 10850... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 179/5000... Step: 10860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 179/5000... Step: 10870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 179/5000... Step: 10880... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 179/5000... Step: 10890... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 179/5000... Step: 10900... Loss: 0.0783... Val Loss: 0.0788\n",
      "Epoch: 179/5000... Step: 10910... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 180/5000... Step: 10920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 180/5000... Step: 10930... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 180/5000... Step: 10940... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 180/5000... Step: 10950... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 180/5000... Step: 10960... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 180/5000... Step: 10970... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 180/5000... Step: 10980... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 181/5000... Step: 10990... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 181/5000... Step: 11000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 181/5000... Step: 11010... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 181/5000... Step: 11020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 181/5000... Step: 11030... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 181/5000... Step: 11040... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 182/5000... Step: 11050... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 182/5000... Step: 11060... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 182/5000... Step: 11070... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 182/5000... Step: 11080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 182/5000... Step: 11090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 182/5000... Step: 11100... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 183/5000... Step: 11110... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 183/5000... Step: 11120... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 183/5000... Step: 11130... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 183/5000... Step: 11140... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 183/5000... Step: 11150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 183/5000... Step: 11160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 184/5000... Step: 11170... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 184/5000... Step: 11180... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 184/5000... Step: 11190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 184/5000... Step: 11200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 184/5000... Step: 11210... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 184/5000... Step: 11220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 185/5000... Step: 11230... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 185/5000... Step: 11240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 185/5000... Step: 11250... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 185/5000... Step: 11260... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 185/5000... Step: 11270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 185/5000... Step: 11280... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11290... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11320... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11330... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 186/5000... Step: 11340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 187/5000... Step: 11350... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 187/5000... Step: 11360... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 187/5000... Step: 11370... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 187/5000... Step: 11380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 187/5000... Step: 11390... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 187/5000... Step: 11400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 188/5000... Step: 11410... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 188/5000... Step: 11420... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 188/5000... Step: 11430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 188/5000... Step: 11440... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 188/5000... Step: 11450... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 188/5000... Step: 11460... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 189/5000... Step: 11470... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 189/5000... Step: 11480... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 189/5000... Step: 11490... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 189/5000... Step: 11500... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 189/5000... Step: 11510... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 189/5000... Step: 11520... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11540... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11560... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 190/5000... Step: 11570... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11580... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 190/5000... Step: 11590... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191/5000... Step: 11600... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 191/5000... Step: 11610... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 191/5000... Step: 11620... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 191/5000... Step: 11630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 191/5000... Step: 11640... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 191/5000... Step: 11650... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 192/5000... Step: 11660... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 192/5000... Step: 11670... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 192/5000... Step: 11680... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 192/5000... Step: 11690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 192/5000... Step: 11700... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 192/5000... Step: 11710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 193/5000... Step: 11720... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 193/5000... Step: 11730... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 193/5000... Step: 11740... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 193/5000... Step: 11750... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 193/5000... Step: 11760... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 193/5000... Step: 11770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 194/5000... Step: 11780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 194/5000... Step: 11790... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 194/5000... Step: 11800... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 194/5000... Step: 11810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 194/5000... Step: 11820... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 194/5000... Step: 11830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 195/5000... Step: 11840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 195/5000... Step: 11850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 195/5000... Step: 11860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 195/5000... Step: 11870... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 195/5000... Step: 11880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 195/5000... Step: 11890... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 196/5000... Step: 11900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 196/5000... Step: 11910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 196/5000... Step: 11920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 196/5000... Step: 11930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 196/5000... Step: 11940... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 196/5000... Step: 11950... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 11960... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 11970... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 11980... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 11990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 12000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 197/5000... Step: 12010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12020... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12030... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12040... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 198/5000... Step: 12070... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 199/5000... Step: 12080... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 199/5000... Step: 12090... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 199/5000... Step: 12100... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 199/5000... Step: 12110... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 199/5000... Step: 12120... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 199/5000... Step: 12130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 200/5000... Step: 12140... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 200/5000... Step: 12150... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 200/5000... Step: 12160... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 200/5000... Step: 12170... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 200/5000... Step: 12180... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 200/5000... Step: 12190... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 200/5000... Step: 12200... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 201/5000... Step: 12210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 201/5000... Step: 12220... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 201/5000... Step: 12230... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 201/5000... Step: 12240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 201/5000... Step: 12250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 201/5000... Step: 12260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 202/5000... Step: 12270... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 202/5000... Step: 12280... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 202/5000... Step: 12290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 202/5000... Step: 12300... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 202/5000... Step: 12310... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 202/5000... Step: 12320... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 203/5000... Step: 12330... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 203/5000... Step: 12340... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 203/5000... Step: 12350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 203/5000... Step: 12360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 203/5000... Step: 12370... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 203/5000... Step: 12380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 204/5000... Step: 12390... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 204/5000... Step: 12400... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 204/5000... Step: 12410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 204/5000... Step: 12420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 204/5000... Step: 12430... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 204/5000... Step: 12440... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 205/5000... Step: 12450... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 205/5000... Step: 12460... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 205/5000... Step: 12470... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 205/5000... Step: 12480... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 205/5000... Step: 12490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 205/5000... Step: 12500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12510... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12520... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12530... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 206/5000... Step: 12560... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 207/5000... Step: 12570... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 207/5000... Step: 12580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 207/5000... Step: 12590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 207/5000... Step: 12600... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 207/5000... Step: 12610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 207/5000... Step: 12620... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 208/5000... Step: 12630... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 208/5000... Step: 12640... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 208/5000... Step: 12650... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 208/5000... Step: 12660... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 208/5000... Step: 12670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 208/5000... Step: 12680... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 209/5000... Step: 12690... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 209/5000... Step: 12700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 209/5000... Step: 12710... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 209/5000... Step: 12720... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 209/5000... Step: 12730... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 209/5000... Step: 12740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 210/5000... Step: 12750... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 210/5000... Step: 12760... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 210/5000... Step: 12770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 210/5000... Step: 12780... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 210/5000... Step: 12790... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 210/5000... Step: 12800... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 210/5000... Step: 12810... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 211/5000... Step: 12820... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 211/5000... Step: 12830... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 211/5000... Step: 12840... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 211/5000... Step: 12850... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 211/5000... Step: 12860... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 211/5000... Step: 12870... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 212/5000... Step: 12880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 212/5000... Step: 12890... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 212/5000... Step: 12900... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 212/5000... Step: 12910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 212/5000... Step: 12920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 212/5000... Step: 12930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 213/5000... Step: 12940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 213/5000... Step: 12950... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 213/5000... Step: 12960... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 213/5000... Step: 12970... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 213/5000... Step: 12980... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 213/5000... Step: 12990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13000... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13010... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13020... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13040... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 214/5000... Step: 13050... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 215/5000... Step: 13060... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 215/5000... Step: 13070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 215/5000... Step: 13080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 215/5000... Step: 13090... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 215/5000... Step: 13100... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 215/5000... Step: 13110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13130... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13140... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 216/5000... Step: 13170... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 217/5000... Step: 13180... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 217/5000... Step: 13190... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 217/5000... Step: 13200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 217/5000... Step: 13210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 217/5000... Step: 13220... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 217/5000... Step: 13230... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 218/5000... Step: 13240... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 218/5000... Step: 13250... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 218/5000... Step: 13260... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 218/5000... Step: 13270... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 218/5000... Step: 13280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 218/5000... Step: 13290... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 219/5000... Step: 13300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 219/5000... Step: 13310... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 219/5000... Step: 13320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 219/5000... Step: 13330... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 219/5000... Step: 13340... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 219/5000... Step: 13350... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 220/5000... Step: 13360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 220/5000... Step: 13370... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 220/5000... Step: 13380... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 220/5000... Step: 13390... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 220/5000... Step: 13400... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 220/5000... Step: 13410... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 220/5000... Step: 13420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 221/5000... Step: 13430... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 221/5000... Step: 13440... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 221/5000... Step: 13450... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 221/5000... Step: 13460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 221/5000... Step: 13470... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 221/5000... Step: 13480... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 222/5000... Step: 13490... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 222/5000... Step: 13500... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 222/5000... Step: 13510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 222/5000... Step: 13520... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 222/5000... Step: 13530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 222/5000... Step: 13540... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 223/5000... Step: 13550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 223/5000... Step: 13560... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 223/5000... Step: 13570... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 223/5000... Step: 13580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 223/5000... Step: 13590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 223/5000... Step: 13600... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13620... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13630... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13650... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 224/5000... Step: 13660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 225/5000... Step: 13670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 225/5000... Step: 13680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 225/5000... Step: 13690... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 225/5000... Step: 13700... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 225/5000... Step: 13710... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 225/5000... Step: 13720... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 226/5000... Step: 13730... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 226/5000... Step: 13740... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 226/5000... Step: 13750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 226/5000... Step: 13760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 226/5000... Step: 13770... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 226/5000... Step: 13780... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 227/5000... Step: 13790... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 227/5000... Step: 13800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 227/5000... Step: 13810... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 227/5000... Step: 13820... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 227/5000... Step: 13830... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 227/5000... Step: 13840... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 228/5000... Step: 13850... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 228/5000... Step: 13860... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 228/5000... Step: 13870... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 228/5000... Step: 13880... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 228/5000... Step: 13890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 228/5000... Step: 13900... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13930... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13950... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 229/5000... Step: 13960... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 230/5000... Step: 13970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 230/5000... Step: 13980... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 230/5000... Step: 13990... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 230/5000... Step: 14000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 230/5000... Step: 14010... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 230/5000... Step: 14020... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 230/5000... Step: 14030... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 231/5000... Step: 14040... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 231/5000... Step: 14050... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 231/5000... Step: 14060... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 231/5000... Step: 14070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 231/5000... Step: 14080... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 231/5000... Step: 14090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 232/5000... Step: 14100... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 232/5000... Step: 14110... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 232/5000... Step: 14120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 232/5000... Step: 14130... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 232/5000... Step: 14140... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 232/5000... Step: 14150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 233/5000... Step: 14160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 233/5000... Step: 14170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 233/5000... Step: 14180... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 233/5000... Step: 14190... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 233/5000... Step: 14200... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 233/5000... Step: 14210... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 234/5000... Step: 14220... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 234/5000... Step: 14230... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 234/5000... Step: 14240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 234/5000... Step: 14250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 234/5000... Step: 14260... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 234/5000... Step: 14270... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 235/5000... Step: 14280... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 235/5000... Step: 14290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 235/5000... Step: 14300... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 235/5000... Step: 14310... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 235/5000... Step: 14320... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 235/5000... Step: 14330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 236/5000... Step: 14340... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 236/5000... Step: 14350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 236/5000... Step: 14360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 236/5000... Step: 14370... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 236/5000... Step: 14380... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 236/5000... Step: 14390... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 237/5000... Step: 14400... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 237/5000... Step: 14410... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 237/5000... Step: 14420... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 237/5000... Step: 14430... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 237/5000... Step: 14440... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 237/5000... Step: 14450... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 238/5000... Step: 14460... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 238/5000... Step: 14470... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 238/5000... Step: 14480... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 238/5000... Step: 14490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 238/5000... Step: 14500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 238/5000... Step: 14510... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 239/5000... Step: 14520... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 239/5000... Step: 14530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 239/5000... Step: 14540... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 239/5000... Step: 14550... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 239/5000... Step: 14560... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 239/5000... Step: 14570... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 240/5000... Step: 14580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 240/5000... Step: 14590... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 240/5000... Step: 14600... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 240/5000... Step: 14610... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 240/5000... Step: 14620... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 240/5000... Step: 14630... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 240/5000... Step: 14640... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 241/5000... Step: 14650... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 241/5000... Step: 14660... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 241/5000... Step: 14670... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 241/5000... Step: 14680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 241/5000... Step: 14690... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 241/5000... Step: 14700... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 242/5000... Step: 14710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 242/5000... Step: 14720... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 242/5000... Step: 14730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 242/5000... Step: 14740... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 242/5000... Step: 14750... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 242/5000... Step: 14760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 243/5000... Step: 14770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 243/5000... Step: 14780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 243/5000... Step: 14790... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 243/5000... Step: 14800... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 243/5000... Step: 14810... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 243/5000... Step: 14820... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 244/5000... Step: 14830... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 244/5000... Step: 14840... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 244/5000... Step: 14850... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 244/5000... Step: 14860... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 244/5000... Step: 14870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 244/5000... Step: 14880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 245/5000... Step: 14890... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 245/5000... Step: 14900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 245/5000... Step: 14910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 245/5000... Step: 14920... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 245/5000... Step: 14930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 245/5000... Step: 14940... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 246/5000... Step: 14950... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 246/5000... Step: 14960... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 246/5000... Step: 14970... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 246/5000... Step: 14980... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 246/5000... Step: 14990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 246/5000... Step: 15000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 247/5000... Step: 15010... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 247/5000... Step: 15020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 247/5000... Step: 15030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 247/5000... Step: 15040... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 247/5000... Step: 15050... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 247/5000... Step: 15060... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 248/5000... Step: 15070... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 248/5000... Step: 15080... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 248/5000... Step: 15090... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 248/5000... Step: 15100... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 248/5000... Step: 15110... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 248/5000... Step: 15120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 249/5000... Step: 15130... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 249/5000... Step: 15140... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 249/5000... Step: 15150... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 249/5000... Step: 15160... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 249/5000... Step: 15170... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 249/5000... Step: 15180... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 250/5000... Step: 15190... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 250/5000... Step: 15200... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 250/5000... Step: 15210... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 250/5000... Step: 15220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 250/5000... Step: 15230... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 250/5000... Step: 15240... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 250/5000... Step: 15250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 251/5000... Step: 15260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 251/5000... Step: 15270... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 251/5000... Step: 15280... Loss: 0.0786... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251/5000... Step: 15290... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 251/5000... Step: 15300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 251/5000... Step: 15310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 252/5000... Step: 15320... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 252/5000... Step: 15330... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 252/5000... Step: 15340... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 252/5000... Step: 15350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 252/5000... Step: 15360... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 252/5000... Step: 15370... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 253/5000... Step: 15380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 253/5000... Step: 15390... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 253/5000... Step: 15400... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 253/5000... Step: 15410... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 253/5000... Step: 15420... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 253/5000... Step: 15430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 254/5000... Step: 15440... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 254/5000... Step: 15450... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 254/5000... Step: 15460... Loss: 0.0785... Val Loss: 0.0788\n",
      "Epoch: 254/5000... Step: 15470... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 254/5000... Step: 15480... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 254/5000... Step: 15490... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 255/5000... Step: 15500... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 255/5000... Step: 15510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 255/5000... Step: 15520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 255/5000... Step: 15530... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 255/5000... Step: 15540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 255/5000... Step: 15550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15560... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15570... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15590... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15600... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 256/5000... Step: 15610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 257/5000... Step: 15620... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 257/5000... Step: 15630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 257/5000... Step: 15640... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 257/5000... Step: 15650... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 257/5000... Step: 15660... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 257/5000... Step: 15670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 258/5000... Step: 15680... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 258/5000... Step: 15690... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 258/5000... Step: 15700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 258/5000... Step: 15710... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 258/5000... Step: 15720... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 258/5000... Step: 15730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 259/5000... Step: 15740... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 259/5000... Step: 15750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 259/5000... Step: 15760... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 259/5000... Step: 15770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 259/5000... Step: 15780... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 259/5000... Step: 15790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 260/5000... Step: 15800... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 260/5000... Step: 15810... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 260/5000... Step: 15820... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 260/5000... Step: 15830... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 260/5000... Step: 15840... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 260/5000... Step: 15850... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 260/5000... Step: 15860... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 261/5000... Step: 15870... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 261/5000... Step: 15880... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 261/5000... Step: 15890... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 261/5000... Step: 15900... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 261/5000... Step: 15910... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 261/5000... Step: 15920... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 262/5000... Step: 15930... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 262/5000... Step: 15940... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 262/5000... Step: 15950... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 262/5000... Step: 15960... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 262/5000... Step: 15970... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 262/5000... Step: 15980... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 263/5000... Step: 15990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 263/5000... Step: 16000... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 263/5000... Step: 16010... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 263/5000... Step: 16020... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 263/5000... Step: 16030... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 263/5000... Step: 16040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 264/5000... Step: 16050... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 264/5000... Step: 16060... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 264/5000... Step: 16070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 264/5000... Step: 16080... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 264/5000... Step: 16090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 264/5000... Step: 16100... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 265/5000... Step: 16110... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 265/5000... Step: 16120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 265/5000... Step: 16130... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 265/5000... Step: 16140... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 265/5000... Step: 16150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 265/5000... Step: 16160... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 266/5000... Step: 16170... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 266/5000... Step: 16180... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 266/5000... Step: 16190... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 266/5000... Step: 16200... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 266/5000... Step: 16210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 266/5000... Step: 16220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16230... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16260... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16270... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 267/5000... Step: 16280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 268/5000... Step: 16290... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 268/5000... Step: 16300... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 268/5000... Step: 16310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 268/5000... Step: 16320... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 268/5000... Step: 16330... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 268/5000... Step: 16340... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 269/5000... Step: 16350... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 269/5000... Step: 16360... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 269/5000... Step: 16370... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 269/5000... Step: 16380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 269/5000... Step: 16390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 269/5000... Step: 16400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 270/5000... Step: 16410... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 270/5000... Step: 16420... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 270/5000... Step: 16430... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 270/5000... Step: 16440... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 270/5000... Step: 16450... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 270/5000... Step: 16460... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 270/5000... Step: 16470... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 271/5000... Step: 16480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 271/5000... Step: 16490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 271/5000... Step: 16500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 271/5000... Step: 16510... Loss: 0.0785... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 271/5000... Step: 16520... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 271/5000... Step: 16530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16540... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16570... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 272/5000... Step: 16590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 273/5000... Step: 16600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 273/5000... Step: 16610... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 273/5000... Step: 16620... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 273/5000... Step: 16630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 273/5000... Step: 16640... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 273/5000... Step: 16650... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 274/5000... Step: 16660... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 274/5000... Step: 16670... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 274/5000... Step: 16680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 274/5000... Step: 16690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 274/5000... Step: 16700... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 274/5000... Step: 16710... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 275/5000... Step: 16720... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 275/5000... Step: 16730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 275/5000... Step: 16740... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 275/5000... Step: 16750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 275/5000... Step: 16760... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 275/5000... Step: 16770... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 276/5000... Step: 16780... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 276/5000... Step: 16790... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 276/5000... Step: 16800... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 276/5000... Step: 16810... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 276/5000... Step: 16820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 276/5000... Step: 16830... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 277/5000... Step: 16840... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 277/5000... Step: 16850... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 277/5000... Step: 16860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 277/5000... Step: 16870... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 277/5000... Step: 16880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 277/5000... Step: 16890... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 278/5000... Step: 16900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 278/5000... Step: 16910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 278/5000... Step: 16920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 278/5000... Step: 16930... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 278/5000... Step: 16940... Loss: 0.0785... Val Loss: 0.0788\n",
      "Epoch: 278/5000... Step: 16950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 279/5000... Step: 16960... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 279/5000... Step: 16970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 279/5000... Step: 16980... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 279/5000... Step: 16990... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 279/5000... Step: 17000... Loss: 0.0783... Val Loss: 0.0788\n",
      "Epoch: 279/5000... Step: 17010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 280/5000... Step: 17020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 280/5000... Step: 17030... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 280/5000... Step: 17040... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 280/5000... Step: 17050... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 280/5000... Step: 17060... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 280/5000... Step: 17070... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 280/5000... Step: 17080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 281/5000... Step: 17090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 281/5000... Step: 17100... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 281/5000... Step: 17110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 281/5000... Step: 17120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 281/5000... Step: 17130... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 281/5000... Step: 17140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 282/5000... Step: 17150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 282/5000... Step: 17160... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 282/5000... Step: 17170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 282/5000... Step: 17180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 282/5000... Step: 17190... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 282/5000... Step: 17200... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 283/5000... Step: 17210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 283/5000... Step: 17220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 283/5000... Step: 17230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 283/5000... Step: 17240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 283/5000... Step: 17250... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 283/5000... Step: 17260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 284/5000... Step: 17270... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 284/5000... Step: 17280... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 284/5000... Step: 17290... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 284/5000... Step: 17300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 284/5000... Step: 17310... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 284/5000... Step: 17320... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17330... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17350... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17360... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17370... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 285/5000... Step: 17380... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 286/5000... Step: 17390... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 286/5000... Step: 17400... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 286/5000... Step: 17410... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 286/5000... Step: 17420... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 286/5000... Step: 17430... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 286/5000... Step: 17440... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 287/5000... Step: 17450... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 287/5000... Step: 17460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 287/5000... Step: 17470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 287/5000... Step: 17480... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 287/5000... Step: 17490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 287/5000... Step: 17500... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 288/5000... Step: 17510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 288/5000... Step: 17520... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 288/5000... Step: 17530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 288/5000... Step: 17540... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 288/5000... Step: 17550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 288/5000... Step: 17560... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 289/5000... Step: 17570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 289/5000... Step: 17580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 289/5000... Step: 17590... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 289/5000... Step: 17600... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 289/5000... Step: 17610... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 289/5000... Step: 17620... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 290/5000... Step: 17630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 290/5000... Step: 17640... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 290/5000... Step: 17650... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 290/5000... Step: 17660... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 290/5000... Step: 17670... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 290/5000... Step: 17680... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 290/5000... Step: 17690... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 291/5000... Step: 17700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 291/5000... Step: 17710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 291/5000... Step: 17720... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 291/5000... Step: 17730... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 291/5000... Step: 17740... Loss: 0.0786... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 291/5000... Step: 17750... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 292/5000... Step: 17760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 292/5000... Step: 17770... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 292/5000... Step: 17780... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 292/5000... Step: 17790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 292/5000... Step: 17800... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 292/5000... Step: 17810... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 293/5000... Step: 17820... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 293/5000... Step: 17830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 293/5000... Step: 17840... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 293/5000... Step: 17850... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 293/5000... Step: 17860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 293/5000... Step: 17870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 294/5000... Step: 17880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 294/5000... Step: 17890... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 294/5000... Step: 17900... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 294/5000... Step: 17910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 294/5000... Step: 17920... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 294/5000... Step: 17930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 295/5000... Step: 17940... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 295/5000... Step: 17950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 295/5000... Step: 17960... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 295/5000... Step: 17970... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 295/5000... Step: 17980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 295/5000... Step: 17990... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 296/5000... Step: 18000... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 296/5000... Step: 18010... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 296/5000... Step: 18020... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 296/5000... Step: 18030... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 296/5000... Step: 18040... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 296/5000... Step: 18050... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 297/5000... Step: 18060... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 297/5000... Step: 18070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 297/5000... Step: 18080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 297/5000... Step: 18090... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 297/5000... Step: 18100... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 297/5000... Step: 18110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18130... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18140... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18150... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 298/5000... Step: 18170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 299/5000... Step: 18180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 299/5000... Step: 18190... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 299/5000... Step: 18200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 299/5000... Step: 18210... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 299/5000... Step: 18220... Loss: 0.0781... Val Loss: 0.0788\n",
      "Epoch: 299/5000... Step: 18230... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 300/5000... Step: 18240... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 300/5000... Step: 18250... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 300/5000... Step: 18260... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 300/5000... Step: 18270... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 300/5000... Step: 18280... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 300/5000... Step: 18290... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 300/5000... Step: 18300... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 301/5000... Step: 18310... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 301/5000... Step: 18320... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 301/5000... Step: 18330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 301/5000... Step: 18340... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 301/5000... Step: 18350... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 301/5000... Step: 18360... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 302/5000... Step: 18370... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 302/5000... Step: 18380... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 302/5000... Step: 18390... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 302/5000... Step: 18400... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 302/5000... Step: 18410... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 302/5000... Step: 18420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 303/5000... Step: 18430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 303/5000... Step: 18440... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 303/5000... Step: 18450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 303/5000... Step: 18460... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 303/5000... Step: 18470... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 303/5000... Step: 18480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 304/5000... Step: 18490... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 304/5000... Step: 18500... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 304/5000... Step: 18510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 304/5000... Step: 18520... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 304/5000... Step: 18530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 304/5000... Step: 18540... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 305/5000... Step: 18550... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 305/5000... Step: 18560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 305/5000... Step: 18570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 305/5000... Step: 18580... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 305/5000... Step: 18590... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 305/5000... Step: 18600... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18610... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18620... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18650... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 306/5000... Step: 18660... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 307/5000... Step: 18670... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 307/5000... Step: 18680... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 307/5000... Step: 18690... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 307/5000... Step: 18700... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 307/5000... Step: 18710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 307/5000... Step: 18720... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 308/5000... Step: 18730... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 308/5000... Step: 18740... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 308/5000... Step: 18750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 308/5000... Step: 18760... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 308/5000... Step: 18770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 308/5000... Step: 18780... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 309/5000... Step: 18790... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 309/5000... Step: 18800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 309/5000... Step: 18810... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 309/5000... Step: 18820... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 309/5000... Step: 18830... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 309/5000... Step: 18840... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 310/5000... Step: 18850... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 310/5000... Step: 18860... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 310/5000... Step: 18870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 310/5000... Step: 18880... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 310/5000... Step: 18890... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 310/5000... Step: 18900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 310/5000... Step: 18910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 311/5000... Step: 18920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 311/5000... Step: 18930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 311/5000... Step: 18940... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 311/5000... Step: 18950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 311/5000... Step: 18960... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 311/5000... Step: 18970... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 312/5000... Step: 18980... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 312/5000... Step: 18990... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 312/5000... Step: 19000... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 312/5000... Step: 19010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 312/5000... Step: 19020... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 312/5000... Step: 19030... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 313/5000... Step: 19040... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 313/5000... Step: 19050... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 313/5000... Step: 19060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 313/5000... Step: 19070... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 313/5000... Step: 19080... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 313/5000... Step: 19090... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 314/5000... Step: 19100... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 314/5000... Step: 19110... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 314/5000... Step: 19120... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 314/5000... Step: 19130... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 314/5000... Step: 19140... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 314/5000... Step: 19150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 315/5000... Step: 19160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 315/5000... Step: 19170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 315/5000... Step: 19180... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 315/5000... Step: 19190... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 315/5000... Step: 19200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 315/5000... Step: 19210... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 316/5000... Step: 19220... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 316/5000... Step: 19230... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 316/5000... Step: 19240... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 316/5000... Step: 19250... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 316/5000... Step: 19260... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 316/5000... Step: 19270... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 317/5000... Step: 19280... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 317/5000... Step: 19290... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 317/5000... Step: 19300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 317/5000... Step: 19310... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 317/5000... Step: 19320... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 317/5000... Step: 19330... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 318/5000... Step: 19340... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 318/5000... Step: 19350... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 318/5000... Step: 19360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 318/5000... Step: 19370... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 318/5000... Step: 19380... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 318/5000... Step: 19390... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 319/5000... Step: 19400... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 319/5000... Step: 19410... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 319/5000... Step: 19420... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 319/5000... Step: 19430... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 319/5000... Step: 19440... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 319/5000... Step: 19450... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 320/5000... Step: 19460... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 320/5000... Step: 19470... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 320/5000... Step: 19480... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 320/5000... Step: 19490... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 320/5000... Step: 19500... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 320/5000... Step: 19510... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 320/5000... Step: 19520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 321/5000... Step: 19530... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 321/5000... Step: 19540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 321/5000... Step: 19550... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 321/5000... Step: 19560... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 321/5000... Step: 19570... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 321/5000... Step: 19580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 322/5000... Step: 19590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 322/5000... Step: 19600... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 322/5000... Step: 19610... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 322/5000... Step: 19620... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 322/5000... Step: 19630... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 322/5000... Step: 19640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 323/5000... Step: 19650... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 323/5000... Step: 19660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 323/5000... Step: 19670... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 323/5000... Step: 19680... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 323/5000... Step: 19690... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 323/5000... Step: 19700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 324/5000... Step: 19710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 324/5000... Step: 19720... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 324/5000... Step: 19730... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 324/5000... Step: 19740... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 324/5000... Step: 19750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 324/5000... Step: 19760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19770... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19780... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19790... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19800... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 325/5000... Step: 19820... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 326/5000... Step: 19830... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 326/5000... Step: 19840... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 326/5000... Step: 19850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 326/5000... Step: 19860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 326/5000... Step: 19870... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 326/5000... Step: 19880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 327/5000... Step: 19890... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 327/5000... Step: 19900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 327/5000... Step: 19910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 327/5000... Step: 19920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 327/5000... Step: 19930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 327/5000... Step: 19940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 328/5000... Step: 19950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 328/5000... Step: 19960... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 328/5000... Step: 19970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 328/5000... Step: 19980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 328/5000... Step: 19990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 328/5000... Step: 20000... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 329/5000... Step: 20010... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 329/5000... Step: 20020... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 329/5000... Step: 20030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 329/5000... Step: 20040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 329/5000... Step: 20050... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 329/5000... Step: 20060... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 330/5000... Step: 20070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 330/5000... Step: 20080... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 330/5000... Step: 20090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 330/5000... Step: 20100... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 330/5000... Step: 20110... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 330/5000... Step: 20120... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 330/5000... Step: 20130... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 331/5000... Step: 20140... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 331/5000... Step: 20150... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 331/5000... Step: 20160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 331/5000... Step: 20170... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 331/5000... Step: 20180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 331/5000... Step: 20190... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 332/5000... Step: 20200... Loss: 0.0785... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 332/5000... Step: 20210... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 332/5000... Step: 20220... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 332/5000... Step: 20230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 332/5000... Step: 20240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 332/5000... Step: 20250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 333/5000... Step: 20260... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 333/5000... Step: 20270... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 333/5000... Step: 20280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 333/5000... Step: 20290... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 333/5000... Step: 20300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 333/5000... Step: 20310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 334/5000... Step: 20320... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 334/5000... Step: 20330... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 334/5000... Step: 20340... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 334/5000... Step: 20350... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 334/5000... Step: 20360... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 334/5000... Step: 20370... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 335/5000... Step: 20380... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 335/5000... Step: 20390... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 335/5000... Step: 20400... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 335/5000... Step: 20410... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 335/5000... Step: 20420... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 335/5000... Step: 20430... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 336/5000... Step: 20440... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 336/5000... Step: 20450... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 336/5000... Step: 20460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 336/5000... Step: 20470... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 336/5000... Step: 20480... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 336/5000... Step: 20490... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 337/5000... Step: 20500... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 337/5000... Step: 20510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 337/5000... Step: 20520... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 337/5000... Step: 20530... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 337/5000... Step: 20540... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 337/5000... Step: 20550... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 338/5000... Step: 20560... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 338/5000... Step: 20570... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 338/5000... Step: 20580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 338/5000... Step: 20590... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 338/5000... Step: 20600... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 338/5000... Step: 20610... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 339/5000... Step: 20620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 339/5000... Step: 20630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 339/5000... Step: 20640... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 339/5000... Step: 20650... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 339/5000... Step: 20660... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 339/5000... Step: 20670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 340/5000... Step: 20680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 340/5000... Step: 20690... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 340/5000... Step: 20700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 340/5000... Step: 20710... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 340/5000... Step: 20720... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 340/5000... Step: 20730... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 340/5000... Step: 20740... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 341/5000... Step: 20750... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 341/5000... Step: 20760... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 341/5000... Step: 20770... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 341/5000... Step: 20780... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 341/5000... Step: 20790... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 341/5000... Step: 20800... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 342/5000... Step: 20810... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 342/5000... Step: 20820... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 342/5000... Step: 20830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 342/5000... Step: 20840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 342/5000... Step: 20850... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 342/5000... Step: 20860... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 343/5000... Step: 20870... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 343/5000... Step: 20880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 343/5000... Step: 20890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 343/5000... Step: 20900... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 343/5000... Step: 20910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 343/5000... Step: 20920... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 344/5000... Step: 20930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 344/5000... Step: 20940... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 344/5000... Step: 20950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 344/5000... Step: 20960... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 344/5000... Step: 20970... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 344/5000... Step: 20980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 345/5000... Step: 20990... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 345/5000... Step: 21000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 345/5000... Step: 21010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 345/5000... Step: 21020... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 345/5000... Step: 21030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 345/5000... Step: 21040... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 346/5000... Step: 21050... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 346/5000... Step: 21060... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 346/5000... Step: 21070... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 346/5000... Step: 21080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 346/5000... Step: 21090... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 346/5000... Step: 21100... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 347/5000... Step: 21110... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 347/5000... Step: 21120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 347/5000... Step: 21130... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 347/5000... Step: 21140... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 347/5000... Step: 21150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 347/5000... Step: 21160... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 348/5000... Step: 21170... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 348/5000... Step: 21180... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 348/5000... Step: 21190... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 348/5000... Step: 21200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 348/5000... Step: 21210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 348/5000... Step: 21220... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 349/5000... Step: 21230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 349/5000... Step: 21240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 349/5000... Step: 21250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 349/5000... Step: 21260... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 349/5000... Step: 21270... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 349/5000... Step: 21280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 350/5000... Step: 21290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 350/5000... Step: 21300... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 350/5000... Step: 21310... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 350/5000... Step: 21320... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 350/5000... Step: 21330... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 350/5000... Step: 21340... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 350/5000... Step: 21350... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 351/5000... Step: 21360... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 351/5000... Step: 21370... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 351/5000... Step: 21380... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 351/5000... Step: 21390... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 351/5000... Step: 21400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 351/5000... Step: 21410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 352/5000... Step: 21420... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 352/5000... Step: 21430... Loss: 0.0781... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 352/5000... Step: 21440... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 352/5000... Step: 21450... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 352/5000... Step: 21460... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 352/5000... Step: 21470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 353/5000... Step: 21480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 353/5000... Step: 21490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 353/5000... Step: 21500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 353/5000... Step: 21510... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 353/5000... Step: 21520... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 353/5000... Step: 21530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 354/5000... Step: 21540... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 354/5000... Step: 21550... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 354/5000... Step: 21560... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 354/5000... Step: 21570... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 354/5000... Step: 21580... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 354/5000... Step: 21590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 355/5000... Step: 21600... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 355/5000... Step: 21610... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 355/5000... Step: 21620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 355/5000... Step: 21630... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 355/5000... Step: 21640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 355/5000... Step: 21650... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21660... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21670... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21690... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21700... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 356/5000... Step: 21710... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 357/5000... Step: 21720... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 357/5000... Step: 21730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 357/5000... Step: 21740... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 357/5000... Step: 21750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 357/5000... Step: 21760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 357/5000... Step: 21770... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 358/5000... Step: 21780... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 358/5000... Step: 21790... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 358/5000... Step: 21800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 358/5000... Step: 21810... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 358/5000... Step: 21820... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 358/5000... Step: 21830... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 359/5000... Step: 21840... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 359/5000... Step: 21850... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 359/5000... Step: 21860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 359/5000... Step: 21870... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 359/5000... Step: 21880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 359/5000... Step: 21890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 360/5000... Step: 21900... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 360/5000... Step: 21910... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 360/5000... Step: 21920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 360/5000... Step: 21930... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 360/5000... Step: 21940... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 360/5000... Step: 21950... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 360/5000... Step: 21960... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 361/5000... Step: 21970... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 361/5000... Step: 21980... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 361/5000... Step: 21990... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 361/5000... Step: 22000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 361/5000... Step: 22010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 361/5000... Step: 22020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 362/5000... Step: 22030... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 362/5000... Step: 22040... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 362/5000... Step: 22050... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 362/5000... Step: 22060... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 362/5000... Step: 22070... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 362/5000... Step: 22080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 363/5000... Step: 22090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 363/5000... Step: 22100... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 363/5000... Step: 22110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 363/5000... Step: 22120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 363/5000... Step: 22130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 363/5000... Step: 22140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22160... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22170... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22190... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 364/5000... Step: 22200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 365/5000... Step: 22210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 365/5000... Step: 22220... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 365/5000... Step: 22230... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 365/5000... Step: 22240... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 365/5000... Step: 22250... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 365/5000... Step: 22260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22270... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22280... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22310... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 366/5000... Step: 22320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 367/5000... Step: 22330... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 367/5000... Step: 22340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 367/5000... Step: 22350... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 367/5000... Step: 22360... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 367/5000... Step: 22370... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 367/5000... Step: 22380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 368/5000... Step: 22390... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 368/5000... Step: 22400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 368/5000... Step: 22410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 368/5000... Step: 22420... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 368/5000... Step: 22430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 368/5000... Step: 22440... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22460... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22470... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 369/5000... Step: 22500... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 370/5000... Step: 22510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 370/5000... Step: 22520... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 370/5000... Step: 22530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 370/5000... Step: 22540... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 370/5000... Step: 22550... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 370/5000... Step: 22560... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 370/5000... Step: 22570... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 371/5000... Step: 22580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 371/5000... Step: 22590... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 371/5000... Step: 22600... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 371/5000... Step: 22610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 371/5000... Step: 22620... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 371/5000... Step: 22630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 372/5000... Step: 22640... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 372/5000... Step: 22650... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 372/5000... Step: 22660... Loss: 0.0786... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 372/5000... Step: 22670... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 372/5000... Step: 22680... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 372/5000... Step: 22690... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 373/5000... Step: 22700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 373/5000... Step: 22710... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 373/5000... Step: 22720... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 373/5000... Step: 22730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 373/5000... Step: 22740... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 373/5000... Step: 22750... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 374/5000... Step: 22760... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 374/5000... Step: 22770... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 374/5000... Step: 22780... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 374/5000... Step: 22790... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 374/5000... Step: 22800... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 374/5000... Step: 22810... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 375/5000... Step: 22820... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 375/5000... Step: 22830... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 375/5000... Step: 22840... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 375/5000... Step: 22850... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 375/5000... Step: 22860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 375/5000... Step: 22870... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22880... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22890... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22900... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 376/5000... Step: 22930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 377/5000... Step: 22940... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 377/5000... Step: 22950... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 377/5000... Step: 22960... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 377/5000... Step: 22970... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 377/5000... Step: 22980... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 377/5000... Step: 22990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23000... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23020... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23040... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 378/5000... Step: 23050... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 379/5000... Step: 23060... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 379/5000... Step: 23070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 379/5000... Step: 23080... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 379/5000... Step: 23090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 379/5000... Step: 23100... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 379/5000... Step: 23110... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23130... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23140... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23150... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23160... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 380/5000... Step: 23170... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 380/5000... Step: 23180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 381/5000... Step: 23190... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 381/5000... Step: 23200... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 381/5000... Step: 23210... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 381/5000... Step: 23220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 381/5000... Step: 23230... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 381/5000... Step: 23240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 382/5000... Step: 23250... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 382/5000... Step: 23260... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 382/5000... Step: 23270... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 382/5000... Step: 23280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 382/5000... Step: 23290... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 382/5000... Step: 23300... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 383/5000... Step: 23310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 383/5000... Step: 23320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 383/5000... Step: 23330... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 383/5000... Step: 23340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 383/5000... Step: 23350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 383/5000... Step: 23360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 384/5000... Step: 23370... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 384/5000... Step: 23380... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 384/5000... Step: 23390... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 384/5000... Step: 23400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 384/5000... Step: 23410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 384/5000... Step: 23420... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 385/5000... Step: 23430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 385/5000... Step: 23440... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 385/5000... Step: 23450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 385/5000... Step: 23460... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 385/5000... Step: 23470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 385/5000... Step: 23480... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 386/5000... Step: 23490... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 386/5000... Step: 23500... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 386/5000... Step: 23510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 386/5000... Step: 23520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 386/5000... Step: 23530... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 386/5000... Step: 23540... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23550... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23560... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23580... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 387/5000... Step: 23600... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 388/5000... Step: 23610... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 388/5000... Step: 23620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 388/5000... Step: 23630... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 388/5000... Step: 23640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 388/5000... Step: 23650... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 388/5000... Step: 23660... Loss: 0.0786... Val Loss: 0.0788\n",
      "Epoch: 389/5000... Step: 23670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 389/5000... Step: 23680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 389/5000... Step: 23690... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 389/5000... Step: 23700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 389/5000... Step: 23710... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 389/5000... Step: 23720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 390/5000... Step: 23730... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 390/5000... Step: 23740... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 390/5000... Step: 23750... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 390/5000... Step: 23760... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 390/5000... Step: 23770... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 390/5000... Step: 23780... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 390/5000... Step: 23790... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 391/5000... Step: 23800... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 391/5000... Step: 23810... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 391/5000... Step: 23820... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 391/5000... Step: 23830... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 391/5000... Step: 23840... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 391/5000... Step: 23850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 392/5000... Step: 23860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 392/5000... Step: 23870... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 392/5000... Step: 23880... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 392/5000... Step: 23890... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 392/5000... Step: 23900... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 392/5000... Step: 23910... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 393/5000... Step: 23920... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 393/5000... Step: 23930... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 393/5000... Step: 23940... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 393/5000... Step: 23950... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 393/5000... Step: 23960... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 393/5000... Step: 23970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 394/5000... Step: 23980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 394/5000... Step: 23990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 394/5000... Step: 24000... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 394/5000... Step: 24010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 394/5000... Step: 24020... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 394/5000... Step: 24030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 395/5000... Step: 24040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 395/5000... Step: 24050... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 395/5000... Step: 24060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 395/5000... Step: 24070... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 395/5000... Step: 24080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 395/5000... Step: 24090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 396/5000... Step: 24100... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 396/5000... Step: 24110... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 396/5000... Step: 24120... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 396/5000... Step: 24130... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 396/5000... Step: 24140... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 396/5000... Step: 24150... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24160... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24170... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24190... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 397/5000... Step: 24210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 398/5000... Step: 24220... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 398/5000... Step: 24230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 398/5000... Step: 24240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 398/5000... Step: 24250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 398/5000... Step: 24260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 398/5000... Step: 24270... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24300... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24310... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 399/5000... Step: 24330... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 400/5000... Step: 24340... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 400/5000... Step: 24350... Loss: 0.0789... Val Loss: 0.0786\n",
      "Epoch: 400/5000... Step: 24360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 400/5000... Step: 24370... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 400/5000... Step: 24380... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 400/5000... Step: 24390... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 400/5000... Step: 24400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 401/5000... Step: 24410... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 401/5000... Step: 24420... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 401/5000... Step: 24430... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 401/5000... Step: 24440... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 401/5000... Step: 24450... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 401/5000... Step: 24460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 402/5000... Step: 24470... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 402/5000... Step: 24480... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 402/5000... Step: 24490... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 402/5000... Step: 24500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 402/5000... Step: 24510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 402/5000... Step: 24520... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 403/5000... Step: 24530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 403/5000... Step: 24540... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 403/5000... Step: 24550... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 403/5000... Step: 24560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 403/5000... Step: 24570... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 403/5000... Step: 24580... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 404/5000... Step: 24590... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 404/5000... Step: 24600... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 404/5000... Step: 24610... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 404/5000... Step: 24620... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 404/5000... Step: 24630... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 404/5000... Step: 24640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 405/5000... Step: 24650... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 405/5000... Step: 24660... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 405/5000... Step: 24670... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 405/5000... Step: 24680... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 405/5000... Step: 24690... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 405/5000... Step: 24700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 406/5000... Step: 24710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 406/5000... Step: 24720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 406/5000... Step: 24730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 406/5000... Step: 24740... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 406/5000... Step: 24750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 406/5000... Step: 24760... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 407/5000... Step: 24770... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 407/5000... Step: 24780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 407/5000... Step: 24790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 407/5000... Step: 24800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 407/5000... Step: 24810... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 407/5000... Step: 24820... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 408/5000... Step: 24830... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 408/5000... Step: 24840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 408/5000... Step: 24850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 408/5000... Step: 24860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 408/5000... Step: 24870... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 408/5000... Step: 24880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 409/5000... Step: 24890... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 409/5000... Step: 24900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 409/5000... Step: 24910... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 409/5000... Step: 24920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 409/5000... Step: 24930... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 409/5000... Step: 24940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 410/5000... Step: 24950... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 410/5000... Step: 24960... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 410/5000... Step: 24970... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 410/5000... Step: 24980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 410/5000... Step: 24990... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 410/5000... Step: 25000... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 410/5000... Step: 25010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 411/5000... Step: 25020... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 411/5000... Step: 25030... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 411/5000... Step: 25040... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 411/5000... Step: 25050... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 411/5000... Step: 25060... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 411/5000... Step: 25070... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 412/5000... Step: 25080... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 412/5000... Step: 25090... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 412/5000... Step: 25100... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 412/5000... Step: 25110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 412/5000... Step: 25120... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 412/5000... Step: 25130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 413/5000... Step: 25140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 413/5000... Step: 25150... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 413/5000... Step: 25160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 413/5000... Step: 25170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 413/5000... Step: 25180... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 413/5000... Step: 25190... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 414/5000... Step: 25200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 414/5000... Step: 25210... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 414/5000... Step: 25220... Loss: 0.0786... Val Loss: 0.0788\n",
      "Epoch: 414/5000... Step: 25230... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 414/5000... Step: 25240... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 414/5000... Step: 25250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 415/5000... Step: 25260... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 415/5000... Step: 25270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 415/5000... Step: 25280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 415/5000... Step: 25290... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 415/5000... Step: 25300... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 415/5000... Step: 25310... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 416/5000... Step: 25320... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 416/5000... Step: 25330... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 416/5000... Step: 25340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 416/5000... Step: 25350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 416/5000... Step: 25360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 416/5000... Step: 25370... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25380... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25390... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25410... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25420... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 417/5000... Step: 25430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 418/5000... Step: 25440... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 418/5000... Step: 25450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 418/5000... Step: 25460... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 418/5000... Step: 25470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 418/5000... Step: 25480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 418/5000... Step: 25490... Loss: 0.0785... Val Loss: 0.0788\n",
      "Epoch: 419/5000... Step: 25500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 419/5000... Step: 25510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 419/5000... Step: 25520... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 419/5000... Step: 25530... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 419/5000... Step: 25540... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 419/5000... Step: 25550... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25560... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25570... Loss: 0.0789... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25590... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25600... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 420/5000... Step: 25610... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 420/5000... Step: 25620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 421/5000... Step: 25630... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 421/5000... Step: 25640... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 421/5000... Step: 25650... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 421/5000... Step: 25660... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 421/5000... Step: 25670... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 421/5000... Step: 25680... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 422/5000... Step: 25690... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 422/5000... Step: 25700... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 422/5000... Step: 25710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 422/5000... Step: 25720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 422/5000... Step: 25730... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 422/5000... Step: 25740... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 423/5000... Step: 25750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 423/5000... Step: 25760... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 423/5000... Step: 25770... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 423/5000... Step: 25780... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 423/5000... Step: 25790... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 423/5000... Step: 25800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 424/5000... Step: 25810... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 424/5000... Step: 25820... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 424/5000... Step: 25830... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 424/5000... Step: 25840... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 424/5000... Step: 25850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 424/5000... Step: 25860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 425/5000... Step: 25870... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 425/5000... Step: 25880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 425/5000... Step: 25890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 425/5000... Step: 25900... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 425/5000... Step: 25910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 425/5000... Step: 25920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 426/5000... Step: 25930... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 426/5000... Step: 25940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 426/5000... Step: 25950... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 426/5000... Step: 25960... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 426/5000... Step: 25970... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 426/5000... Step: 25980... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 427/5000... Step: 25990... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 427/5000... Step: 26000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 427/5000... Step: 26010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 427/5000... Step: 26020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 427/5000... Step: 26030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 427/5000... Step: 26040... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 428/5000... Step: 26050... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 428/5000... Step: 26060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 428/5000... Step: 26070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 428/5000... Step: 26080... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 428/5000... Step: 26090... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 428/5000... Step: 26100... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 429/5000... Step: 26110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 429/5000... Step: 26120... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 429/5000... Step: 26130... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 429/5000... Step: 26140... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 429/5000... Step: 26150... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 429/5000... Step: 26160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 430/5000... Step: 26170... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 430/5000... Step: 26180... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 430/5000... Step: 26190... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 430/5000... Step: 26200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 430/5000... Step: 26210... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 430/5000... Step: 26220... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 430/5000... Step: 26230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 431/5000... Step: 26240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 431/5000... Step: 26250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 431/5000... Step: 26260... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 431/5000... Step: 26270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 431/5000... Step: 26280... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 431/5000... Step: 26290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 432/5000... Step: 26300... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 432/5000... Step: 26310... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 432/5000... Step: 26320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 432/5000... Step: 26330... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 432/5000... Step: 26340... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 432/5000... Step: 26350... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 433/5000... Step: 26360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 433/5000... Step: 26370... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 433/5000... Step: 26380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 433/5000... Step: 26390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 433/5000... Step: 26400... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 433/5000... Step: 26410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 434/5000... Step: 26420... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 434/5000... Step: 26430... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 434/5000... Step: 26440... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 434/5000... Step: 26450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 434/5000... Step: 26460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 434/5000... Step: 26470... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 435/5000... Step: 26480... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 435/5000... Step: 26490... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 435/5000... Step: 26500... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 435/5000... Step: 26510... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 435/5000... Step: 26520... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 435/5000... Step: 26530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 436/5000... Step: 26540... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 436/5000... Step: 26550... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 436/5000... Step: 26560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 436/5000... Step: 26570... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 436/5000... Step: 26580... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 436/5000... Step: 26590... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26600... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26620... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26630... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26640... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 437/5000... Step: 26650... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 438/5000... Step: 26660... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 438/5000... Step: 26670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 438/5000... Step: 26680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 438/5000... Step: 26690... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 438/5000... Step: 26700... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 438/5000... Step: 26710... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 439/5000... Step: 26720... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 439/5000... Step: 26730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 439/5000... Step: 26740... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 439/5000... Step: 26750... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 439/5000... Step: 26760... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 439/5000... Step: 26770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 440/5000... Step: 26780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26790... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26800... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26810... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26820... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26830... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 440/5000... Step: 26840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 441/5000... Step: 26850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 441/5000... Step: 26860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 441/5000... Step: 26870... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 441/5000... Step: 26880... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 441/5000... Step: 26890... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 441/5000... Step: 26900... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 442/5000... Step: 26910... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 442/5000... Step: 26920... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 442/5000... Step: 26930... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 442/5000... Step: 26940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 442/5000... Step: 26950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 442/5000... Step: 26960... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 443/5000... Step: 26970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 443/5000... Step: 26980... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 443/5000... Step: 26990... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 443/5000... Step: 27000... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 443/5000... Step: 27010... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 443/5000... Step: 27020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27040... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27050... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27060... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27070... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 444/5000... Step: 27080... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27090... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27100... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27120... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27130... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 445/5000... Step: 27140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 446/5000... Step: 27150... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 446/5000... Step: 27160... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 446/5000... Step: 27170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 446/5000... Step: 27180... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 446/5000... Step: 27190... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 446/5000... Step: 27200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 447/5000... Step: 27210... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 447/5000... Step: 27220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 447/5000... Step: 27230... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 447/5000... Step: 27240... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 447/5000... Step: 27250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 447/5000... Step: 27260... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 448/5000... Step: 27270... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 448/5000... Step: 27280... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 448/5000... Step: 27290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 448/5000... Step: 27300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 448/5000... Step: 27310... Loss: 0.0784... Val Loss: 0.0788\n",
      "Epoch: 448/5000... Step: 27320... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 449/5000... Step: 27330... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 449/5000... Step: 27340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 449/5000... Step: 27350... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 449/5000... Step: 27360... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 449/5000... Step: 27370... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 449/5000... Step: 27380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 450/5000... Step: 27390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 450/5000... Step: 27400... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 450/5000... Step: 27410... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 450/5000... Step: 27420... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 450/5000... Step: 27430... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 450/5000... Step: 27440... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 450/5000... Step: 27450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 451/5000... Step: 27460... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 451/5000... Step: 27470... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 451/5000... Step: 27480... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 451/5000... Step: 27490... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 451/5000... Step: 27500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 451/5000... Step: 27510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 452/5000... Step: 27520... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 452/5000... Step: 27530... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 452/5000... Step: 27540... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 452/5000... Step: 27550... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 452/5000... Step: 27560... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 452/5000... Step: 27570... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 453/5000... Step: 27580... Loss: 0.0785... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 453/5000... Step: 27590... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 453/5000... Step: 27600... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 453/5000... Step: 27610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 453/5000... Step: 27620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 453/5000... Step: 27630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 454/5000... Step: 27640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 454/5000... Step: 27650... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 454/5000... Step: 27660... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 454/5000... Step: 27670... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 454/5000... Step: 27680... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 454/5000... Step: 27690... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 455/5000... Step: 27700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 455/5000... Step: 27710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 455/5000... Step: 27720... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 455/5000... Step: 27730... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 455/5000... Step: 27740... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 455/5000... Step: 27750... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 456/5000... Step: 27760... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 456/5000... Step: 27770... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 456/5000... Step: 27780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 456/5000... Step: 27790... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 456/5000... Step: 27800... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 456/5000... Step: 27810... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 457/5000... Step: 27820... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 457/5000... Step: 27830... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 457/5000... Step: 27840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 457/5000... Step: 27850... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 457/5000... Step: 27860... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 457/5000... Step: 27870... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 458/5000... Step: 27880... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 458/5000... Step: 27890... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 458/5000... Step: 27900... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 458/5000... Step: 27910... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 458/5000... Step: 27920... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 458/5000... Step: 27930... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27960... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27980... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 459/5000... Step: 27990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 460/5000... Step: 28000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 460/5000... Step: 28010... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 460/5000... Step: 28020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 460/5000... Step: 28030... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 460/5000... Step: 28040... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 460/5000... Step: 28050... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 460/5000... Step: 28060... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 461/5000... Step: 28070... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 461/5000... Step: 28080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 461/5000... Step: 28090... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 461/5000... Step: 28100... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 461/5000... Step: 28110... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 461/5000... Step: 28120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 462/5000... Step: 28130... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 462/5000... Step: 28140... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 462/5000... Step: 28150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 462/5000... Step: 28160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 462/5000... Step: 28170... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 462/5000... Step: 28180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 463/5000... Step: 28190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 463/5000... Step: 28200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 463/5000... Step: 28210... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 463/5000... Step: 28220... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 463/5000... Step: 28230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 463/5000... Step: 28240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 464/5000... Step: 28250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 464/5000... Step: 28260... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 464/5000... Step: 28270... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 464/5000... Step: 28280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 464/5000... Step: 28290... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 464/5000... Step: 28300... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 465/5000... Step: 28310... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 465/5000... Step: 28320... Loss: 0.0785... Val Loss: 0.0788\n",
      "Epoch: 465/5000... Step: 28330... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 465/5000... Step: 28340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 465/5000... Step: 28350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 465/5000... Step: 28360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 466/5000... Step: 28370... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 466/5000... Step: 28380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 466/5000... Step: 28390... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 466/5000... Step: 28400... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 466/5000... Step: 28410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 466/5000... Step: 28420... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 467/5000... Step: 28430... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 467/5000... Step: 28440... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 467/5000... Step: 28450... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 467/5000... Step: 28460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 467/5000... Step: 28470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 467/5000... Step: 28480... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 468/5000... Step: 28490... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 468/5000... Step: 28500... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 468/5000... Step: 28510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 468/5000... Step: 28520... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 468/5000... Step: 28530... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 468/5000... Step: 28540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 469/5000... Step: 28550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 469/5000... Step: 28560... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 469/5000... Step: 28570... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 469/5000... Step: 28580... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 469/5000... Step: 28590... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 469/5000... Step: 28600... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 470/5000... Step: 28610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 470/5000... Step: 28620... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 470/5000... Step: 28630... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 470/5000... Step: 28640... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 470/5000... Step: 28650... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 470/5000... Step: 28660... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 470/5000... Step: 28670... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 471/5000... Step: 28680... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 471/5000... Step: 28690... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 471/5000... Step: 28700... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 471/5000... Step: 28710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 471/5000... Step: 28720... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 471/5000... Step: 28730... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 472/5000... Step: 28740... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 472/5000... Step: 28750... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 472/5000... Step: 28760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 472/5000... Step: 28770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 472/5000... Step: 28780... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 472/5000... Step: 28790... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 473/5000... Step: 28800... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 473/5000... Step: 28810... Loss: 0.0783... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 473/5000... Step: 28820... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 473/5000... Step: 28830... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 473/5000... Step: 28840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 473/5000... Step: 28850... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 474/5000... Step: 28860... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 474/5000... Step: 28870... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 474/5000... Step: 28880... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 474/5000... Step: 28890... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 474/5000... Step: 28900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 474/5000... Step: 28910... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 475/5000... Step: 28920... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 475/5000... Step: 28930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 475/5000... Step: 28940... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 475/5000... Step: 28950... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 475/5000... Step: 28960... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 475/5000... Step: 28970... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 476/5000... Step: 28980... Loss: 0.0788... Val Loss: 0.0786\n",
      "Epoch: 476/5000... Step: 28990... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 476/5000... Step: 29000... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 476/5000... Step: 29010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 476/5000... Step: 29020... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 476/5000... Step: 29030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 477/5000... Step: 29040... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 477/5000... Step: 29050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 477/5000... Step: 29060... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 477/5000... Step: 29070... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 477/5000... Step: 29080... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 477/5000... Step: 29090... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 478/5000... Step: 29100... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 478/5000... Step: 29110... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 478/5000... Step: 29120... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 478/5000... Step: 29130... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 478/5000... Step: 29140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 478/5000... Step: 29150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 479/5000... Step: 29160... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 479/5000... Step: 29170... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 479/5000... Step: 29180... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 479/5000... Step: 29190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 479/5000... Step: 29200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 479/5000... Step: 29210... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 480/5000... Step: 29220... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 480/5000... Step: 29230... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 480/5000... Step: 29240... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 480/5000... Step: 29250... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 480/5000... Step: 29260... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 480/5000... Step: 29270... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 480/5000... Step: 29280... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 481/5000... Step: 29290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 481/5000... Step: 29300... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 481/5000... Step: 29310... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 481/5000... Step: 29320... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 481/5000... Step: 29330... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 481/5000... Step: 29340... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 482/5000... Step: 29350... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 482/5000... Step: 29360... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 482/5000... Step: 29370... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 482/5000... Step: 29380... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 482/5000... Step: 29390... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 482/5000... Step: 29400... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29420... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29430... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29440... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29450... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 483/5000... Step: 29460... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 484/5000... Step: 29470... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 484/5000... Step: 29480... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 484/5000... Step: 29490... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 484/5000... Step: 29500... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 484/5000... Step: 29510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 484/5000... Step: 29520... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 485/5000... Step: 29530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 485/5000... Step: 29540... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 485/5000... Step: 29550... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 485/5000... Step: 29560... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 485/5000... Step: 29570... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 485/5000... Step: 29580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 486/5000... Step: 29590... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 486/5000... Step: 29600... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 486/5000... Step: 29610... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 486/5000... Step: 29620... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 486/5000... Step: 29630... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 486/5000... Step: 29640... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 487/5000... Step: 29650... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 487/5000... Step: 29660... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 487/5000... Step: 29670... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 487/5000... Step: 29680... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 487/5000... Step: 29690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 487/5000... Step: 29700... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 488/5000... Step: 29710... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 488/5000... Step: 29720... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 488/5000... Step: 29730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 488/5000... Step: 29740... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 488/5000... Step: 29750... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 488/5000... Step: 29760... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 489/5000... Step: 29770... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 489/5000... Step: 29780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 489/5000... Step: 29790... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 489/5000... Step: 29800... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 489/5000... Step: 29810... Loss: 0.0783... Val Loss: 0.0788\n",
      "Epoch: 489/5000... Step: 29820... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 490/5000... Step: 29830... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 490/5000... Step: 29840... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 490/5000... Step: 29850... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 490/5000... Step: 29860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 490/5000... Step: 29870... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 490/5000... Step: 29880... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 490/5000... Step: 29890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 491/5000... Step: 29900... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 491/5000... Step: 29910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 491/5000... Step: 29920... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 491/5000... Step: 29930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 491/5000... Step: 29940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 491/5000... Step: 29950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 492/5000... Step: 29960... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 492/5000... Step: 29970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 492/5000... Step: 29980... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 492/5000... Step: 29990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 492/5000... Step: 30000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 492/5000... Step: 30010... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 493/5000... Step: 30020... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 493/5000... Step: 30030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 493/5000... Step: 30040... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 493/5000... Step: 30050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 493/5000... Step: 30060... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 493/5000... Step: 30070... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30090... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30100... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30110... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 494/5000... Step: 30130... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 495/5000... Step: 30140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 495/5000... Step: 30150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 495/5000... Step: 30160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 495/5000... Step: 30170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 495/5000... Step: 30180... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 495/5000... Step: 30190... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 496/5000... Step: 30200... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 496/5000... Step: 30210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 496/5000... Step: 30220... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 496/5000... Step: 30230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 496/5000... Step: 30240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 496/5000... Step: 30250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30260... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30270... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30280... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30300... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 497/5000... Step: 30310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 498/5000... Step: 30320... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 498/5000... Step: 30330... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 498/5000... Step: 30340... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 498/5000... Step: 30350... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 498/5000... Step: 30360... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 498/5000... Step: 30370... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30380... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30400... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30410... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30420... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 499/5000... Step: 30430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 500/5000... Step: 30440... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 500/5000... Step: 30450... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 500/5000... Step: 30460... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 500/5000... Step: 30470... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 500/5000... Step: 30480... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 500/5000... Step: 30490... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 500/5000... Step: 30500... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 501/5000... Step: 30510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 501/5000... Step: 30520... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 501/5000... Step: 30530... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 501/5000... Step: 30540... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 501/5000... Step: 30550... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 501/5000... Step: 30560... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 502/5000... Step: 30570... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 502/5000... Step: 30580... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 502/5000... Step: 30590... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 502/5000... Step: 30600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 502/5000... Step: 30610... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 502/5000... Step: 30620... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 503/5000... Step: 30630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 503/5000... Step: 30640... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 503/5000... Step: 30650... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 503/5000... Step: 30660... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 503/5000... Step: 30670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 503/5000... Step: 30680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30700... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30710... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30720... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 504/5000... Step: 30740... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 505/5000... Step: 30750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 505/5000... Step: 30760... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 505/5000... Step: 30770... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 505/5000... Step: 30780... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 505/5000... Step: 30790... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 505/5000... Step: 30800... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 506/5000... Step: 30810... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 506/5000... Step: 30820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 506/5000... Step: 30830... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 506/5000... Step: 30840... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 506/5000... Step: 30850... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 506/5000... Step: 30860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30870... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30880... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30910... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 507/5000... Step: 30920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30930... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30960... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 508/5000... Step: 30980... Loss: 0.0785... Val Loss: 0.0788\n",
      "Epoch: 509/5000... Step: 30990... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 509/5000... Step: 31000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 509/5000... Step: 31010... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 509/5000... Step: 31020... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 509/5000... Step: 31030... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 509/5000... Step: 31040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 510/5000... Step: 31050... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 510/5000... Step: 31060... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 510/5000... Step: 31070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 510/5000... Step: 31080... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 510/5000... Step: 31090... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 510/5000... Step: 31100... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 510/5000... Step: 31110... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 511/5000... Step: 31120... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 511/5000... Step: 31130... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 511/5000... Step: 31140... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 511/5000... Step: 31150... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 511/5000... Step: 31160... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 511/5000... Step: 31170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 512/5000... Step: 31180... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 512/5000... Step: 31190... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 512/5000... Step: 31200... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 512/5000... Step: 31210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 512/5000... Step: 31220... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 512/5000... Step: 31230... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 513/5000... Step: 31240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 513/5000... Step: 31250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 513/5000... Step: 31260... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 513/5000... Step: 31270... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513/5000... Step: 31280... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 513/5000... Step: 31290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 514/5000... Step: 31300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 514/5000... Step: 31310... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 514/5000... Step: 31320... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 514/5000... Step: 31330... Loss: 0.0783... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1179/5000... Step: 71860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1179/5000... Step: 71870... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1179/5000... Step: 71880... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1179/5000... Step: 71890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1179/5000... Step: 71900... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1179/5000... Step: 71910... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1180/5000... Step: 71920... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1180/5000... Step: 71930... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1180/5000... Step: 71940... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1180/5000... Step: 71950... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1180/5000... Step: 71960... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1180/5000... Step: 71970... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1180/5000... Step: 71980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1181/5000... Step: 71990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1181/5000... Step: 72000... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1181/5000... Step: 72010... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1181/5000... Step: 72020... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1181/5000... Step: 72030... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1181/5000... Step: 72040... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1182/5000... Step: 72050... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1182/5000... Step: 72060... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1182/5000... Step: 72070... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1182/5000... Step: 72080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1182/5000... Step: 72090... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1182/5000... Step: 72100... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1183/5000... Step: 72110... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1183/5000... Step: 72120... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1183/5000... Step: 72130... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1183/5000... Step: 72140... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1183/5000... Step: 72150... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1183/5000... Step: 72160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1184/5000... Step: 72170... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1184/5000... Step: 72180... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1184/5000... Step: 72190... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1184/5000... Step: 72200... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1184/5000... Step: 72210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1184/5000... Step: 72220... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1185/5000... Step: 72230... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1185/5000... Step: 72240... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1185/5000... Step: 72250... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1185/5000... Step: 72260... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1185/5000... Step: 72270... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1185/5000... Step: 72280... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1186/5000... Step: 72290... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1186/5000... Step: 72300... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1186/5000... Step: 72310... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1186/5000... Step: 72320... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1186/5000... Step: 72330... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1186/5000... Step: 72340... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1187/5000... Step: 72350... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1187/5000... Step: 72360... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1187/5000... Step: 72370... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1187/5000... Step: 72380... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1187/5000... Step: 72390... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1187/5000... Step: 72400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1188/5000... Step: 72410... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1188/5000... Step: 72420... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1188/5000... Step: 72430... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1188/5000... Step: 72440... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1188/5000... Step: 72450... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1188/5000... Step: 72460... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1189/5000... Step: 72470... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1189/5000... Step: 72480... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1189/5000... Step: 72490... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1189/5000... Step: 72500... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1189/5000... Step: 72510... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1189/5000... Step: 72520... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1190/5000... Step: 72530... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1190/5000... Step: 72540... Loss: 0.0788... Val Loss: 0.0787\n",
      "Epoch: 1190/5000... Step: 72550... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1190/5000... Step: 72560... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1190/5000... Step: 72570... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1190/5000... Step: 72580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1190/5000... Step: 72590... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1191/5000... Step: 72600... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1191/5000... Step: 72610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1191/5000... Step: 72620... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1191/5000... Step: 72630... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1191/5000... Step: 72640... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1191/5000... Step: 72650... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1192/5000... Step: 72660... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1192/5000... Step: 72670... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1192/5000... Step: 72680... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1192/5000... Step: 72690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1192/5000... Step: 72700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1192/5000... Step: 72710... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1193/5000... Step: 72720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1193/5000... Step: 72730... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1193/5000... Step: 72740... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1193/5000... Step: 72750... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1193/5000... Step: 72760... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1193/5000... Step: 72770... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1194/5000... Step: 72780... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1194/5000... Step: 72790... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1194/5000... Step: 72800... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1194/5000... Step: 72810... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1194/5000... Step: 72820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1194/5000... Step: 72830... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1195/5000... Step: 72840... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1195/5000... Step: 72850... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1195/5000... Step: 72860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1195/5000... Step: 72870... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1195/5000... Step: 72880... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1195/5000... Step: 72890... Loss: 0.0782... Val Loss: 0.0788\n",
      "Epoch: 1196/5000... Step: 72900... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1196/5000... Step: 72910... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1196/5000... Step: 72920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1196/5000... Step: 72930... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1196/5000... Step: 72940... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1196/5000... Step: 72950... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1197/5000... Step: 72960... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 1197/5000... Step: 72970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1197/5000... Step: 72980... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1197/5000... Step: 72990... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1197/5000... Step: 73000... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1197/5000... Step: 73010... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1198/5000... Step: 73020... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1198/5000... Step: 73030... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1198/5000... Step: 73040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1198/5000... Step: 73050... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1198/5000... Step: 73060... Loss: 0.0783... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1198/5000... Step: 73070... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1199/5000... Step: 73080... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1199/5000... Step: 73090... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1199/5000... Step: 73100... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1199/5000... Step: 73110... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1199/5000... Step: 73120... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1199/5000... Step: 73130... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1200/5000... Step: 73140... Loss: 0.0778... Val Loss: 0.0786\n",
      "Epoch: 1200/5000... Step: 73150... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1200/5000... Step: 73160... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1200/5000... Step: 73170... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1200/5000... Step: 73180... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1200/5000... Step: 73190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1200/5000... Step: 73200... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1201/5000... Step: 73210... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1201/5000... Step: 73220... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1201/5000... Step: 73230... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1201/5000... Step: 73240... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1201/5000... Step: 73250... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1201/5000... Step: 73260... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1202/5000... Step: 73270... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1202/5000... Step: 73280... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1202/5000... Step: 73290... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1202/5000... Step: 73300... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1202/5000... Step: 73310... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1202/5000... Step: 73320... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1203/5000... Step: 73330... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1203/5000... Step: 73340... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1203/5000... Step: 73350... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1203/5000... Step: 73360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1203/5000... Step: 73370... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1203/5000... Step: 73380... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1204/5000... Step: 73390... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1204/5000... Step: 73400... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1204/5000... Step: 73410... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1204/5000... Step: 73420... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1204/5000... Step: 73430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1204/5000... Step: 73440... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1205/5000... Step: 73450... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1205/5000... Step: 73460... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1205/5000... Step: 73470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1205/5000... Step: 73480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1205/5000... Step: 73490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1205/5000... Step: 73500... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1206/5000... Step: 73510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1206/5000... Step: 73520... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1206/5000... Step: 73530... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1206/5000... Step: 73540... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1206/5000... Step: 73550... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1206/5000... Step: 73560... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1207/5000... Step: 73570... Loss: 0.0786... Val Loss: 0.0785\n",
      "Epoch: 1207/5000... Step: 73580... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1207/5000... Step: 73590... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1207/5000... Step: 73600... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1207/5000... Step: 73610... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1207/5000... Step: 73620... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1208/5000... Step: 73630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1208/5000... Step: 73640... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1208/5000... Step: 73650... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1208/5000... Step: 73660... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1208/5000... Step: 73670... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1208/5000... Step: 73680... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1209/5000... Step: 73690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1209/5000... Step: 73700... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1209/5000... Step: 73710... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1209/5000... Step: 73720... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1209/5000... Step: 73730... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1209/5000... Step: 73740... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1210/5000... Step: 73750... Loss: 0.0778... Val Loss: 0.0786\n",
      "Epoch: 1210/5000... Step: 73760... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1210/5000... Step: 73770... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1210/5000... Step: 73780... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1210/5000... Step: 73790... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1210/5000... Step: 73800... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1210/5000... Step: 73810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1211/5000... Step: 73820... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1211/5000... Step: 73830... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1211/5000... Step: 73840... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1211/5000... Step: 73850... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1211/5000... Step: 73860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1211/5000... Step: 73870... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1212/5000... Step: 73880... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1212/5000... Step: 73890... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1212/5000... Step: 73900... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1212/5000... Step: 73910... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1212/5000... Step: 73920... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1212/5000... Step: 73930... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1213/5000... Step: 73940... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1213/5000... Step: 73950... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1213/5000... Step: 73960... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1213/5000... Step: 73970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1213/5000... Step: 73980... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1213/5000... Step: 73990... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1214/5000... Step: 74000... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1214/5000... Step: 74010... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1214/5000... Step: 74020... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1214/5000... Step: 74030... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1214/5000... Step: 74040... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1214/5000... Step: 74050... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1215/5000... Step: 74060... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1215/5000... Step: 74070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1215/5000... Step: 74080... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1215/5000... Step: 74090... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1215/5000... Step: 74100... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1215/5000... Step: 74110... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1216/5000... Step: 74120... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1216/5000... Step: 74130... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1216/5000... Step: 74140... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1216/5000... Step: 74150... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1216/5000... Step: 74160... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1216/5000... Step: 74170... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1217/5000... Step: 74180... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1217/5000... Step: 74190... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1217/5000... Step: 74200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1217/5000... Step: 74210... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1217/5000... Step: 74220... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1217/5000... Step: 74230... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1218/5000... Step: 74240... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1218/5000... Step: 74250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1218/5000... Step: 74260... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1218/5000... Step: 74270... Loss: 0.0781... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1218/5000... Step: 74280... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1218/5000... Step: 74290... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1219/5000... Step: 74300... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1219/5000... Step: 74310... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1219/5000... Step: 74320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1219/5000... Step: 74330... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1219/5000... Step: 74340... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1219/5000... Step: 74350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1220/5000... Step: 74360... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1220/5000... Step: 74370... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1220/5000... Step: 74380... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1220/5000... Step: 74390... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1220/5000... Step: 74400... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1220/5000... Step: 74410... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1220/5000... Step: 74420... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1221/5000... Step: 74430... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1221/5000... Step: 74440... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1221/5000... Step: 74450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1221/5000... Step: 74460... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1221/5000... Step: 74470... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1221/5000... Step: 74480... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1222/5000... Step: 74490... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1222/5000... Step: 74500... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1222/5000... Step: 74510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1222/5000... Step: 74520... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1222/5000... Step: 74530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1222/5000... Step: 74540... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1223/5000... Step: 74550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1223/5000... Step: 74560... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1223/5000... Step: 74570... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1223/5000... Step: 74580... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1223/5000... Step: 74590... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1223/5000... Step: 74600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1224/5000... Step: 74610... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1224/5000... Step: 74620... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1224/5000... Step: 74630... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1224/5000... Step: 74640... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1224/5000... Step: 74650... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1224/5000... Step: 74660... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1225/5000... Step: 74670... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1225/5000... Step: 74680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1225/5000... Step: 74690... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1225/5000... Step: 74700... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1225/5000... Step: 74710... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1225/5000... Step: 74720... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74730... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74740... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74760... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74770... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1226/5000... Step: 74780... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1227/5000... Step: 74790... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1227/5000... Step: 74800... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1227/5000... Step: 74810... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1227/5000... Step: 74820... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1227/5000... Step: 74830... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1227/5000... Step: 74840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1228/5000... Step: 74850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1228/5000... Step: 74860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1228/5000... Step: 74870... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1228/5000... Step: 74880... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1228/5000... Step: 74890... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1228/5000... Step: 74900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1229/5000... Step: 74910... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1229/5000... Step: 74920... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1229/5000... Step: 74930... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1229/5000... Step: 74940... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1229/5000... Step: 74950... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1229/5000... Step: 74960... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1230/5000... Step: 74970... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1230/5000... Step: 74980... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1230/5000... Step: 74990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1230/5000... Step: 75000... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1230/5000... Step: 75010... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1230/5000... Step: 75020... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1230/5000... Step: 75030... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1231/5000... Step: 75040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1231/5000... Step: 75050... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1231/5000... Step: 75060... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1231/5000... Step: 75070... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1231/5000... Step: 75080... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1231/5000... Step: 75090... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1232/5000... Step: 75100... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1232/5000... Step: 75110... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1232/5000... Step: 75120... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1232/5000... Step: 75130... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1232/5000... Step: 75140... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1232/5000... Step: 75150... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1233/5000... Step: 75160... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1233/5000... Step: 75170... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1233/5000... Step: 75180... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1233/5000... Step: 75190... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1233/5000... Step: 75200... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1233/5000... Step: 75210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1234/5000... Step: 75220... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1234/5000... Step: 75230... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1234/5000... Step: 75240... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1234/5000... Step: 75250... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1234/5000... Step: 75260... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1234/5000... Step: 75270... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1235/5000... Step: 75280... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1235/5000... Step: 75290... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1235/5000... Step: 75300... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1235/5000... Step: 75310... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1235/5000... Step: 75320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1235/5000... Step: 75330... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1236/5000... Step: 75340... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1236/5000... Step: 75350... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1236/5000... Step: 75360... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1236/5000... Step: 75370... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1236/5000... Step: 75380... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1236/5000... Step: 75390... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1237/5000... Step: 75400... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1237/5000... Step: 75410... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1237/5000... Step: 75420... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1237/5000... Step: 75430... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1237/5000... Step: 75440... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1237/5000... Step: 75450... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1238/5000... Step: 75460... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1238/5000... Step: 75470... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1238/5000... Step: 75480... Loss: 0.0784... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1238/5000... Step: 75490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1238/5000... Step: 75500... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1238/5000... Step: 75510... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1239/5000... Step: 75520... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1239/5000... Step: 75530... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1239/5000... Step: 75540... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1239/5000... Step: 75550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1239/5000... Step: 75560... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1239/5000... Step: 75570... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1240/5000... Step: 75580... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1240/5000... Step: 75590... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1240/5000... Step: 75600... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1240/5000... Step: 75610... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1240/5000... Step: 75620... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1240/5000... Step: 75630... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1240/5000... Step: 75640... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1241/5000... Step: 75650... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1241/5000... Step: 75660... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1241/5000... Step: 75670... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1241/5000... Step: 75680... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1241/5000... Step: 75690... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1241/5000... Step: 75700... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1242/5000... Step: 75710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1242/5000... Step: 75720... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1242/5000... Step: 75730... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1242/5000... Step: 75740... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1242/5000... Step: 75750... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1242/5000... Step: 75760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1243/5000... Step: 75770... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1243/5000... Step: 75780... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1243/5000... Step: 75790... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1243/5000... Step: 75800... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1243/5000... Step: 75810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1243/5000... Step: 75820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1244/5000... Step: 75830... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1244/5000... Step: 75840... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1244/5000... Step: 75850... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1244/5000... Step: 75860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1244/5000... Step: 75870... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1244/5000... Step: 75880... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1245/5000... Step: 75890... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1245/5000... Step: 75900... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1245/5000... Step: 75910... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1245/5000... Step: 75920... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1245/5000... Step: 75930... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1245/5000... Step: 75940... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1246/5000... Step: 75950... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1246/5000... Step: 75960... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1246/5000... Step: 75970... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1246/5000... Step: 75980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1246/5000... Step: 75990... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1246/5000... Step: 76000... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1247/5000... Step: 76010... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1247/5000... Step: 76020... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1247/5000... Step: 76030... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1247/5000... Step: 76040... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1247/5000... Step: 76050... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1247/5000... Step: 76060... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1248/5000... Step: 76070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1248/5000... Step: 76080... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1248/5000... Step: 76090... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1248/5000... Step: 76100... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1248/5000... Step: 76110... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1248/5000... Step: 76120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1249/5000... Step: 76130... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1249/5000... Step: 76140... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1249/5000... Step: 76150... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1249/5000... Step: 76160... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1249/5000... Step: 76170... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1249/5000... Step: 76180... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1250/5000... Step: 76190... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1250/5000... Step: 76200... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1250/5000... Step: 76210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1250/5000... Step: 76220... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1250/5000... Step: 76230... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1250/5000... Step: 76240... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1250/5000... Step: 76250... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1251/5000... Step: 76260... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1251/5000... Step: 76270... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1251/5000... Step: 76280... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1251/5000... Step: 76290... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1251/5000... Step: 76300... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1251/5000... Step: 76310... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1252/5000... Step: 76320... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1252/5000... Step: 76330... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1252/5000... Step: 76340... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1252/5000... Step: 76350... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1252/5000... Step: 76360... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1252/5000... Step: 76370... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1253/5000... Step: 76380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1253/5000... Step: 76390... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1253/5000... Step: 76400... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1253/5000... Step: 76410... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1253/5000... Step: 76420... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1253/5000... Step: 76430... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1254/5000... Step: 76440... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1254/5000... Step: 76450... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1254/5000... Step: 76460... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1254/5000... Step: 76470... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1254/5000... Step: 76480... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1254/5000... Step: 76490... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1255/5000... Step: 76500... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1255/5000... Step: 76510... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1255/5000... Step: 76520... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1255/5000... Step: 76530... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1255/5000... Step: 76540... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1255/5000... Step: 76550... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1256/5000... Step: 76560... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1256/5000... Step: 76570... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1256/5000... Step: 76580... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1256/5000... Step: 76590... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1256/5000... Step: 76600... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1256/5000... Step: 76610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1257/5000... Step: 76620... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1257/5000... Step: 76630... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1257/5000... Step: 76640... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1257/5000... Step: 76650... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1257/5000... Step: 76660... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1257/5000... Step: 76670... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1258/5000... Step: 76680... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1258/5000... Step: 76690... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1258/5000... Step: 76700... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1258/5000... Step: 76710... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1258/5000... Step: 76720... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1258/5000... Step: 76730... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1259/5000... Step: 76740... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1259/5000... Step: 76750... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1259/5000... Step: 76760... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1259/5000... Step: 76770... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1259/5000... Step: 76780... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1259/5000... Step: 76790... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1260/5000... Step: 76800... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1260/5000... Step: 76810... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1260/5000... Step: 76820... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1260/5000... Step: 76830... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1260/5000... Step: 76840... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1260/5000... Step: 76850... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1260/5000... Step: 76860... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1261/5000... Step: 76870... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1261/5000... Step: 76880... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1261/5000... Step: 76890... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1261/5000... Step: 76900... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1261/5000... Step: 76910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1261/5000... Step: 76920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1262/5000... Step: 76930... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1262/5000... Step: 76940... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1262/5000... Step: 76950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1262/5000... Step: 76960... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1262/5000... Step: 76970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1262/5000... Step: 76980... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1263/5000... Step: 76990... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1263/5000... Step: 77000... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1263/5000... Step: 77010... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1263/5000... Step: 77020... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1263/5000... Step: 77030... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1263/5000... Step: 77040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1264/5000... Step: 77050... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1264/5000... Step: 77060... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1264/5000... Step: 77070... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1264/5000... Step: 77080... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1264/5000... Step: 77090... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1264/5000... Step: 77100... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1265/5000... Step: 77110... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1265/5000... Step: 77120... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1265/5000... Step: 77130... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1265/5000... Step: 77140... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1265/5000... Step: 77150... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1265/5000... Step: 77160... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1266/5000... Step: 77170... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1266/5000... Step: 77180... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1266/5000... Step: 77190... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1266/5000... Step: 77200... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1266/5000... Step: 77210... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1266/5000... Step: 77220... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1267/5000... Step: 77230... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1267/5000... Step: 77240... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1267/5000... Step: 77250... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1267/5000... Step: 77260... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1267/5000... Step: 77270... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1267/5000... Step: 77280... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1268/5000... Step: 77290... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1268/5000... Step: 77300... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1268/5000... Step: 77310... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1268/5000... Step: 77320... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1268/5000... Step: 77330... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1268/5000... Step: 77340... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1269/5000... Step: 77350... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1269/5000... Step: 77360... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1269/5000... Step: 77370... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1269/5000... Step: 77380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1269/5000... Step: 77390... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1269/5000... Step: 77400... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77410... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77420... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77430... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77440... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77450... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77460... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1270/5000... Step: 77470... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1271/5000... Step: 77480... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1271/5000... Step: 77490... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1271/5000... Step: 77500... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1271/5000... Step: 77510... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1271/5000... Step: 77520... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1271/5000... Step: 77530... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1272/5000... Step: 77540... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1272/5000... Step: 77550... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1272/5000... Step: 77560... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1272/5000... Step: 77570... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1272/5000... Step: 77580... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1272/5000... Step: 77590... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1273/5000... Step: 77600... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1273/5000... Step: 77610... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1273/5000... Step: 77620... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1273/5000... Step: 77630... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1273/5000... Step: 77640... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1273/5000... Step: 77650... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1274/5000... Step: 77660... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1274/5000... Step: 77670... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1274/5000... Step: 77680... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1274/5000... Step: 77690... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1274/5000... Step: 77700... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1274/5000... Step: 77710... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1275/5000... Step: 77720... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1275/5000... Step: 77730... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1275/5000... Step: 77740... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1275/5000... Step: 77750... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1275/5000... Step: 77760... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1275/5000... Step: 77770... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1276/5000... Step: 77780... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1276/5000... Step: 77790... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1276/5000... Step: 77800... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1276/5000... Step: 77810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1276/5000... Step: 77820... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1276/5000... Step: 77830... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1277/5000... Step: 77840... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1277/5000... Step: 77850... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1277/5000... Step: 77860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1277/5000... Step: 77870... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1277/5000... Step: 77880... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1277/5000... Step: 77890... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1278/5000... Step: 77900... Loss: 0.0784... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1278/5000... Step: 77910... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1278/5000... Step: 77920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1278/5000... Step: 77930... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1278/5000... Step: 77940... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1278/5000... Step: 77950... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1279/5000... Step: 77960... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1279/5000... Step: 77970... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1279/5000... Step: 77980... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1279/5000... Step: 77990... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1279/5000... Step: 78000... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1279/5000... Step: 78010... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1280/5000... Step: 78020... Loss: 0.0778... Val Loss: 0.0787\n",
      "Epoch: 1280/5000... Step: 78030... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1280/5000... Step: 78040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1280/5000... Step: 78050... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1280/5000... Step: 78060... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1280/5000... Step: 78070... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1280/5000... Step: 78080... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1281/5000... Step: 78090... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1281/5000... Step: 78100... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1281/5000... Step: 78110... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1281/5000... Step: 78120... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1281/5000... Step: 78130... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1281/5000... Step: 78140... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1282/5000... Step: 78150... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1282/5000... Step: 78160... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1282/5000... Step: 78170... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1282/5000... Step: 78180... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1282/5000... Step: 78190... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1282/5000... Step: 78200... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1283/5000... Step: 78210... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1283/5000... Step: 78220... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1283/5000... Step: 78230... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1283/5000... Step: 78240... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1283/5000... Step: 78250... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1283/5000... Step: 78260... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1284/5000... Step: 78270... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1284/5000... Step: 78280... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1284/5000... Step: 78290... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1284/5000... Step: 78300... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1284/5000... Step: 78310... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1284/5000... Step: 78320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78330... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78340... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78360... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78370... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1285/5000... Step: 78380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1286/5000... Step: 78390... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1286/5000... Step: 78400... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1286/5000... Step: 78410... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1286/5000... Step: 78420... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1286/5000... Step: 78430... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1286/5000... Step: 78440... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1287/5000... Step: 78450... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1287/5000... Step: 78460... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1287/5000... Step: 78470... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1287/5000... Step: 78480... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1287/5000... Step: 78490... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1287/5000... Step: 78500... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1288/5000... Step: 78510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1288/5000... Step: 78520... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1288/5000... Step: 78530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1288/5000... Step: 78540... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1288/5000... Step: 78550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1288/5000... Step: 78560... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1289/5000... Step: 78570... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1289/5000... Step: 78580... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1289/5000... Step: 78590... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1289/5000... Step: 78600... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1289/5000... Step: 78610... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1289/5000... Step: 78620... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1290/5000... Step: 78630... Loss: 0.0777... Val Loss: 0.0787\n",
      "Epoch: 1290/5000... Step: 78640... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1290/5000... Step: 78650... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1290/5000... Step: 78660... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1290/5000... Step: 78670... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1290/5000... Step: 78680... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1290/5000... Step: 78690... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1291/5000... Step: 78700... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1291/5000... Step: 78710... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1291/5000... Step: 78720... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1291/5000... Step: 78730... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1291/5000... Step: 78740... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1291/5000... Step: 78750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1292/5000... Step: 78760... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1292/5000... Step: 78770... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1292/5000... Step: 78780... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1292/5000... Step: 78790... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1292/5000... Step: 78800... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1292/5000... Step: 78810... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1293/5000... Step: 78820... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1293/5000... Step: 78830... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1293/5000... Step: 78840... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1293/5000... Step: 78850... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1293/5000... Step: 78860... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1293/5000... Step: 78870... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1294/5000... Step: 78880... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1294/5000... Step: 78890... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1294/5000... Step: 78900... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1294/5000... Step: 78910... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1294/5000... Step: 78920... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1294/5000... Step: 78930... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1295/5000... Step: 78940... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1295/5000... Step: 78950... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1295/5000... Step: 78960... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1295/5000... Step: 78970... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1295/5000... Step: 78980... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1295/5000... Step: 78990... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1296/5000... Step: 79000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1296/5000... Step: 79010... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1296/5000... Step: 79020... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1296/5000... Step: 79030... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1296/5000... Step: 79040... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1296/5000... Step: 79050... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1297/5000... Step: 79060... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1297/5000... Step: 79070... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1297/5000... Step: 79080... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1297/5000... Step: 79090... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1297/5000... Step: 79100... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1297/5000... Step: 79110... Loss: 0.0783... Val Loss: 0.0786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1298/5000... Step: 79120... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1298/5000... Step: 79130... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1298/5000... Step: 79140... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1298/5000... Step: 79150... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1298/5000... Step: 79160... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1298/5000... Step: 79170... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1299/5000... Step: 79180... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1299/5000... Step: 79190... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1299/5000... Step: 79200... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1299/5000... Step: 79210... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1299/5000... Step: 79220... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1299/5000... Step: 79230... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79240... Loss: 0.0777... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79250... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1300/5000... Step: 79260... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79270... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79280... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79290... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1300/5000... Step: 79300... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1301/5000... Step: 79310... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1301/5000... Step: 79320... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1301/5000... Step: 79330... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1301/5000... Step: 79340... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1301/5000... Step: 79350... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1301/5000... Step: 79360... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1302/5000... Step: 79370... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1302/5000... Step: 79380... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1302/5000... Step: 79390... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1302/5000... Step: 79400... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1302/5000... Step: 79410... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1302/5000... Step: 79420... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1303/5000... Step: 79430... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1303/5000... Step: 79440... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1303/5000... Step: 79450... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1303/5000... Step: 79460... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1303/5000... Step: 79470... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1303/5000... Step: 79480... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1304/5000... Step: 79490... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1304/5000... Step: 79500... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1304/5000... Step: 79510... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1304/5000... Step: 79520... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1304/5000... Step: 79530... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1304/5000... Step: 79540... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1305/5000... Step: 79550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1305/5000... Step: 79560... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1305/5000... Step: 79570... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1305/5000... Step: 79580... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1305/5000... Step: 79590... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1305/5000... Step: 79600... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1306/5000... Step: 79610... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1306/5000... Step: 79620... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1306/5000... Step: 79630... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1306/5000... Step: 79640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1306/5000... Step: 79650... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1306/5000... Step: 79660... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1307/5000... Step: 79670... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1307/5000... Step: 79680... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1307/5000... Step: 79690... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1307/5000... Step: 79700... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1307/5000... Step: 79710... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1307/5000... Step: 79720... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79730... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79740... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79760... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79770... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1308/5000... Step: 79780... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1309/5000... Step: 79790... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1309/5000... Step: 79800... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1309/5000... Step: 79810... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1309/5000... Step: 79820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1309/5000... Step: 79830... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1309/5000... Step: 79840... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1310/5000... Step: 79850... Loss: 0.0777... Val Loss: 0.0786\n",
      "Epoch: 1310/5000... Step: 79860... Loss: 0.0787... Val Loss: 0.0787\n",
      "Epoch: 1310/5000... Step: 79870... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1310/5000... Step: 79880... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1310/5000... Step: 79890... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1310/5000... Step: 79900... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1310/5000... Step: 79910... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1311/5000... Step: 79920... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1311/5000... Step: 79930... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1311/5000... Step: 79940... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1311/5000... Step: 79950... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1311/5000... Step: 79960... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1311/5000... Step: 79970... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1312/5000... Step: 79980... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1312/5000... Step: 79990... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1312/5000... Step: 80000... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1312/5000... Step: 80010... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1312/5000... Step: 80020... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1312/5000... Step: 80030... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1313/5000... Step: 80040... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1313/5000... Step: 80050... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1313/5000... Step: 80060... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1313/5000... Step: 80070... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1313/5000... Step: 80080... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1313/5000... Step: 80090... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1314/5000... Step: 80100... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1314/5000... Step: 80110... Loss: 0.0779... Val Loss: 0.0786\n",
      "Epoch: 1314/5000... Step: 80120... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1314/5000... Step: 80130... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1314/5000... Step: 80140... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1314/5000... Step: 80150... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1315/5000... Step: 80160... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1315/5000... Step: 80170... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1315/5000... Step: 80180... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1315/5000... Step: 80190... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1315/5000... Step: 80200... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1315/5000... Step: 80210... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1316/5000... Step: 80220... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1316/5000... Step: 80230... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1316/5000... Step: 80240... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1316/5000... Step: 80250... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1316/5000... Step: 80260... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1316/5000... Step: 80270... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1317/5000... Step: 80280... Loss: 0.0787... Val Loss: 0.0786\n",
      "Epoch: 1317/5000... Step: 80290... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1317/5000... Step: 80300... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1317/5000... Step: 80310... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1317/5000... Step: 80320... Loss: 0.0782... Val Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1317/5000... Step: 80330... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1318/5000... Step: 80340... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1318/5000... Step: 80350... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1318/5000... Step: 80360... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1318/5000... Step: 80370... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1318/5000... Step: 80380... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1318/5000... Step: 80390... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1319/5000... Step: 80400... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1319/5000... Step: 80410... Loss: 0.0780... Val Loss: 0.0786\n",
      "Epoch: 1319/5000... Step: 80420... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1319/5000... Step: 80430... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1319/5000... Step: 80440... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1319/5000... Step: 80450... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1320/5000... Step: 80460... Loss: 0.0777... Val Loss: 0.0787\n",
      "Epoch: 1320/5000... Step: 80470... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1320/5000... Step: 80480... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1320/5000... Step: 80490... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1320/5000... Step: 80500... Loss: 0.0778... Val Loss: 0.0786\n",
      "Epoch: 1320/5000... Step: 80510... Loss: 0.0785... Val Loss: 0.0786\n",
      "Epoch: 1320/5000... Step: 80520... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1321/5000... Step: 80530... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1321/5000... Step: 80540... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1321/5000... Step: 80550... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1321/5000... Step: 80560... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1321/5000... Step: 80570... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1321/5000... Step: 80580... Loss: 0.0785... Val Loss: 0.0787\n",
      "Epoch: 1322/5000... Step: 80590... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1322/5000... Step: 80600... Loss: 0.0779... Val Loss: 0.0787\n",
      "Epoch: 1322/5000... Step: 80610... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1322/5000... Step: 80620... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1322/5000... Step: 80630... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1322/5000... Step: 80640... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1323/5000... Step: 80650... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1323/5000... Step: 80660... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1323/5000... Step: 80670... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1323/5000... Step: 80680... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1323/5000... Step: 80690... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1323/5000... Step: 80700... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1324/5000... Step: 80710... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1324/5000... Step: 80720... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1324/5000... Step: 80730... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1324/5000... Step: 80740... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1324/5000... Step: 80750... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1324/5000... Step: 80760... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80770... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80780... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80790... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80800... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80810... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1325/5000... Step: 80820... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1326/5000... Step: 80830... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1326/5000... Step: 80840... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1326/5000... Step: 80850... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1326/5000... Step: 80860... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1326/5000... Step: 80870... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1326/5000... Step: 80880... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1327/5000... Step: 80890... Loss: 0.0786... Val Loss: 0.0787\n",
      "Epoch: 1327/5000... Step: 80900... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1327/5000... Step: 80910... Loss: 0.0782... Val Loss: 0.0786\n",
      "Epoch: 1327/5000... Step: 80920... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1327/5000... Step: 80930... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1327/5000... Step: 80940... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1328/5000... Step: 80950... Loss: 0.0784... Val Loss: 0.0787\n",
      "Epoch: 1328/5000... Step: 80960... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1328/5000... Step: 80970... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1328/5000... Step: 80980... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1328/5000... Step: 80990... Loss: 0.0782... Val Loss: 0.0787\n",
      "Epoch: 1328/5000... Step: 81000... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1329/5000... Step: 81010... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1329/5000... Step: 81020... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1329/5000... Step: 81030... Loss: 0.0781... Val Loss: 0.0786\n",
      "Epoch: 1329/5000... Step: 81040... Loss: 0.0783... Val Loss: 0.0787\n",
      "Epoch: 1329/5000... Step: 81050... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1329/5000... Step: 81060... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1330/5000... Step: 81070... Loss: 0.0776... Val Loss: 0.0787\n",
      "Epoch: 1330/5000... Step: 81080... Loss: 0.0786... Val Loss: 0.0786\n",
      "Epoch: 1330/5000... Step: 81090... Loss: 0.0783... Val Loss: 0.0786\n",
      "Epoch: 1330/5000... Step: 81100... Loss: 0.0781... Val Loss: 0.0787\n",
      "Epoch: 1330/5000... Step: 81110... Loss: 0.0780... Val Loss: 0.0787\n",
      "Epoch: 1330/5000... Step: 81120... Loss: 0.0784... Val Loss: 0.0786\n",
      "Epoch: 1330/5000... Step: 81130... Loss: 0.0781... Val Loss: 0.0785\n",
      "Epoch: 1331/5000... Step: 81140... Loss: 0.0779... Val Loss: 0.0781\n",
      "Epoch: 1331/5000... Step: 81150... Loss: 0.0771... Val Loss: 0.0774\n",
      "Epoch: 1331/5000... Step: 81160... Loss: 0.0769... Val Loss: 0.0770\n",
      "Epoch: 1331/5000... Step: 81170... Loss: 0.0760... Val Loss: 0.0769\n",
      "Epoch: 1331/5000... Step: 81180... Loss: 0.0762... Val Loss: 0.0763\n",
      "Epoch: 1331/5000... Step: 81190... Loss: 0.0758... Val Loss: 0.0760\n",
      "Epoch: 1332/5000... Step: 81200... Loss: 0.0757... Val Loss: 0.0758\n",
      "Epoch: 1332/5000... Step: 81210... Loss: 0.0752... Val Loss: 0.0757\n",
      "Epoch: 1332/5000... Step: 81220... Loss: 0.0753... Val Loss: 0.0756\n",
      "Epoch: 1332/5000... Step: 81230... Loss: 0.0752... Val Loss: 0.0754\n",
      "Epoch: 1332/5000... Step: 81240... Loss: 0.0750... Val Loss: 0.0753\n",
      "Epoch: 1332/5000... Step: 81250... Loss: 0.0749... Val Loss: 0.0752\n",
      "Epoch: 1333/5000... Step: 81260... Loss: 0.0747... Val Loss: 0.0747\n",
      "Epoch: 1333/5000... Step: 81270... Loss: 0.0742... Val Loss: 0.0743\n",
      "Epoch: 1333/5000... Step: 81280... Loss: 0.0739... Val Loss: 0.0736\n",
      "Epoch: 1333/5000... Step: 81290... Loss: 0.0729... Val Loss: 0.0729\n",
      "Epoch: 1333/5000... Step: 81300... Loss: 0.0723... Val Loss: 0.0721\n",
      "Epoch: 1333/5000... Step: 81310... Loss: 0.0716... Val Loss: 0.0714\n",
      "Epoch: 1334/5000... Step: 81320... Loss: 0.0710... Val Loss: 0.0710\n",
      "Epoch: 1334/5000... Step: 81330... Loss: 0.0703... Val Loss: 0.0705\n",
      "Epoch: 1334/5000... Step: 81340... Loss: 0.0704... Val Loss: 0.0700\n",
      "Epoch: 1334/5000... Step: 81350... Loss: 0.0696... Val Loss: 0.0697\n",
      "Epoch: 1334/5000... Step: 81360... Loss: 0.0695... Val Loss: 0.0693\n",
      "Epoch: 1334/5000... Step: 81370... Loss: 0.0690... Val Loss: 0.0690\n",
      "Epoch: 1335/5000... Step: 81380... Loss: 0.0685... Val Loss: 0.0686\n",
      "Epoch: 1335/5000... Step: 81390... Loss: 0.0684... Val Loss: 0.0683\n",
      "Epoch: 1335/5000... Step: 81400... Loss: 0.0681... Val Loss: 0.0679\n",
      "Epoch: 1335/5000... Step: 81410... Loss: 0.0679... Val Loss: 0.0675\n",
      "Epoch: 1335/5000... Step: 81420... Loss: 0.0670... Val Loss: 0.0671\n",
      "Epoch: 1335/5000... Step: 81430... Loss: 0.0669... Val Loss: 0.0668\n",
      "Epoch: 1336/5000... Step: 81440... Loss: 0.0669... Val Loss: 0.0665\n",
      "Epoch: 1336/5000... Step: 81450... Loss: 0.0662... Val Loss: 0.0661\n",
      "Epoch: 1336/5000... Step: 81460... Loss: 0.0655... Val Loss: 0.0658\n",
      "Epoch: 1336/5000... Step: 81470... Loss: 0.0652... Val Loss: 0.0654\n",
      "Epoch: 1336/5000... Step: 81480... Loss: 0.0649... Val Loss: 0.0650\n",
      "Epoch: 1336/5000... Step: 81490... Loss: 0.0645... Val Loss: 0.0646\n",
      "Epoch: 1337/5000... Step: 81500... Loss: 0.0649... Val Loss: 0.0640\n",
      "Epoch: 1337/5000... Step: 81510... Loss: 0.0636... Val Loss: 0.0636\n",
      "Epoch: 1337/5000... Step: 81520... Loss: 0.0636... Val Loss: 0.0633\n",
      "Epoch: 1337/5000... Step: 81530... Loss: 0.0629... Val Loss: 0.0630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1337/5000... Step: 81540... Loss: 0.0629... Val Loss: 0.0628\n",
      "Epoch: 1337/5000... Step: 81550... Loss: 0.0628... Val Loss: 0.0624\n",
      "Epoch: 1338/5000... Step: 81560... Loss: 0.0627... Val Loss: 0.0622\n",
      "Epoch: 1338/5000... Step: 81570... Loss: 0.0619... Val Loss: 0.0619\n",
      "Epoch: 1338/5000... Step: 81580... Loss: 0.0619... Val Loss: 0.0617\n",
      "Epoch: 1338/5000... Step: 81590... Loss: 0.0617... Val Loss: 0.0614\n",
      "Epoch: 1338/5000... Step: 81600... Loss: 0.0608... Val Loss: 0.0612\n",
      "Epoch: 1338/5000... Step: 81610... Loss: 0.0613... Val Loss: 0.0609\n",
      "Epoch: 1339/5000... Step: 81620... Loss: 0.0609... Val Loss: 0.0606\n",
      "Epoch: 1339/5000... Step: 81630... Loss: 0.0604... Val Loss: 0.0605\n",
      "Epoch: 1339/5000... Step: 81640... Loss: 0.0599... Val Loss: 0.0601\n",
      "Epoch: 1339/5000... Step: 81650... Loss: 0.0600... Val Loss: 0.0599\n",
      "Epoch: 1339/5000... Step: 81660... Loss: 0.0594... Val Loss: 0.0597\n",
      "Epoch: 1339/5000... Step: 81670... Loss: 0.0594... Val Loss: 0.0593\n",
      "Epoch: 1340/5000... Step: 81680... Loss: 0.0594... Val Loss: 0.0591\n",
      "Epoch: 1340/5000... Step: 81690... Loss: 0.0594... Val Loss: 0.0588\n",
      "Epoch: 1340/5000... Step: 81700... Loss: 0.0588... Val Loss: 0.0592\n",
      "Epoch: 1340/5000... Step: 81710... Loss: 0.0583... Val Loss: 0.0588\n",
      "Epoch: 1340/5000... Step: 81720... Loss: 0.0576... Val Loss: 0.0588\n",
      "Epoch: 1340/5000... Step: 81730... Loss: 0.0580... Val Loss: 0.0585\n",
      "Epoch: 1340/5000... Step: 81740... Loss: 0.0579... Val Loss: 0.0580\n",
      "Epoch: 1341/5000... Step: 81750... Loss: 0.0576... Val Loss: 0.0571\n",
      "Epoch: 1341/5000... Step: 81760... Loss: 0.0570... Val Loss: 0.0569\n",
      "Epoch: 1341/5000... Step: 81770... Loss: 0.0569... Val Loss: 0.0566\n",
      "Epoch: 1341/5000... Step: 81780... Loss: 0.0563... Val Loss: 0.0564\n",
      "Epoch: 1341/5000... Step: 81790... Loss: 0.0557... Val Loss: 0.0561\n",
      "Epoch: 1341/5000... Step: 81800... Loss: 0.0560... Val Loss: 0.0560\n",
      "Epoch: 1342/5000... Step: 81810... Loss: 0.0557... Val Loss: 0.0558\n",
      "Epoch: 1342/5000... Step: 81820... Loss: 0.0553... Val Loss: 0.0556\n",
      "Epoch: 1342/5000... Step: 81830... Loss: 0.0554... Val Loss: 0.0553\n",
      "Epoch: 1342/5000... Step: 81840... Loss: 0.0548... Val Loss: 0.0552\n",
      "Epoch: 1342/5000... Step: 81850... Loss: 0.0551... Val Loss: 0.0551\n",
      "Epoch: 1342/5000... Step: 81860... Loss: 0.0548... Val Loss: 0.0549\n",
      "Epoch: 1343/5000... Step: 81870... Loss: 0.0546... Val Loss: 0.0546\n",
      "Epoch: 1343/5000... Step: 81880... Loss: 0.0545... Val Loss: 0.0545\n",
      "Epoch: 1343/5000... Step: 81890... Loss: 0.0543... Val Loss: 0.0544\n",
      "Epoch: 1343/5000... Step: 81900... Loss: 0.0539... Val Loss: 0.0542\n",
      "Epoch: 1343/5000... Step: 81910... Loss: 0.0539... Val Loss: 0.0541\n",
      "Epoch: 1343/5000... Step: 81920... Loss: 0.0535... Val Loss: 0.0540\n",
      "Epoch: 1344/5000... Step: 81930... Loss: 0.0531... Val Loss: 0.0539\n",
      "Epoch: 1344/5000... Step: 81940... Loss: 0.0534... Val Loss: 0.0537\n",
      "Epoch: 1344/5000... Step: 81950... Loss: 0.0533... Val Loss: 0.0536\n",
      "Epoch: 1344/5000... Step: 81960... Loss: 0.0530... Val Loss: 0.0535\n",
      "Epoch: 1344/5000... Step: 81970... Loss: 0.0528... Val Loss: 0.0534\n",
      "Epoch: 1344/5000... Step: 81980... Loss: 0.0526... Val Loss: 0.0533\n",
      "Epoch: 1345/5000... Step: 81990... Loss: 0.0523... Val Loss: 0.0531\n",
      "Epoch: 1345/5000... Step: 82000... Loss: 0.0519... Val Loss: 0.0529\n",
      "Epoch: 1345/5000... Step: 82010... Loss: 0.0520... Val Loss: 0.0529\n",
      "Epoch: 1345/5000... Step: 82020... Loss: 0.0523... Val Loss: 0.0528\n",
      "Epoch: 1345/5000... Step: 82030... Loss: 0.0517... Val Loss: 0.0527\n",
      "Epoch: 1345/5000... Step: 82040... Loss: 0.0522... Val Loss: 0.0527\n",
      "Epoch: 1346/5000... Step: 82050... Loss: 0.0519... Val Loss: 0.0527\n",
      "Epoch: 1346/5000... Step: 82060... Loss: 0.0511... Val Loss: 0.0525\n",
      "Epoch: 1346/5000... Step: 82070... Loss: 0.0508... Val Loss: 0.0523\n",
      "Epoch: 1346/5000... Step: 82080... Loss: 0.0509... Val Loss: 0.0523\n",
      "Epoch: 1346/5000... Step: 82090... Loss: 0.0513... Val Loss: 0.0522\n",
      "Epoch: 1346/5000... Step: 82100... Loss: 0.0513... Val Loss: 0.0521\n",
      "Epoch: 1347/5000... Step: 82110... Loss: 0.0514... Val Loss: 0.0522\n",
      "Epoch: 1347/5000... Step: 82120... Loss: 0.0503... Val Loss: 0.0520\n",
      "Epoch: 1347/5000... Step: 82130... Loss: 0.0507... Val Loss: 0.0518\n",
      "Epoch: 1347/5000... Step: 82140... Loss: 0.0510... Val Loss: 0.0519\n",
      "Epoch: 1347/5000... Step: 82150... Loss: 0.0501... Val Loss: 0.0519\n",
      "Epoch: 1347/5000... Step: 82160... Loss: 0.0506... Val Loss: 0.0517\n",
      "Epoch: 1348/5000... Step: 82170... Loss: 0.0507... Val Loss: 0.0517\n",
      "Epoch: 1348/5000... Step: 82180... Loss: 0.0500... Val Loss: 0.0516\n",
      "Epoch: 1348/5000... Step: 82190... Loss: 0.0502... Val Loss: 0.0516\n",
      "Epoch: 1348/5000... Step: 82200... Loss: 0.0500... Val Loss: 0.0516\n",
      "Epoch: 1348/5000... Step: 82210... Loss: 0.0497... Val Loss: 0.0516\n",
      "Epoch: 1348/5000... Step: 82220... Loss: 0.0503... Val Loss: 0.0514\n",
      "Epoch: 1349/5000... Step: 82230... Loss: 0.0501... Val Loss: 0.0513\n",
      "Epoch: 1349/5000... Step: 82240... Loss: 0.0494... Val Loss: 0.0514\n",
      "Epoch: 1349/5000... Step: 82250... Loss: 0.0492... Val Loss: 0.0512\n",
      "Epoch: 1349/5000... Step: 82260... Loss: 0.0492... Val Loss: 0.0513\n",
      "Epoch: 1349/5000... Step: 82270... Loss: 0.0493... Val Loss: 0.0512\n",
      "Epoch: 1349/5000... Step: 82280... Loss: 0.0495... Val Loss: 0.0512\n",
      "Epoch: 1350/5000... Step: 82290... Loss: 0.0492... Val Loss: 0.0512\n",
      "Epoch: 1350/5000... Step: 82300... Loss: 0.0493... Val Loss: 0.0511\n",
      "Epoch: 1350/5000... Step: 82310... Loss: 0.0492... Val Loss: 0.0512\n",
      "Epoch: 1350/5000... Step: 82320... Loss: 0.0490... Val Loss: 0.0511\n",
      "Epoch: 1350/5000... Step: 82330... Loss: 0.0483... Val Loss: 0.0510\n",
      "Epoch: 1350/5000... Step: 82340... Loss: 0.0489... Val Loss: 0.0511\n",
      "Epoch: 1350/5000... Step: 82350... Loss: 0.0490... Val Loss: 0.0511\n",
      "Epoch: 1351/5000... Step: 82360... Loss: 0.0488... Val Loss: 0.0510\n",
      "Epoch: 1351/5000... Step: 82370... Loss: 0.0489... Val Loss: 0.0509\n",
      "Epoch: 1351/5000... Step: 82380... Loss: 0.0488... Val Loss: 0.0509\n",
      "Epoch: 1351/5000... Step: 82390... Loss: 0.0487... Val Loss: 0.0509\n",
      "Epoch: 1351/5000... Step: 82400... Loss: 0.0480... Val Loss: 0.0510\n",
      "Epoch: 1351/5000... Step: 82410... Loss: 0.0483... Val Loss: 0.0510\n",
      "Epoch: 1352/5000... Step: 82420... Loss: 0.0483... Val Loss: 0.0509\n",
      "Epoch: 1352/5000... Step: 82430... Loss: 0.0484... Val Loss: 0.0509\n",
      "Epoch: 1352/5000... Step: 82440... Loss: 0.0485... Val Loss: 0.0508\n",
      "Epoch: 1352/5000... Step: 82450... Loss: 0.0483... Val Loss: 0.0508\n",
      "Epoch: 1352/5000... Step: 82460... Loss: 0.0482... Val Loss: 0.0508\n",
      "Epoch: 1352/5000... Step: 82470... Loss: 0.0481... Val Loss: 0.0507\n",
      "Epoch: 1353/5000... Step: 82480... Loss: 0.0480... Val Loss: 0.0508\n",
      "Epoch: 1353/5000... Step: 82490... Loss: 0.0480... Val Loss: 0.0508\n",
      "Epoch: 1353/5000... Step: 82500... Loss: 0.0478... Val Loss: 0.0507\n",
      "Epoch: 1353/5000... Step: 82510... Loss: 0.0478... Val Loss: 0.0508\n",
      "Epoch: 1353/5000... Step: 82520... Loss: 0.0475... Val Loss: 0.0509\n",
      "Epoch: 1353/5000... Step: 82530... Loss: 0.0477... Val Loss: 0.0508\n",
      "Epoch: 1354/5000... Step: 82540... Loss: 0.0475... Val Loss: 0.0506\n",
      "Epoch: 1354/5000... Step: 82550... Loss: 0.0475... Val Loss: 0.0507\n",
      "Epoch: 1354/5000... Step: 82560... Loss: 0.0475... Val Loss: 0.0507\n",
      "Epoch: 1354/5000... Step: 82570... Loss: 0.0470... Val Loss: 0.0507\n",
      "Epoch: 1354/5000... Step: 82580... Loss: 0.0473... Val Loss: 0.0507\n",
      "Epoch: 1354/5000... Step: 82590... Loss: 0.0471... Val Loss: 0.0506\n",
      "Epoch: 1355/5000... Step: 82600... Loss: 0.0470... Val Loss: 0.0506\n",
      "Epoch: 1355/5000... Step: 82610... Loss: 0.0465... Val Loss: 0.0506\n",
      "Epoch: 1355/5000... Step: 82620... Loss: 0.0467... Val Loss: 0.0507\n",
      "Epoch: 1355/5000... Step: 82630... Loss: 0.0474... Val Loss: 0.0507\n",
      "Epoch: 1355/5000... Step: 82640... Loss: 0.0466... Val Loss: 0.0508\n",
      "Epoch: 1355/5000... Step: 82650... Loss: 0.0474... Val Loss: 0.0507\n",
      "Epoch: 1356/5000... Step: 82660... Loss: 0.0470... Val Loss: 0.0506\n",
      "Epoch: 1356/5000... Step: 82670... Loss: 0.0465... Val Loss: 0.0507\n",
      "Epoch: 1356/5000... Step: 82680... Loss: 0.0463... Val Loss: 0.0507\n",
      "Epoch: 1356/5000... Step: 82690... Loss: 0.0465... Val Loss: 0.0506\n",
      "Epoch: 1356/5000... Step: 82700... Loss: 0.0467... Val Loss: 0.0508\n",
      "Epoch: 1356/5000... Step: 82710... Loss: 0.0466... Val Loss: 0.0507\n",
      "Epoch: 1357/5000... Step: 82720... Loss: 0.0472... Val Loss: 0.0506\n",
      "Epoch: 1357/5000... Step: 82730... Loss: 0.0465... Val Loss: 0.0507\n",
      "Epoch: 1357/5000... Step: 82740... Loss: 0.0465... Val Loss: 0.0506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1357/5000... Step: 82750... Loss: 0.0463... Val Loss: 0.0507\n",
      "Epoch: 1357/5000... Step: 82760... Loss: 0.0458... Val Loss: 0.0506\n",
      "Epoch: 1357/5000... Step: 82770... Loss: 0.0464... Val Loss: 0.0507\n",
      "Epoch: 1358/5000... Step: 82780... Loss: 0.0465... Val Loss: 0.0507\n",
      "Epoch: 1358/5000... Step: 82790... Loss: 0.0458... Val Loss: 0.0508\n",
      "Epoch: 1358/5000... Step: 82800... Loss: 0.0460... Val Loss: 0.0506\n",
      "Epoch: 1358/5000... Step: 82810... Loss: 0.0458... Val Loss: 0.0506\n",
      "Epoch: 1358/5000... Step: 82820... Loss: 0.0457... Val Loss: 0.0506\n",
      "Epoch: 1358/5000... Step: 82830... Loss: 0.0465... Val Loss: 0.0507\n",
      "Epoch: 1359/5000... Step: 82840... Loss: 0.0464... Val Loss: 0.0507\n",
      "Epoch: 1359/5000... Step: 82850... Loss: 0.0453... Val Loss: 0.0507\n",
      "Epoch: 1359/5000... Step: 82860... Loss: 0.0454... Val Loss: 0.0506\n",
      "Epoch: 1359/5000... Step: 82870... Loss: 0.0456... Val Loss: 0.0507\n",
      "Epoch: 1359/5000... Step: 82880... Loss: 0.0458... Val Loss: 0.0505\n",
      "Epoch: 1359/5000... Step: 82890... Loss: 0.0458... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82900... Loss: 0.0455... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82910... Loss: 0.0456... Val Loss: 0.0508\n",
      "Epoch: 1360/5000... Step: 82920... Loss: 0.0458... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82930... Loss: 0.0457... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82940... Loss: 0.0451... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82950... Loss: 0.0452... Val Loss: 0.0507\n",
      "Epoch: 1360/5000... Step: 82960... Loss: 0.0456... Val Loss: 0.0507\n",
      "Epoch: 1361/5000... Step: 82970... Loss: 0.0453... Val Loss: 0.0508\n",
      "Epoch: 1361/5000... Step: 82980... Loss: 0.0453... Val Loss: 0.0508\n",
      "Epoch: 1361/5000... Step: 82990... Loss: 0.0452... Val Loss: 0.0508\n",
      "Epoch: 1361/5000... Step: 83000... Loss: 0.0455... Val Loss: 0.0508\n",
      "Epoch: 1361/5000... Step: 83010... Loss: 0.0448... Val Loss: 0.0509\n",
      "Epoch: 1361/5000... Step: 83020... Loss: 0.0451... Val Loss: 0.0508\n",
      "Epoch: 1362/5000... Step: 83030... Loss: 0.0449... Val Loss: 0.0506\n",
      "Epoch: 1362/5000... Step: 83040... Loss: 0.0453... Val Loss: 0.0507\n",
      "Epoch: 1362/5000... Step: 83050... Loss: 0.0453... Val Loss: 0.0506\n",
      "Epoch: 1362/5000... Step: 83060... Loss: 0.0451... Val Loss: 0.0507\n",
      "Epoch: 1362/5000... Step: 83070... Loss: 0.0449... Val Loss: 0.0508\n",
      "Epoch: 1362/5000... Step: 83080... Loss: 0.0449... Val Loss: 0.0508\n",
      "Epoch: 1363/5000... Step: 83090... Loss: 0.0446... Val Loss: 0.0507\n",
      "Epoch: 1363/5000... Step: 83100... Loss: 0.0451... Val Loss: 0.0509\n",
      "Epoch: 1363/5000... Step: 83110... Loss: 0.0448... Val Loss: 0.0509\n",
      "Epoch: 1363/5000... Step: 83120... Loss: 0.0446... Val Loss: 0.0509\n",
      "Epoch: 1363/5000... Step: 83130... Loss: 0.0442... Val Loss: 0.0510\n",
      "Epoch: 1363/5000... Step: 83140... Loss: 0.0449... Val Loss: 0.0508\n",
      "Epoch: 1364/5000... Step: 83150... Loss: 0.0445... Val Loss: 0.0507\n",
      "Epoch: 1364/5000... Step: 83160... Loss: 0.0444... Val Loss: 0.0507\n",
      "Epoch: 1364/5000... Step: 83170... Loss: 0.0447... Val Loss: 0.0509\n",
      "Epoch: 1364/5000... Step: 83180... Loss: 0.0440... Val Loss: 0.0508\n",
      "Epoch: 1364/5000... Step: 83190... Loss: 0.0443... Val Loss: 0.0510\n",
      "Epoch: 1364/5000... Step: 83200... Loss: 0.0443... Val Loss: 0.0510\n",
      "Epoch: 1365/5000... Step: 83210... Loss: 0.0444... Val Loss: 0.0509\n",
      "Epoch: 1365/5000... Step: 83220... Loss: 0.0440... Val Loss: 0.0511\n",
      "Epoch: 1365/5000... Step: 83230... Loss: 0.0440... Val Loss: 0.0512\n",
      "Epoch: 1365/5000... Step: 83240... Loss: 0.0446... Val Loss: 0.0510\n",
      "Epoch: 1365/5000... Step: 83250... Loss: 0.0440... Val Loss: 0.0511\n",
      "Epoch: 1365/5000... Step: 83260... Loss: 0.0446... Val Loss: 0.0510\n",
      "Epoch: 1366/5000... Step: 83270... Loss: 0.0444... Val Loss: 0.0507\n",
      "Epoch: 1366/5000... Step: 83280... Loss: 0.0437... Val Loss: 0.0511\n",
      "Epoch: 1366/5000... Step: 83290... Loss: 0.0437... Val Loss: 0.0511\n",
      "Epoch: 1366/5000... Step: 83300... Loss: 0.0438... Val Loss: 0.0510\n",
      "Epoch: 1366/5000... Step: 83310... Loss: 0.0440... Val Loss: 0.0512\n",
      "Epoch: 1366/5000... Step: 83320... Loss: 0.0438... Val Loss: 0.0511\n",
      "Epoch: 1367/5000... Step: 83330... Loss: 0.0444... Val Loss: 0.0512\n",
      "Epoch: 1367/5000... Step: 83340... Loss: 0.0437... Val Loss: 0.0514\n",
      "Epoch: 1367/5000... Step: 83350... Loss: 0.0438... Val Loss: 0.0512\n",
      "Epoch: 1367/5000... Step: 83360... Loss: 0.0439... Val Loss: 0.0510\n",
      "Epoch: 1367/5000... Step: 83370... Loss: 0.0436... Val Loss: 0.0511\n",
      "Epoch: 1367/5000... Step: 83380... Loss: 0.0442... Val Loss: 0.0510\n",
      "Epoch: 1368/5000... Step: 83390... Loss: 0.0442... Val Loss: 0.0512\n",
      "Epoch: 1368/5000... Step: 83400... Loss: 0.0435... Val Loss: 0.0514\n",
      "Epoch: 1368/5000... Step: 83410... Loss: 0.0436... Val Loss: 0.0512\n",
      "Epoch: 1368/5000... Step: 83420... Loss: 0.0433... Val Loss: 0.0512\n",
      "Epoch: 1368/5000... Step: 83430... Loss: 0.0433... Val Loss: 0.0510\n",
      "Epoch: 1368/5000... Step: 83440... Loss: 0.0440... Val Loss: 0.0511\n",
      "Epoch: 1369/5000... Step: 83450... Loss: 0.0435... Val Loss: 0.0513\n",
      "Epoch: 1369/5000... Step: 83460... Loss: 0.0430... Val Loss: 0.0510\n",
      "Epoch: 1369/5000... Step: 83470... Loss: 0.0431... Val Loss: 0.0512\n",
      "Epoch: 1369/5000... Step: 83480... Loss: 0.0432... Val Loss: 0.0515\n",
      "Epoch: 1369/5000... Step: 83490... Loss: 0.0433... Val Loss: 0.0512\n",
      "Epoch: 1369/5000... Step: 83500... Loss: 0.0434... Val Loss: 0.0514\n",
      "Epoch: 1370/5000... Step: 83510... Loss: 0.0429... Val Loss: 0.0514\n",
      "Epoch: 1370/5000... Step: 83520... Loss: 0.0433... Val Loss: 0.0514\n",
      "Epoch: 1370/5000... Step: 83530... Loss: 0.0432... Val Loss: 0.0511\n",
      "Epoch: 1370/5000... Step: 83540... Loss: 0.0429... Val Loss: 0.0515\n",
      "Epoch: 1370/5000... Step: 83550... Loss: 0.0428... Val Loss: 0.0514\n",
      "Epoch: 1370/5000... Step: 83560... Loss: 0.0430... Val Loss: 0.0515\n",
      "Epoch: 1370/5000... Step: 83570... Loss: 0.0434... Val Loss: 0.0515\n",
      "Epoch: 1371/5000... Step: 83580... Loss: 0.0432... Val Loss: 0.0515\n",
      "Epoch: 1371/5000... Step: 83590... Loss: 0.0429... Val Loss: 0.0512\n",
      "Epoch: 1371/5000... Step: 83600... Loss: 0.0432... Val Loss: 0.0515\n",
      "Epoch: 1371/5000... Step: 83610... Loss: 0.0434... Val Loss: 0.0515\n",
      "Epoch: 1371/5000... Step: 83620... Loss: 0.0428... Val Loss: 0.0516\n",
      "Epoch: 1371/5000... Step: 83630... Loss: 0.0427... Val Loss: 0.0515\n",
      "Epoch: 1372/5000... Step: 83640... Loss: 0.0428... Val Loss: 0.0515\n",
      "Epoch: 1372/5000... Step: 83650... Loss: 0.0429... Val Loss: 0.0515\n",
      "Epoch: 1372/5000... Step: 83660... Loss: 0.0431... Val Loss: 0.0519\n",
      "Epoch: 1372/5000... Step: 83670... Loss: 0.0427... Val Loss: 0.0519\n",
      "Epoch: 1372/5000... Step: 83680... Loss: 0.0429... Val Loss: 0.0519\n",
      "Epoch: 1372/5000... Step: 83690... Loss: 0.0428... Val Loss: 0.0516\n",
      "Epoch: 1373/5000... Step: 83700... Loss: 0.0426... Val Loss: 0.0515\n",
      "Epoch: 1373/5000... Step: 83710... Loss: 0.0431... Val Loss: 0.0517\n",
      "Epoch: 1373/5000... Step: 83720... Loss: 0.0424... Val Loss: 0.0520\n",
      "Epoch: 1373/5000... Step: 83730... Loss: 0.0426... Val Loss: 0.0518\n",
      "Epoch: 1373/5000... Step: 83740... Loss: 0.0424... Val Loss: 0.0519\n",
      "Epoch: 1373/5000... Step: 83750... Loss: 0.0427... Val Loss: 0.0516\n",
      "Epoch: 1374/5000... Step: 83760... Loss: 0.0427... Val Loss: 0.0516\n",
      "Epoch: 1374/5000... Step: 83770... Loss: 0.0424... Val Loss: 0.0519\n",
      "Epoch: 1374/5000... Step: 83780... Loss: 0.0423... Val Loss: 0.0518\n",
      "Epoch: 1374/5000... Step: 83790... Loss: 0.0422... Val Loss: 0.0518\n",
      "Epoch: 1374/5000... Step: 83800... Loss: 0.0422... Val Loss: 0.0516\n",
      "Epoch: 1374/5000... Step: 83810... Loss: 0.0421... Val Loss: 0.0517\n",
      "Epoch: 1375/5000... Step: 83820... Loss: 0.0424... Val Loss: 0.0518\n",
      "Epoch: 1375/5000... Step: 83830... Loss: 0.0420... Val Loss: 0.0521\n",
      "Epoch: 1375/5000... Step: 83840... Loss: 0.0421... Val Loss: 0.0520\n",
      "Epoch: 1375/5000... Step: 83850... Loss: 0.0424... Val Loss: 0.0520\n",
      "Epoch: 1375/5000... Step: 83860... Loss: 0.0421... Val Loss: 0.0517\n",
      "Epoch: 1375/5000... Step: 83870... Loss: 0.0426... Val Loss: 0.0517\n",
      "Epoch: 1376/5000... Step: 83880... Loss: 0.0426... Val Loss: 0.0517\n",
      "Epoch: 1376/5000... Step: 83890... Loss: 0.0420... Val Loss: 0.0521\n",
      "Epoch: 1376/5000... Step: 83900... Loss: 0.0417... Val Loss: 0.0520\n",
      "Epoch: 1376/5000... Step: 83910... Loss: 0.0421... Val Loss: 0.0520\n",
      "Epoch: 1376/5000... Step: 83920... Loss: 0.0420... Val Loss: 0.0518\n",
      "Epoch: 1376/5000... Step: 83930... Loss: 0.0421... Val Loss: 0.0517\n",
      "Epoch: 1377/5000... Step: 83940... Loss: 0.0426... Val Loss: 0.0518\n",
      "Epoch: 1377/5000... Step: 83950... Loss: 0.0419... Val Loss: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1377/5000... Step: 83960... Loss: 0.0421... Val Loss: 0.0516\n",
      "Epoch: 1377/5000... Step: 83970... Loss: 0.0420... Val Loss: 0.0520\n",
      "Epoch: 1377/5000... Step: 83980... Loss: 0.0417... Val Loss: 0.0519\n",
      "Epoch: 1377/5000... Step: 83990... Loss: 0.0422... Val Loss: 0.0520\n",
      "Epoch: 1378/5000... Step: 84000... Loss: 0.0424... Val Loss: 0.0520\n",
      "Epoch: 1378/5000... Step: 84010... Loss: 0.0416... Val Loss: 0.0522\n",
      "Epoch: 1378/5000... Step: 84020... Loss: 0.0418... Val Loss: 0.0519\n",
      "Epoch: 1378/5000... Step: 84030... Loss: 0.0414... Val Loss: 0.0520\n",
      "Epoch: 1378/5000... Step: 84040... Loss: 0.0415... Val Loss: 0.0522\n",
      "Epoch: 1378/5000... Step: 84050... Loss: 0.0419... Val Loss: 0.0523\n",
      "Epoch: 1379/5000... Step: 84060... Loss: 0.0421... Val Loss: 0.0523\n",
      "Epoch: 1379/5000... Step: 84070... Loss: 0.0413... Val Loss: 0.0522\n",
      "Epoch: 1379/5000... Step: 84080... Loss: 0.0418... Val Loss: 0.0522\n",
      "Epoch: 1379/5000... Step: 84090... Loss: 0.0415... Val Loss: 0.0523\n",
      "Epoch: 1379/5000... Step: 84100... Loss: 0.0415... Val Loss: 0.0525\n",
      "Epoch: 1379/5000... Step: 84110... Loss: 0.0416... Val Loss: 0.0523\n",
      "Epoch: 1380/5000... Step: 84120... Loss: 0.0412... Val Loss: 0.0525\n",
      "Epoch: 1380/5000... Step: 84130... Loss: 0.0417... Val Loss: 0.0523\n",
      "Epoch: 1380/5000... Step: 84140... Loss: 0.0415... Val Loss: 0.0526\n",
      "Epoch: 1380/5000... Step: 84150... Loss: 0.0415... Val Loss: 0.0526\n",
      "Epoch: 1380/5000... Step: 84160... Loss: 0.0411... Val Loss: 0.0525\n",
      "Epoch: 1380/5000... Step: 84170... Loss: 0.0415... Val Loss: 0.0524\n",
      "Epoch: 1380/5000... Step: 84180... Loss: 0.0416... Val Loss: 0.0522\n",
      "Epoch: 1381/5000... Step: 84190... Loss: 0.0415... Val Loss: 0.0523\n",
      "Epoch: 1381/5000... Step: 84200... Loss: 0.0412... Val Loss: 0.0527\n",
      "Epoch: 1381/5000... Step: 84210... Loss: 0.0414... Val Loss: 0.0527\n",
      "Epoch: 1381/5000... Step: 84220... Loss: 0.0414... Val Loss: 0.0525\n",
      "Epoch: 1381/5000... Step: 84230... Loss: 0.0412... Val Loss: 0.0522\n",
      "Epoch: 1381/5000... Step: 84240... Loss: 0.0408... Val Loss: 0.0523\n",
      "Epoch: 1382/5000... Step: 84250... Loss: 0.0415... Val Loss: 0.0524\n",
      "Epoch: 1382/5000... Step: 84260... Loss: 0.0412... Val Loss: 0.0526\n",
      "Epoch: 1382/5000... Step: 84270... Loss: 0.0412... Val Loss: 0.0526\n",
      "Epoch: 1382/5000... Step: 84280... Loss: 0.0411... Val Loss: 0.0527\n",
      "Epoch: 1382/5000... Step: 84290... Loss: 0.0413... Val Loss: 0.0523\n",
      "Epoch: 1382/5000... Step: 84300... Loss: 0.0409... Val Loss: 0.0524\n",
      "Epoch: 1383/5000... Step: 84310... Loss: 0.0413... Val Loss: 0.0524\n",
      "Epoch: 1383/5000... Step: 84320... Loss: 0.0413... Val Loss: 0.0528\n",
      "Epoch: 1383/5000... Step: 84330... Loss: 0.0409... Val Loss: 0.0528\n",
      "Epoch: 1383/5000... Step: 84340... Loss: 0.0409... Val Loss: 0.0527\n",
      "Epoch: 1383/5000... Step: 84350... Loss: 0.0408... Val Loss: 0.0527\n",
      "Epoch: 1383/5000... Step: 84360... Loss: 0.0411... Val Loss: 0.0528\n",
      "Epoch: 1384/5000... Step: 84370... Loss: 0.0410... Val Loss: 0.0525\n",
      "Epoch: 1384/5000... Step: 84380... Loss: 0.0411... Val Loss: 0.0528\n",
      "Epoch: 1384/5000... Step: 84390... Loss: 0.0409... Val Loss: 0.0526\n",
      "Epoch: 1384/5000... Step: 84400... Loss: 0.0406... Val Loss: 0.0527\n",
      "Epoch: 1384/5000... Step: 84410... Loss: 0.0409... Val Loss: 0.0524\n",
      "Epoch: 1384/5000... Step: 84420... Loss: 0.0410... Val Loss: 0.0527\n",
      "Epoch: 1385/5000... Step: 84430... Loss: 0.0409... Val Loss: 0.0526\n",
      "Epoch: 1385/5000... Step: 84440... Loss: 0.0407... Val Loss: 0.0531\n",
      "Epoch: 1385/5000... Step: 84450... Loss: 0.0407... Val Loss: 0.0529\n",
      "Epoch: 1385/5000... Step: 84460... Loss: 0.0408... Val Loss: 0.0530\n",
      "Epoch: 1385/5000... Step: 84470... Loss: 0.0409... Val Loss: 0.0527\n",
      "Epoch: 1385/5000... Step: 84480... Loss: 0.0412... Val Loss: 0.0528\n",
      "Epoch: 1386/5000... Step: 84490... Loss: 0.0408... Val Loss: 0.0526\n",
      "Epoch: 1386/5000... Step: 84500... Loss: 0.0403... Val Loss: 0.0530\n",
      "Epoch: 1386/5000... Step: 84510... Loss: 0.0405... Val Loss: 0.0526\n",
      "Epoch: 1386/5000... Step: 84520... Loss: 0.0404... Val Loss: 0.0527\n",
      "Epoch: 1386/5000... Step: 84530... Loss: 0.0404... Val Loss: 0.0530\n",
      "Epoch: 1386/5000... Step: 84540... Loss: 0.0405... Val Loss: 0.0528\n",
      "Epoch: 1387/5000... Step: 84550... Loss: 0.0413... Val Loss: 0.0528\n",
      "Epoch: 1387/5000... Step: 84560... Loss: 0.0404... Val Loss: 0.0530\n",
      "Epoch: 1387/5000... Step: 84570... Loss: 0.0405... Val Loss: 0.0529\n",
      "Epoch: 1387/5000... Step: 84580... Loss: 0.0405... Val Loss: 0.0531\n",
      "Epoch: 1387/5000... Step: 84590... Loss: 0.0400... Val Loss: 0.0533\n",
      "Epoch: 1387/5000... Step: 84600... Loss: 0.0407... Val Loss: 0.0529\n",
      "Epoch: 1388/5000... Step: 84610... Loss: 0.0409... Val Loss: 0.0530\n",
      "Epoch: 1388/5000... Step: 84620... Loss: 0.0403... Val Loss: 0.0531\n",
      "Epoch: 1388/5000... Step: 84630... Loss: 0.0403... Val Loss: 0.0531\n",
      "Epoch: 1388/5000... Step: 84640... Loss: 0.0401... Val Loss: 0.0531\n",
      "Epoch: 1388/5000... Step: 84650... Loss: 0.0402... Val Loss: 0.0534\n",
      "Epoch: 1388/5000... Step: 84660... Loss: 0.0406... Val Loss: 0.0530\n",
      "Epoch: 1389/5000... Step: 84670... Loss: 0.0407... Val Loss: 0.0532\n",
      "Epoch: 1389/5000... Step: 84680... Loss: 0.0396... Val Loss: 0.0532\n",
      "Epoch: 1389/5000... Step: 84690... Loss: 0.0403... Val Loss: 0.0532\n",
      "Epoch: 1389/5000... Step: 84700... Loss: 0.0399... Val Loss: 0.0532\n",
      "Epoch: 1389/5000... Step: 84710... Loss: 0.0402... Val Loss: 0.0536\n",
      "Epoch: 1389/5000... Step: 84720... Loss: 0.0403... Val Loss: 0.0531\n",
      "Epoch: 1390/5000... Step: 84730... Loss: 0.0397... Val Loss: 0.0532\n",
      "Epoch: 1390/5000... Step: 84740... Loss: 0.0400... Val Loss: 0.0532\n",
      "Epoch: 1390/5000... Step: 84750... Loss: 0.0402... Val Loss: 0.0533\n",
      "Epoch: 1390/5000... Step: 84760... Loss: 0.0397... Val Loss: 0.0534\n",
      "Epoch: 1390/5000... Step: 84770... Loss: 0.0399... Val Loss: 0.0536\n",
      "Epoch: 1390/5000... Step: 84780... Loss: 0.0401... Val Loss: 0.0533\n",
      "Epoch: 1390/5000... Step: 84790... Loss: 0.0403... Val Loss: 0.0535\n",
      "Epoch: 1391/5000... Step: 84800... Loss: 0.0399... Val Loss: 0.0532\n",
      "Epoch: 1391/5000... Step: 84810... Loss: 0.0398... Val Loss: 0.0532\n",
      "Epoch: 1391/5000... Step: 84820... Loss: 0.0402... Val Loss: 0.0535\n",
      "Epoch: 1391/5000... Step: 84830... Loss: 0.0401... Val Loss: 0.0535\n",
      "Epoch: 1391/5000... Step: 84840... Loss: 0.0398... Val Loss: 0.0536\n",
      "Epoch: 1391/5000... Step: 84850... Loss: 0.0396... Val Loss: 0.0535\n",
      "Epoch: 1392/5000... Step: 84860... Loss: 0.0402... Val Loss: 0.0534\n",
      "Epoch: 1392/5000... Step: 84870... Loss: 0.0398... Val Loss: 0.0534\n",
      "Epoch: 1392/5000... Step: 84880... Loss: 0.0400... Val Loss: 0.0535\n",
      "Epoch: 1392/5000... Step: 84890... Loss: 0.0398... Val Loss: 0.0532\n",
      "Epoch: 1392/5000... Step: 84900... Loss: 0.0399... Val Loss: 0.0533\n",
      "Epoch: 1392/5000... Step: 84910... Loss: 0.0400... Val Loss: 0.0535\n",
      "Epoch: 1393/5000... Step: 84920... Loss: 0.0402... Val Loss: 0.0535\n",
      "Epoch: 1393/5000... Step: 84930... Loss: 0.0399... Val Loss: 0.0536\n",
      "Epoch: 1393/5000... Step: 84940... Loss: 0.0398... Val Loss: 0.0536\n",
      "Epoch: 1393/5000... Step: 84950... Loss: 0.0395... Val Loss: 0.0534\n",
      "Epoch: 1393/5000... Step: 84960... Loss: 0.0397... Val Loss: 0.0535\n",
      "Epoch: 1393/5000... Step: 84970... Loss: 0.0399... Val Loss: 0.0535\n",
      "Epoch: 1394/5000... Step: 84980... Loss: 0.0396... Val Loss: 0.0535\n",
      "Epoch: 1394/5000... Step: 84990... Loss: 0.0398... Val Loss: 0.0537\n",
      "Epoch: 1394/5000... Step: 85000... Loss: 0.0398... Val Loss: 0.0536\n",
      "Epoch: 1394/5000... Step: 85010... Loss: 0.0397... Val Loss: 0.0535\n",
      "Epoch: 1394/5000... Step: 85020... Loss: 0.0397... Val Loss: 0.0537\n",
      "Epoch: 1394/5000... Step: 85030... Loss: 0.0396... Val Loss: 0.0536\n",
      "Epoch: 1395/5000... Step: 85040... Loss: 0.0397... Val Loss: 0.0535\n",
      "Epoch: 1395/5000... Step: 85050... Loss: 0.0392... Val Loss: 0.0537\n",
      "Epoch: 1395/5000... Step: 85060... Loss: 0.0392... Val Loss: 0.0535\n",
      "Epoch: 1395/5000... Step: 85070... Loss: 0.0397... Val Loss: 0.0536\n",
      "Epoch: 1395/5000... Step: 85080... Loss: 0.0393... Val Loss: 0.0538\n",
      "Epoch: 1395/5000... Step: 85090... Loss: 0.0398... Val Loss: 0.0538\n",
      "Epoch: 1396/5000... Step: 85100... Loss: 0.0395... Val Loss: 0.0537\n",
      "Epoch: 1396/5000... Step: 85110... Loss: 0.0391... Val Loss: 0.0539\n",
      "Epoch: 1396/5000... Step: 85120... Loss: 0.0393... Val Loss: 0.0538\n",
      "Epoch: 1396/5000... Step: 85130... Loss: 0.0392... Val Loss: 0.0538\n",
      "Epoch: 1396/5000... Step: 85140... Loss: 0.0393... Val Loss: 0.0539\n",
      "Epoch: 1396/5000... Step: 85150... Loss: 0.0392... Val Loss: 0.0537\n",
      "Epoch: 1397/5000... Step: 85160... Loss: 0.0401... Val Loss: 0.0536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1397/5000... Step: 85170... Loss: 0.0392... Val Loss: 0.0538\n",
      "Epoch: 1397/5000... Step: 85180... Loss: 0.0394... Val Loss: 0.0536\n",
      "Epoch: 1397/5000... Step: 85190... Loss: 0.0393... Val Loss: 0.0541\n",
      "Epoch: 1397/5000... Step: 85200... Loss: 0.0388... Val Loss: 0.0544\n",
      "Epoch: 1397/5000... Step: 85210... Loss: 0.0395... Val Loss: 0.0539\n",
      "Epoch: 1398/5000... Step: 85220... Loss: 0.0397... Val Loss: 0.0538\n",
      "Epoch: 1398/5000... Step: 85230... Loss: 0.0391... Val Loss: 0.0538\n",
      "Epoch: 1398/5000... Step: 85240... Loss: 0.0394... Val Loss: 0.0537\n",
      "Epoch: 1398/5000... Step: 85250... Loss: 0.0393... Val Loss: 0.0541\n",
      "Epoch: 1398/5000... Step: 85260... Loss: 0.0392... Val Loss: 0.0538\n",
      "Epoch: 1398/5000... Step: 85270... Loss: 0.0396... Val Loss: 0.0539\n",
      "Epoch: 1399/5000... Step: 85280... Loss: 0.0395... Val Loss: 0.0540\n",
      "Epoch: 1399/5000... Step: 85290... Loss: 0.0387... Val Loss: 0.0538\n",
      "Epoch: 1399/5000... Step: 85300... Loss: 0.0391... Val Loss: 0.0541\n",
      "Epoch: 1399/5000... Step: 85310... Loss: 0.0391... Val Loss: 0.0541\n",
      "Epoch: 1399/5000... Step: 85320... Loss: 0.0390... Val Loss: 0.0542\n",
      "Epoch: 1399/5000... Step: 85330... Loss: 0.0393... Val Loss: 0.0538\n",
      "Epoch: 1400/5000... Step: 85340... Loss: 0.0388... Val Loss: 0.0541\n",
      "Epoch: 1400/5000... Step: 85350... Loss: 0.0390... Val Loss: 0.0539\n",
      "Epoch: 1400/5000... Step: 85360... Loss: 0.0391... Val Loss: 0.0542\n",
      "Epoch: 1400/5000... Step: 85370... Loss: 0.0386... Val Loss: 0.0543\n",
      "Epoch: 1400/5000... Step: 85380... Loss: 0.0386... Val Loss: 0.0543\n",
      "Epoch: 1400/5000... Step: 85390... Loss: 0.0392... Val Loss: 0.0540\n",
      "Epoch: 1400/5000... Step: 85400... Loss: 0.0391... Val Loss: 0.0540\n",
      "Epoch: 1401/5000... Step: 85410... Loss: 0.0392... Val Loss: 0.0538\n",
      "Epoch: 1401/5000... Step: 85420... Loss: 0.0387... Val Loss: 0.0541\n",
      "Epoch: 1401/5000... Step: 85430... Loss: 0.0389... Val Loss: 0.0542\n",
      "Epoch: 1401/5000... Step: 85440... Loss: 0.0390... Val Loss: 0.0542\n",
      "Epoch: 1401/5000... Step: 85450... Loss: 0.0389... Val Loss: 0.0539\n",
      "Epoch: 1401/5000... Step: 85460... Loss: 0.0385... Val Loss: 0.0543\n",
      "Epoch: 1402/5000... Step: 85470... Loss: 0.0389... Val Loss: 0.0540\n",
      "Epoch: 1402/5000... Step: 85480... Loss: 0.0388... Val Loss: 0.0541\n",
      "Epoch: 1402/5000... Step: 85490... Loss: 0.0390... Val Loss: 0.0543\n",
      "Epoch: 1402/5000... Step: 85500... Loss: 0.0387... Val Loss: 0.0543\n",
      "Epoch: 1402/5000... Step: 85510... Loss: 0.0386... Val Loss: 0.0542\n",
      "Epoch: 1402/5000... Step: 85520... Loss: 0.0388... Val Loss: 0.0544\n",
      "Epoch: 1403/5000... Step: 85530... Loss: 0.0390... Val Loss: 0.0539\n",
      "Epoch: 1403/5000... Step: 85540... Loss: 0.0389... Val Loss: 0.0545\n",
      "Epoch: 1403/5000... Step: 85550... Loss: 0.0388... Val Loss: 0.0544\n",
      "Epoch: 1403/5000... Step: 85560... Loss: 0.0386... Val Loss: 0.0543\n",
      "Epoch: 1403/5000... Step: 85570... Loss: 0.0387... Val Loss: 0.0544\n",
      "Epoch: 1403/5000... Step: 85580... Loss: 0.0387... Val Loss: 0.0544\n",
      "Epoch: 1404/5000... Step: 85590... Loss: 0.0383... Val Loss: 0.0542\n",
      "Epoch: 1404/5000... Step: 85600... Loss: 0.0386... Val Loss: 0.0545\n",
      "Epoch: 1404/5000... Step: 85610... Loss: 0.0389... Val Loss: 0.0543\n",
      "Epoch: 1404/5000... Step: 85620... Loss: 0.0385... Val Loss: 0.0542\n",
      "Epoch: 1404/5000... Step: 85630... Loss: 0.0385... Val Loss: 0.0545\n",
      "Epoch: 1404/5000... Step: 85640... Loss: 0.0386... Val Loss: 0.0544\n",
      "Epoch: 1405/5000... Step: 85650... Loss: 0.0386... Val Loss: 0.0544\n",
      "Epoch: 1405/5000... Step: 85660... Loss: 0.0385... Val Loss: 0.0543\n",
      "Epoch: 1405/5000... Step: 85670... Loss: 0.0381... Val Loss: 0.0544\n",
      "Epoch: 1405/5000... Step: 85680... Loss: 0.0387... Val Loss: 0.0547\n",
      "Epoch: 1405/5000... Step: 85690... Loss: 0.0383... Val Loss: 0.0546\n",
      "Epoch: 1405/5000... Step: 85700... Loss: 0.0389... Val Loss: 0.0543\n",
      "Epoch: 1406/5000... Step: 85710... Loss: 0.0386... Val Loss: 0.0545\n",
      "Epoch: 1406/5000... Step: 85720... Loss: 0.0383... Val Loss: 0.0542\n",
      "Epoch: 1406/5000... Step: 85730... Loss: 0.0382... Val Loss: 0.0544\n",
      "Epoch: 1406/5000... Step: 85740... Loss: 0.0382... Val Loss: 0.0544\n",
      "Epoch: 1406/5000... Step: 85750... Loss: 0.0386... Val Loss: 0.0547\n",
      "Epoch: 1406/5000... Step: 85760... Loss: 0.0383... Val Loss: 0.0543\n",
      "Epoch: 1407/5000... Step: 85770... Loss: 0.0388... Val Loss: 0.0546\n",
      "Epoch: 1407/5000... Step: 85780... Loss: 0.0382... Val Loss: 0.0545\n",
      "Epoch: 1407/5000... Step: 85790... Loss: 0.0383... Val Loss: 0.0545\n",
      "Epoch: 1407/5000... Step: 85800... Loss: 0.0382... Val Loss: 0.0546\n",
      "Epoch: 1407/5000... Step: 85810... Loss: 0.0381... Val Loss: 0.0548\n",
      "Epoch: 1407/5000... Step: 85820... Loss: 0.0383... Val Loss: 0.0545\n",
      "Epoch: 1408/5000... Step: 85830... Loss: 0.0387... Val Loss: 0.0545\n",
      "Epoch: 1408/5000... Step: 85840... Loss: 0.0383... Val Loss: 0.0545\n",
      "Epoch: 1408/5000... Step: 85850... Loss: 0.0382... Val Loss: 0.0546\n",
      "Epoch: 1408/5000... Step: 85860... Loss: 0.0383... Val Loss: 0.0547\n",
      "Epoch: 1408/5000... Step: 85870... Loss: 0.0377... Val Loss: 0.0548\n",
      "Epoch: 1408/5000... Step: 85880... Loss: 0.0384... Val Loss: 0.0545\n",
      "Epoch: 1409/5000... Step: 85890... Loss: 0.0385... Val Loss: 0.0548\n",
      "Epoch: 1409/5000... Step: 85900... Loss: 0.0381... Val Loss: 0.0544\n",
      "Epoch: 1409/5000... Step: 85910... Loss: 0.0380... Val Loss: 0.0546\n",
      "Epoch: 1409/5000... Step: 85920... Loss: 0.0383... Val Loss: 0.0549\n",
      "Epoch: 1409/5000... Step: 85930... Loss: 0.0379... Val Loss: 0.0550\n",
      "Epoch: 1409/5000... Step: 85940... Loss: 0.0382... Val Loss: 0.0548\n",
      "Epoch: 1410/5000... Step: 85950... Loss: 0.0376... Val Loss: 0.0548\n",
      "Epoch: 1410/5000... Step: 85960... Loss: 0.0382... Val Loss: 0.0544\n",
      "Epoch: 1410/5000... Step: 85970... Loss: 0.0380... Val Loss: 0.0545\n",
      "Epoch: 1410/5000... Step: 85980... Loss: 0.0375... Val Loss: 0.0547\n",
      "Epoch: 1410/5000... Step: 85990... Loss: 0.0375... Val Loss: 0.0548\n",
      "Epoch: 1410/5000... Step: 86000... Loss: 0.0380... Val Loss: 0.0546\n",
      "Epoch: 1410/5000... Step: 86010... Loss: 0.0382... Val Loss: 0.0548\n",
      "Epoch: 1411/5000... Step: 86020... Loss: 0.0382... Val Loss: 0.0546\n",
      "Epoch: 1411/5000... Step: 86030... Loss: 0.0381... Val Loss: 0.0548\n",
      "Epoch: 1411/5000... Step: 86040... Loss: 0.0379... Val Loss: 0.0551\n",
      "Epoch: 1411/5000... Step: 86050... Loss: 0.0382... Val Loss: 0.0549\n",
      "Epoch: 1411/5000... Step: 86060... Loss: 0.0381... Val Loss: 0.0550\n",
      "Epoch: 1411/5000... Step: 86070... Loss: 0.0378... Val Loss: 0.0547\n",
      "Epoch: 1412/5000... Step: 86080... Loss: 0.0381... Val Loss: 0.0546\n",
      "Epoch: 1412/5000... Step: 86090... Loss: 0.0379... Val Loss: 0.0546\n",
      "Epoch: 1412/5000... Step: 86100... Loss: 0.0380... Val Loss: 0.0549\n",
      "Epoch: 1412/5000... Step: 86110... Loss: 0.0377... Val Loss: 0.0550\n",
      "Epoch: 1412/5000... Step: 86120... Loss: 0.0379... Val Loss: 0.0546\n",
      "Epoch: 1412/5000... Step: 86130... Loss: 0.0378... Val Loss: 0.0548\n",
      "Epoch: 1413/5000... Step: 86140... Loss: 0.0380... Val Loss: 0.0548\n",
      "Epoch: 1413/5000... Step: 86150... Loss: 0.0382... Val Loss: 0.0549\n",
      "Epoch: 1413/5000... Step: 86160... Loss: 0.0377... Val Loss: 0.0548\n",
      "Epoch: 1413/5000... Step: 86170... Loss: 0.0375... Val Loss: 0.0549\n",
      "Epoch: 1413/5000... Step: 86180... Loss: 0.0381... Val Loss: 0.0552\n",
      "Epoch: 1413/5000... Step: 86190... Loss: 0.0378... Val Loss: 0.0552\n",
      "Epoch: 1414/5000... Step: 86200... Loss: 0.0379... Val Loss: 0.0551\n",
      "Epoch: 1414/5000... Step: 86210... Loss: 0.0377... Val Loss: 0.0551\n",
      "Epoch: 1414/5000... Step: 86220... Loss: 0.0374... Val Loss: 0.0546\n",
      "Epoch: 1414/5000... Step: 86230... Loss: 0.0377... Val Loss: 0.0550\n",
      "Epoch: 1414/5000... Step: 86240... Loss: 0.0376... Val Loss: 0.0552\n",
      "Epoch: 1414/5000... Step: 86250... Loss: 0.0376... Val Loss: 0.0552\n",
      "Epoch: 1415/5000... Step: 86260... Loss: 0.0378... Val Loss: 0.0551\n",
      "Epoch: 1415/5000... Step: 86270... Loss: 0.0375... Val Loss: 0.0550\n",
      "Epoch: 1415/5000... Step: 86280... Loss: 0.0375... Val Loss: 0.0549\n",
      "Epoch: 1415/5000... Step: 86290... Loss: 0.0380... Val Loss: 0.0551\n",
      "Epoch: 1415/5000... Step: 86300... Loss: 0.0378... Val Loss: 0.0557\n",
      "Epoch: 1415/5000... Step: 86310... Loss: 0.0377... Val Loss: 0.0551\n",
      "Epoch: 1416/5000... Step: 86320... Loss: 0.0379... Val Loss: 0.0551\n",
      "Epoch: 1416/5000... Step: 86330... Loss: 0.0375... Val Loss: 0.0550\n",
      "Epoch: 1416/5000... Step: 86340... Loss: 0.0376... Val Loss: 0.0549\n",
      "Epoch: 1416/5000... Step: 86350... Loss: 0.0375... Val Loss: 0.0553\n",
      "Epoch: 1416/5000... Step: 86360... Loss: 0.0375... Val Loss: 0.0555\n",
      "Epoch: 1416/5000... Step: 86370... Loss: 0.0377... Val Loss: 0.0550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1417/5000... Step: 86380... Loss: 0.0382... Val Loss: 0.0549\n",
      "Epoch: 1417/5000... Step: 86390... Loss: 0.0375... Val Loss: 0.0549\n",
      "Epoch: 1417/5000... Step: 86400... Loss: 0.0376... Val Loss: 0.0550\n",
      "Epoch: 1417/5000... Step: 86410... Loss: 0.0375... Val Loss: 0.0550\n",
      "Epoch: 1417/5000... Step: 86420... Loss: 0.0370... Val Loss: 0.0552\n",
      "Epoch: 1417/5000... Step: 86430... Loss: 0.0374... Val Loss: 0.0549\n",
      "Epoch: 1418/5000... Step: 86440... Loss: 0.0379... Val Loss: 0.0550\n",
      "Epoch: 1418/5000... Step: 86450... Loss: 0.0375... Val Loss: 0.0553\n",
      "Epoch: 1418/5000... Step: 86460... Loss: 0.0374... Val Loss: 0.0552\n",
      "Epoch: 1418/5000... Step: 86470... Loss: 0.0374... Val Loss: 0.0550\n",
      "Epoch: 1418/5000... Step: 86480... Loss: 0.0370... Val Loss: 0.0553\n",
      "Epoch: 1418/5000... Step: 86490... Loss: 0.0378... Val Loss: 0.0551\n",
      "Epoch: 1419/5000... Step: 86500... Loss: 0.0374... Val Loss: 0.0552\n",
      "Epoch: 1419/5000... Step: 86510... Loss: 0.0372... Val Loss: 0.0553\n",
      "Epoch: 1419/5000... Step: 86520... Loss: 0.0373... Val Loss: 0.0551\n",
      "Epoch: 1419/5000... Step: 86530... Loss: 0.0374... Val Loss: 0.0555\n",
      "Epoch: 1419/5000... Step: 86540... Loss: 0.0374... Val Loss: 0.0555\n",
      "Epoch: 1419/5000... Step: 86550... Loss: 0.0374... Val Loss: 0.0553\n",
      "Epoch: 1420/5000... Step: 86560... Loss: 0.0370... Val Loss: 0.0556\n",
      "Epoch: 1420/5000... Step: 86570... Loss: 0.0371... Val Loss: 0.0553\n",
      "Epoch: 1420/5000... Step: 86580... Loss: 0.0374... Val Loss: 0.0554\n",
      "Epoch: 1420/5000... Step: 86590... Loss: 0.0369... Val Loss: 0.0555\n",
      "Epoch: 1420/5000... Step: 86600... Loss: 0.0367... Val Loss: 0.0555\n",
      "Epoch: 1420/5000... Step: 86610... Loss: 0.0373... Val Loss: 0.0555\n",
      "Epoch: 1420/5000... Step: 86620... Loss: 0.0373... Val Loss: 0.0554\n",
      "Epoch: 1421/5000... Step: 86630... Loss: 0.0375... Val Loss: 0.0554\n",
      "Epoch: 1421/5000... Step: 86640... Loss: 0.0370... Val Loss: 0.0554\n",
      "Epoch: 1421/5000... Step: 86650... Loss: 0.0371... Val Loss: 0.0553\n",
      "Epoch: 1421/5000... Step: 86660... Loss: 0.0374... Val Loss: 0.0556\n",
      "Epoch: 1421/5000... Step: 86670... Loss: 0.0372... Val Loss: 0.0554\n",
      "Epoch: 1421/5000... Step: 86680... Loss: 0.0368... Val Loss: 0.0556\n",
      "Epoch: 1422/5000... Step: 86690... Loss: 0.0374... Val Loss: 0.0556\n",
      "Epoch: 1422/5000... Step: 86700... Loss: 0.0373... Val Loss: 0.0556\n",
      "Epoch: 1422/5000... Step: 86710... Loss: 0.0370... Val Loss: 0.0556\n",
      "Epoch: 1422/5000... Step: 86720... Loss: 0.0371... Val Loss: 0.0553\n",
      "Epoch: 1422/5000... Step: 86730... Loss: 0.0370... Val Loss: 0.0555\n",
      "Epoch: 1422/5000... Step: 86740... Loss: 0.0369... Val Loss: 0.0556\n",
      "Epoch: 1423/5000... Step: 86750... Loss: 0.0372... Val Loss: 0.0553\n",
      "Epoch: 1423/5000... Step: 86760... Loss: 0.0371... Val Loss: 0.0555\n",
      "Epoch: 1423/5000... Step: 86770... Loss: 0.0370... Val Loss: 0.0555\n",
      "Epoch: 1423/5000... Step: 86780... Loss: 0.0369... Val Loss: 0.0554\n",
      "Epoch: 1423/5000... Step: 86790... Loss: 0.0368... Val Loss: 0.0558\n",
      "Epoch: 1423/5000... Step: 86800... Loss: 0.0370... Val Loss: 0.0555\n",
      "Epoch: 1424/5000... Step: 86810... Loss: 0.0368... Val Loss: 0.0553\n",
      "Epoch: 1424/5000... Step: 86820... Loss: 0.0371... Val Loss: 0.0557\n",
      "Epoch: 1424/5000... Step: 86830... Loss: 0.0370... Val Loss: 0.0553\n",
      "Epoch: 1424/5000... Step: 86840... Loss: 0.0368... Val Loss: 0.0552\n",
      "Epoch: 1424/5000... Step: 86850... Loss: 0.0368... Val Loss: 0.0561\n",
      "Epoch: 1424/5000... Step: 86860... Loss: 0.0367... Val Loss: 0.0556\n",
      "Epoch: 1425/5000... Step: 86870... Loss: 0.0371... Val Loss: 0.0556\n",
      "Epoch: 1425/5000... Step: 86880... Loss: 0.0367... Val Loss: 0.0557\n",
      "Epoch: 1425/5000... Step: 86890... Loss: 0.0367... Val Loss: 0.0552\n",
      "Epoch: 1425/5000... Step: 86900... Loss: 0.0371... Val Loss: 0.0556\n",
      "Epoch: 1425/5000... Step: 86910... Loss: 0.0369... Val Loss: 0.0560\n",
      "Epoch: 1425/5000... Step: 86920... Loss: 0.0374... Val Loss: 0.0557\n",
      "Epoch: 1426/5000... Step: 86930... Loss: 0.0370... Val Loss: 0.0554\n",
      "Epoch: 1426/5000... Step: 86940... Loss: 0.0364... Val Loss: 0.0556\n",
      "Epoch: 1426/5000... Step: 86950... Loss: 0.0369... Val Loss: 0.0556\n",
      "Epoch: 1426/5000... Step: 86960... Loss: 0.0368... Val Loss: 0.0558\n",
      "Epoch: 1426/5000... Step: 86970... Loss: 0.0370... Val Loss: 0.0562\n",
      "Epoch: 1426/5000... Step: 86980... Loss: 0.0368... Val Loss: 0.0558\n",
      "Epoch: 1427/5000... Step: 86990... Loss: 0.0374... Val Loss: 0.0559\n",
      "Epoch: 1427/5000... Step: 87000... Loss: 0.0365... Val Loss: 0.0555\n",
      "Epoch: 1427/5000... Step: 87010... Loss: 0.0368... Val Loss: 0.0555\n",
      "Epoch: 1427/5000... Step: 87020... Loss: 0.0367... Val Loss: 0.0561\n",
      "Epoch: 1427/5000... Step: 87030... Loss: 0.0364... Val Loss: 0.0563\n",
      "Epoch: 1427/5000... Step: 87040... Loss: 0.0368... Val Loss: 0.0555\n",
      "Epoch: 1428/5000... Step: 87050... Loss: 0.0372... Val Loss: 0.0559\n",
      "Epoch: 1428/5000... Step: 87060... Loss: 0.0366... Val Loss: 0.0556\n",
      "Epoch: 1428/5000... Step: 87070... Loss: 0.0366... Val Loss: 0.0558\n",
      "Epoch: 1428/5000... Step: 87080... Loss: 0.0367... Val Loss: 0.0563\n",
      "Epoch: 1428/5000... Step: 87090... Loss: 0.0366... Val Loss: 0.0562\n",
      "Epoch: 1428/5000... Step: 87100... Loss: 0.0370... Val Loss: 0.0561\n",
      "Epoch: 1429/5000... Step: 87110... Loss: 0.0367... Val Loss: 0.0560\n",
      "Epoch: 1429/5000... Step: 87120... Loss: 0.0365... Val Loss: 0.0560\n",
      "Epoch: 1429/5000... Step: 87130... Loss: 0.0367... Val Loss: 0.0562\n",
      "Epoch: 1429/5000... Step: 87140... Loss: 0.0365... Val Loss: 0.0559\n",
      "Epoch: 1429/5000... Step: 87150... Loss: 0.0366... Val Loss: 0.0560\n",
      "Epoch: 1429/5000... Step: 87160... Loss: 0.0368... Val Loss: 0.0559\n",
      "Epoch: 1430/5000... Step: 87170... Loss: 0.0363... Val Loss: 0.0559\n",
      "Epoch: 1430/5000... Step: 87180... Loss: 0.0369... Val Loss: 0.0560\n",
      "Epoch: 1430/5000... Step: 87190... Loss: 0.0366... Val Loss: 0.0562\n",
      "Epoch: 1430/5000... Step: 87200... Loss: 0.0362... Val Loss: 0.0560\n",
      "Epoch: 1430/5000... Step: 87210... Loss: 0.0361... Val Loss: 0.0558\n",
      "Epoch: 1430/5000... Step: 87220... Loss: 0.0365... Val Loss: 0.0559\n",
      "Epoch: 1430/5000... Step: 87230... Loss: 0.0371... Val Loss: 0.0561\n",
      "Epoch: 1431/5000... Step: 87240... Loss: 0.0368... Val Loss: 0.0559\n",
      "Epoch: 1431/5000... Step: 87250... Loss: 0.0363... Val Loss: 0.0563\n",
      "Epoch: 1431/5000... Step: 87260... Loss: 0.0360... Val Loss: 0.0559\n",
      "Epoch: 1431/5000... Step: 87270... Loss: 0.0367... Val Loss: 0.0557\n",
      "Epoch: 1431/5000... Step: 87280... Loss: 0.0363... Val Loss: 0.0564\n",
      "Epoch: 1431/5000... Step: 87290... Loss: 0.0362... Val Loss: 0.0563\n",
      "Epoch: 1432/5000... Step: 87300... Loss: 0.0365... Val Loss: 0.0561\n",
      "Epoch: 1432/5000... Step: 87310... Loss: 0.0366... Val Loss: 0.0561\n",
      "Epoch: 1432/5000... Step: 87320... Loss: 0.0367... Val Loss: 0.0558\n",
      "Epoch: 1432/5000... Step: 87330... Loss: 0.0362... Val Loss: 0.0562\n",
      "Epoch: 1432/5000... Step: 87340... Loss: 0.0364... Val Loss: 0.0564\n",
      "Epoch: 1432/5000... Step: 87350... Loss: 0.0363... Val Loss: 0.0565\n",
      "Epoch: 1433/5000... Step: 87360... Loss: 0.0363... Val Loss: 0.0560\n",
      "Epoch: 1433/5000... Step: 87370... Loss: 0.0364... Val Loss: 0.0561\n",
      "Epoch: 1433/5000... Step: 87380... Loss: 0.0366... Val Loss: 0.0560\n",
      "Epoch: 1433/5000... Step: 87390... Loss: 0.0364... Val Loss: 0.0561\n",
      "Epoch: 1433/5000... Step: 87400... Loss: 0.0361... Val Loss: 0.0565\n",
      "Epoch: 1433/5000... Step: 87410... Loss: 0.0366... Val Loss: 0.0560\n",
      "Epoch: 1434/5000... Step: 87420... Loss: 0.0362... Val Loss: 0.0560\n",
      "Epoch: 1434/5000... Step: 87430... Loss: 0.0363... Val Loss: 0.0561\n",
      "Epoch: 1434/5000... Step: 87440... Loss: 0.0362... Val Loss: 0.0560\n",
      "Epoch: 1434/5000... Step: 87450... Loss: 0.0361... Val Loss: 0.0561\n",
      "Epoch: 1434/5000... Step: 87460... Loss: 0.0362... Val Loss: 0.0565\n",
      "Epoch: 1434/5000... Step: 87470... Loss: 0.0361... Val Loss: 0.0560\n",
      "Epoch: 1435/5000... Step: 87480... Loss: 0.0364... Val Loss: 0.0560\n",
      "Epoch: 1435/5000... Step: 87490... Loss: 0.0362... Val Loss: 0.0563\n",
      "Epoch: 1435/5000... Step: 87500... Loss: 0.0359... Val Loss: 0.0563\n",
      "Epoch: 1435/5000... Step: 87510... Loss: 0.0361... Val Loss: 0.0563\n",
      "Epoch: 1435/5000... Step: 87520... Loss: 0.0362... Val Loss: 0.0566\n",
      "Epoch: 1435/5000... Step: 87530... Loss: 0.0364... Val Loss: 0.0559\n",
      "Epoch: 1436/5000... Step: 87540... Loss: 0.0365... Val Loss: 0.0563\n",
      "Epoch: 1436/5000... Step: 87550... Loss: 0.0359... Val Loss: 0.0563\n",
      "Epoch: 1436/5000... Step: 87560... Loss: 0.0362... Val Loss: 0.0565\n",
      "Epoch: 1436/5000... Step: 87570... Loss: 0.0360... Val Loss: 0.0564\n",
      "Epoch: 1436/5000... Step: 87580... Loss: 0.0363... Val Loss: 0.0562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1436/5000... Step: 87590... Loss: 0.0358... Val Loss: 0.0563\n",
      "Epoch: 1437/5000... Step: 87600... Loss: 0.0364... Val Loss: 0.0565\n",
      "Epoch: 1437/5000... Step: 87610... Loss: 0.0356... Val Loss: 0.0564\n",
      "Epoch: 1437/5000... Step: 87620... Loss: 0.0358... Val Loss: 0.0564\n",
      "Epoch: 1437/5000... Step: 87630... Loss: 0.0362... Val Loss: 0.0561\n",
      "Epoch: 1437/5000... Step: 87640... Loss: 0.0357... Val Loss: 0.0562\n",
      "Epoch: 1437/5000... Step: 87650... Loss: 0.0361... Val Loss: 0.0563\n",
      "Epoch: 1438/5000... Step: 87660... Loss: 0.0366... Val Loss: 0.0565\n",
      "Epoch: 1438/5000... Step: 87670... Loss: 0.0358... Val Loss: 0.0564\n",
      "Epoch: 1438/5000... Step: 87680... Loss: 0.0360... Val Loss: 0.0561\n",
      "Epoch: 1438/5000... Step: 87690... Loss: 0.0360... Val Loss: 0.0561\n",
      "Epoch: 1438/5000... Step: 87700... Loss: 0.0357... Val Loss: 0.0563\n",
      "Epoch: 1438/5000... Step: 87710... Loss: 0.0361... Val Loss: 0.0561\n",
      "Epoch: 1439/5000... Step: 87720... Loss: 0.0360... Val Loss: 0.0564\n",
      "Epoch: 1439/5000... Step: 87730... Loss: 0.0359... Val Loss: 0.0565\n",
      "Epoch: 1439/5000... Step: 87740... Loss: 0.0358... Val Loss: 0.0561\n",
      "Epoch: 1439/5000... Step: 87750... Loss: 0.0357... Val Loss: 0.0562\n",
      "Epoch: 1439/5000... Step: 87760... Loss: 0.0360... Val Loss: 0.0564\n",
      "Epoch: 1439/5000... Step: 87770... Loss: 0.0361... Val Loss: 0.0566\n",
      "Epoch: 1440/5000... Step: 87780... Loss: 0.0354... Val Loss: 0.0565\n",
      "Epoch: 1440/5000... Step: 87790... Loss: 0.0358... Val Loss: 0.0562\n",
      "Epoch: 1440/5000... Step: 87800... Loss: 0.0356... Val Loss: 0.0561\n",
      "Epoch: 1440/5000... Step: 87810... Loss: 0.0358... Val Loss: 0.0564\n",
      "Epoch: 1440/5000... Step: 87820... Loss: 0.0353... Val Loss: 0.0566\n",
      "Epoch: 1440/5000... Step: 87830... Loss: 0.0357... Val Loss: 0.0567\n",
      "Epoch: 1440/5000... Step: 87840... Loss: 0.0357... Val Loss: 0.0565\n",
      "Epoch: 1441/5000... Step: 87850... Loss: 0.0359... Val Loss: 0.0563\n",
      "Epoch: 1441/5000... Step: 87860... Loss: 0.0358... Val Loss: 0.0562\n",
      "Epoch: 1441/5000... Step: 87870... Loss: 0.0358... Val Loss: 0.0563\n",
      "Epoch: 1441/5000... Step: 87880... Loss: 0.0358... Val Loss: 0.0568\n",
      "Epoch: 1441/5000... Step: 87890... Loss: 0.0355... Val Loss: 0.0565\n",
      "Epoch: 1441/5000... Step: 87900... Loss: 0.0356... Val Loss: 0.0561\n",
      "Epoch: 1442/5000... Step: 87910... Loss: 0.0359... Val Loss: 0.0563\n",
      "Epoch: 1442/5000... Step: 87920... Loss: 0.0359... Val Loss: 0.0566\n",
      "Epoch: 1442/5000... Step: 87930... Loss: 0.0359... Val Loss: 0.0565\n",
      "Epoch: 1442/5000... Step: 87940... Loss: 0.0354... Val Loss: 0.0563\n",
      "Epoch: 1442/5000... Step: 87950... Loss: 0.0356... Val Loss: 0.0566\n",
      "Epoch: 1442/5000... Step: 87960... Loss: 0.0357... Val Loss: 0.0565\n",
      "Epoch: 1443/5000... Step: 87970... Loss: 0.0355... Val Loss: 0.0564\n",
      "Epoch: 1443/5000... Step: 87980... Loss: 0.0354... Val Loss: 0.0566\n",
      "Epoch: 1443/5000... Step: 87990... Loss: 0.0357... Val Loss: 0.0566\n",
      "Epoch: 1443/5000... Step: 88000... Loss: 0.0353... Val Loss: 0.0566\n",
      "Epoch: 1443/5000... Step: 88010... Loss: 0.0355... Val Loss: 0.0567\n",
      "Epoch: 1443/5000... Step: 88020... Loss: 0.0354... Val Loss: 0.0565\n",
      "Epoch: 1444/5000... Step: 88030... Loss: 0.0355... Val Loss: 0.0564\n",
      "Epoch: 1444/5000... Step: 88040... Loss: 0.0354... Val Loss: 0.0570\n",
      "Epoch: 1444/5000... Step: 88050... Loss: 0.0352... Val Loss: 0.0566\n",
      "Epoch: 1444/5000... Step: 88060... Loss: 0.0352... Val Loss: 0.0566\n",
      "Epoch: 1444/5000... Step: 88070... Loss: 0.0354... Val Loss: 0.0568\n",
      "Epoch: 1444/5000... Step: 88080... Loss: 0.0356... Val Loss: 0.0566\n",
      "Epoch: 1445/5000... Step: 88090... Loss: 0.0356... Val Loss: 0.0565\n",
      "Epoch: 1445/5000... Step: 88100... Loss: 0.0351... Val Loss: 0.0567\n",
      "Epoch: 1445/5000... Step: 88110... Loss: 0.0352... Val Loss: 0.0566\n",
      "Epoch: 1445/5000... Step: 88120... Loss: 0.0354... Val Loss: 0.0563\n",
      "Epoch: 1445/5000... Step: 88130... Loss: 0.0355... Val Loss: 0.0569\n",
      "Epoch: 1445/5000... Step: 88140... Loss: 0.0353... Val Loss: 0.0565\n",
      "Epoch: 1446/5000... Step: 88150... Loss: 0.0355... Val Loss: 0.0569\n",
      "Epoch: 1446/5000... Step: 88160... Loss: 0.0351... Val Loss: 0.0571\n",
      "Epoch: 1446/5000... Step: 88170... Loss: 0.0353... Val Loss: 0.0562\n",
      "Epoch: 1446/5000... Step: 88180... Loss: 0.0354... Val Loss: 0.0562\n",
      "Epoch: 1446/5000... Step: 88190... Loss: 0.0354... Val Loss: 0.0570\n",
      "Epoch: 1446/5000... Step: 88200... Loss: 0.0354... Val Loss: 0.0564\n",
      "Epoch: 1447/5000... Step: 88210... Loss: 0.0359... Val Loss: 0.0570\n",
      "Epoch: 1447/5000... Step: 88220... Loss: 0.0350... Val Loss: 0.0565\n",
      "Epoch: 1447/5000... Step: 88230... Loss: 0.0351... Val Loss: 0.0563\n",
      "Epoch: 1447/5000... Step: 88240... Loss: 0.0353... Val Loss: 0.0567\n",
      "Epoch: 1447/5000... Step: 88250... Loss: 0.0350... Val Loss: 0.0567\n",
      "Epoch: 1447/5000... Step: 88260... Loss: 0.0354... Val Loss: 0.0564\n",
      "Epoch: 1448/5000... Step: 88270... Loss: 0.0358... Val Loss: 0.0572\n",
      "Epoch: 1448/5000... Step: 88280... Loss: 0.0352... Val Loss: 0.0561\n",
      "Epoch: 1448/5000... Step: 88290... Loss: 0.0349... Val Loss: 0.0564\n",
      "Epoch: 1448/5000... Step: 88300... Loss: 0.0352... Val Loss: 0.0569\n",
      "Epoch: 1448/5000... Step: 88310... Loss: 0.0348... Val Loss: 0.0569\n",
      "Epoch: 1448/5000... Step: 88320... Loss: 0.0355... Val Loss: 0.0568\n",
      "Epoch: 1449/5000... Step: 88330... Loss: 0.0353... Val Loss: 0.0572\n",
      "Epoch: 1449/5000... Step: 88340... Loss: 0.0350... Val Loss: 0.0563\n",
      "Epoch: 1449/5000... Step: 88350... Loss: 0.0350... Val Loss: 0.0569\n",
      "Epoch: 1449/5000... Step: 88360... Loss: 0.0349... Val Loss: 0.0566\n",
      "Epoch: 1449/5000... Step: 88370... Loss: 0.0351... Val Loss: 0.0568\n",
      "Epoch: 1449/5000... Step: 88380... Loss: 0.0352... Val Loss: 0.0568\n",
      "Epoch: 1450/5000... Step: 88390... Loss: 0.0347... Val Loss: 0.0569\n",
      "Epoch: 1450/5000... Step: 88400... Loss: 0.0352... Val Loss: 0.0566\n",
      "Epoch: 1450/5000... Step: 88410... Loss: 0.0350... Val Loss: 0.0569\n",
      "Epoch: 1450/5000... Step: 88420... Loss: 0.0348... Val Loss: 0.0569\n",
      "Epoch: 1450/5000... Step: 88430... Loss: 0.0347... Val Loss: 0.0568\n",
      "Epoch: 1450/5000... Step: 88440... Loss: 0.0349... Val Loss: 0.0570\n",
      "Epoch: 1450/5000... Step: 88450... Loss: 0.0349... Val Loss: 0.0570\n",
      "Epoch: 1451/5000... Step: 88460... Loss: 0.0350... Val Loss: 0.0566\n",
      "Epoch: 1451/5000... Step: 88470... Loss: 0.0348... Val Loss: 0.0568\n",
      "Epoch: 1451/5000... Step: 88480... Loss: 0.0348... Val Loss: 0.0571\n",
      "Epoch: 1451/5000... Step: 88490... Loss: 0.0349... Val Loss: 0.0567\n",
      "Epoch: 1451/5000... Step: 88500... Loss: 0.0347... Val Loss: 0.0569\n",
      "Epoch: 1451/5000... Step: 88510... Loss: 0.0346... Val Loss: 0.0572\n",
      "Epoch: 1452/5000... Step: 88520... Loss: 0.0349... Val Loss: 0.0568\n",
      "Epoch: 1452/5000... Step: 88530... Loss: 0.0349... Val Loss: 0.0571\n",
      "Epoch: 1452/5000... Step: 88540... Loss: 0.0347... Val Loss: 0.0570\n",
      "Epoch: 1452/5000... Step: 88550... Loss: 0.0347... Val Loss: 0.0562\n",
      "Epoch: 1452/5000... Step: 88560... Loss: 0.0349... Val Loss: 0.0573\n",
      "Epoch: 1452/5000... Step: 88570... Loss: 0.0347... Val Loss: 0.0566\n",
      "Epoch: 1453/5000... Step: 88580... Loss: 0.0348... Val Loss: 0.0571\n",
      "Epoch: 1453/5000... Step: 88590... Loss: 0.0347... Val Loss: 0.0572\n",
      "Epoch: 1453/5000... Step: 88600... Loss: 0.0348... Val Loss: 0.0566\n",
      "Epoch: 1453/5000... Step: 88610... Loss: 0.0346... Val Loss: 0.0568\n",
      "Epoch: 1453/5000... Step: 88620... Loss: 0.0345... Val Loss: 0.0575\n",
      "Epoch: 1453/5000... Step: 88630... Loss: 0.0344... Val Loss: 0.0568\n",
      "Epoch: 1454/5000... Step: 88640... Loss: 0.0345... Val Loss: 0.0570\n",
      "Epoch: 1454/5000... Step: 88650... Loss: 0.0346... Val Loss: 0.0569\n",
      "Epoch: 1454/5000... Step: 88660... Loss: 0.0344... Val Loss: 0.0569\n",
      "Epoch: 1454/5000... Step: 88670... Loss: 0.0345... Val Loss: 0.0571\n",
      "Epoch: 1454/5000... Step: 88680... Loss: 0.0342... Val Loss: 0.0571\n",
      "Epoch: 1454/5000... Step: 88690... Loss: 0.0343... Val Loss: 0.0564\n",
      "Epoch: 1455/5000... Step: 88700... Loss: 0.0349... Val Loss: 0.0569\n",
      "Epoch: 1455/5000... Step: 88710... Loss: 0.0343... Val Loss: 0.0572\n",
      "Epoch: 1455/5000... Step: 88720... Loss: 0.0341... Val Loss: 0.0565\n",
      "Epoch: 1455/5000... Step: 88730... Loss: 0.0346... Val Loss: 0.0568\n",
      "Epoch: 1455/5000... Step: 88740... Loss: 0.0344... Val Loss: 0.0569\n",
      "Epoch: 1455/5000... Step: 88750... Loss: 0.0345... Val Loss: 0.0568\n",
      "Epoch: 1456/5000... Step: 88760... Loss: 0.0342... Val Loss: 0.0571\n",
      "Epoch: 1456/5000... Step: 88770... Loss: 0.0341... Val Loss: 0.0567\n",
      "Epoch: 1456/5000... Step: 88780... Loss: 0.0342... Val Loss: 0.0567\n",
      "Epoch: 1456/5000... Step: 88790... Loss: 0.0343... Val Loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1456/5000... Step: 88800... Loss: 0.0343... Val Loss: 0.0569\n",
      "Epoch: 1456/5000... Step: 88810... Loss: 0.0340... Val Loss: 0.0568\n",
      "Epoch: 1457/5000... Step: 88820... Loss: 0.0348... Val Loss: 0.0573\n",
      "Epoch: 1457/5000... Step: 88830... Loss: 0.0342... Val Loss: 0.0567\n",
      "Epoch: 1457/5000... Step: 88840... Loss: 0.0342... Val Loss: 0.0570\n",
      "Epoch: 1457/5000... Step: 88850... Loss: 0.0342... Val Loss: 0.0571\n",
      "Epoch: 1457/5000... Step: 88860... Loss: 0.0338... Val Loss: 0.0568\n",
      "Epoch: 1457/5000... Step: 88870... Loss: 0.0341... Val Loss: 0.0570\n",
      "Epoch: 1458/5000... Step: 88880... Loss: 0.0344... Val Loss: 0.0574\n",
      "Epoch: 1458/5000... Step: 88890... Loss: 0.0341... Val Loss: 0.0567\n",
      "Epoch: 1458/5000... Step: 88900... Loss: 0.0341... Val Loss: 0.0567\n",
      "Epoch: 1458/5000... Step: 88910... Loss: 0.0340... Val Loss: 0.0570\n",
      "Epoch: 1458/5000... Step: 88920... Loss: 0.0339... Val Loss: 0.0569\n",
      "Epoch: 1458/5000... Step: 88930... Loss: 0.0343... Val Loss: 0.0571\n",
      "Epoch: 1459/5000... Step: 88940... Loss: 0.0342... Val Loss: 0.0576\n",
      "Epoch: 1459/5000... Step: 88950... Loss: 0.0339... Val Loss: 0.0566\n",
      "Epoch: 1459/5000... Step: 88960... Loss: 0.0341... Val Loss: 0.0571\n",
      "Epoch: 1459/5000... Step: 88970... Loss: 0.0341... Val Loss: 0.0570\n",
      "Epoch: 1459/5000... Step: 88980... Loss: 0.0342... Val Loss: 0.0567\n",
      "Epoch: 1459/5000... Step: 88990... Loss: 0.0341... Val Loss: 0.0573\n",
      "Epoch: 1460/5000... Step: 89000... Loss: 0.0334... Val Loss: 0.0568\n",
      "Epoch: 1460/5000... Step: 89010... Loss: 0.0340... Val Loss: 0.0566\n",
      "Epoch: 1460/5000... Step: 89020... Loss: 0.0338... Val Loss: 0.0571\n",
      "Epoch: 1460/5000... Step: 89030... Loss: 0.0336... Val Loss: 0.0570\n",
      "Epoch: 1460/5000... Step: 89040... Loss: 0.0334... Val Loss: 0.0569\n",
      "Epoch: 1460/5000... Step: 89050... Loss: 0.0338... Val Loss: 0.0573\n",
      "Epoch: 1460/5000... Step: 89060... Loss: 0.0342... Val Loss: 0.0569\n",
      "Epoch: 1461/5000... Step: 89070... Loss: 0.0340... Val Loss: 0.0568\n",
      "Epoch: 1461/5000... Step: 89080... Loss: 0.0339... Val Loss: 0.0571\n",
      "Epoch: 1461/5000... Step: 89090... Loss: 0.0337... Val Loss: 0.0571\n",
      "Epoch: 1461/5000... Step: 89100... Loss: 0.0340... Val Loss: 0.0570\n",
      "Epoch: 1461/5000... Step: 89110... Loss: 0.0335... Val Loss: 0.0570\n",
      "Epoch: 1461/5000... Step: 89120... Loss: 0.0336... Val Loss: 0.0568\n",
      "Epoch: 1462/5000... Step: 89130... Loss: 0.0340... Val Loss: 0.0571\n",
      "Epoch: 1462/5000... Step: 89140... Loss: 0.0337... Val Loss: 0.0570\n",
      "Epoch: 1462/5000... Step: 89150... Loss: 0.0339... Val Loss: 0.0569\n",
      "Epoch: 1462/5000... Step: 89160... Loss: 0.0338... Val Loss: 0.0570\n",
      "Epoch: 1462/5000... Step: 89170... Loss: 0.0337... Val Loss: 0.0573\n",
      "Epoch: 1462/5000... Step: 89180... Loss: 0.0337... Val Loss: 0.0570\n",
      "Epoch: 1463/5000... Step: 89190... Loss: 0.0338... Val Loss: 0.0571\n",
      "Epoch: 1463/5000... Step: 89200... Loss: 0.0336... Val Loss: 0.0571\n",
      "Epoch: 1463/5000... Step: 89210... Loss: 0.0335... Val Loss: 0.0570\n",
      "Epoch: 1463/5000... Step: 89220... Loss: 0.0335... Val Loss: 0.0570\n",
      "Epoch: 1463/5000... Step: 89230... Loss: 0.0335... Val Loss: 0.0573\n",
      "Epoch: 1463/5000... Step: 89240... Loss: 0.0336... Val Loss: 0.0567\n",
      "Epoch: 1464/5000... Step: 89250... Loss: 0.0337... Val Loss: 0.0571\n",
      "Epoch: 1464/5000... Step: 89260... Loss: 0.0335... Val Loss: 0.0568\n",
      "Epoch: 1464/5000... Step: 89270... Loss: 0.0336... Val Loss: 0.0570\n",
      "Epoch: 1464/5000... Step: 89280... Loss: 0.0333... Val Loss: 0.0572\n",
      "Epoch: 1464/5000... Step: 89290... Loss: 0.0336... Val Loss: 0.0572\n",
      "Epoch: 1464/5000... Step: 89300... Loss: 0.0335... Val Loss: 0.0572\n",
      "Epoch: 1465/5000... Step: 89310... Loss: 0.0340... Val Loss: 0.0574\n",
      "Epoch: 1465/5000... Step: 89320... Loss: 0.0332... Val Loss: 0.0570\n",
      "Epoch: 1465/5000... Step: 89330... Loss: 0.0333... Val Loss: 0.0570\n",
      "Epoch: 1465/5000... Step: 89340... Loss: 0.0336... Val Loss: 0.0571\n",
      "Epoch: 1465/5000... Step: 89350... Loss: 0.0333... Val Loss: 0.0572\n",
      "Epoch: 1465/5000... Step: 89360... Loss: 0.0336... Val Loss: 0.0570\n",
      "Epoch: 1466/5000... Step: 89370... Loss: 0.0333... Val Loss: 0.0576\n",
      "Epoch: 1466/5000... Step: 89380... Loss: 0.0335... Val Loss: 0.0567\n",
      "Epoch: 1466/5000... Step: 89390... Loss: 0.0333... Val Loss: 0.0573\n",
      "Epoch: 1466/5000... Step: 89400... Loss: 0.0332... Val Loss: 0.0571\n",
      "Epoch: 1466/5000... Step: 89410... Loss: 0.0335... Val Loss: 0.0571\n",
      "Epoch: 1466/5000... Step: 89420... Loss: 0.0333... Val Loss: 0.0573\n",
      "Epoch: 1467/5000... Step: 89430... Loss: 0.0341... Val Loss: 0.0576\n",
      "Epoch: 1467/5000... Step: 89440... Loss: 0.0331... Val Loss: 0.0568\n",
      "Epoch: 1467/5000... Step: 89450... Loss: 0.0332... Val Loss: 0.0573\n",
      "Epoch: 1467/5000... Step: 89460... Loss: 0.0335... Val Loss: 0.0574\n",
      "Epoch: 1467/5000... Step: 89470... Loss: 0.0332... Val Loss: 0.0571\n",
      "Epoch: 1467/5000... Step: 89480... Loss: 0.0334... Val Loss: 0.0574\n",
      "Epoch: 1468/5000... Step: 89490... Loss: 0.0340... Val Loss: 0.0573\n",
      "Epoch: 1468/5000... Step: 89500... Loss: 0.0334... Val Loss: 0.0570\n",
      "Epoch: 1468/5000... Step: 89510... Loss: 0.0334... Val Loss: 0.0575\n",
      "Epoch: 1468/5000... Step: 89520... Loss: 0.0332... Val Loss: 0.0573\n",
      "Epoch: 1468/5000... Step: 89530... Loss: 0.0331... Val Loss: 0.0572\n",
      "Epoch: 1468/5000... Step: 89540... Loss: 0.0335... Val Loss: 0.0575\n",
      "Epoch: 1469/5000... Step: 89550... Loss: 0.0334... Val Loss: 0.0575\n",
      "Epoch: 1469/5000... Step: 89560... Loss: 0.0332... Val Loss: 0.0571\n",
      "Epoch: 1469/5000... Step: 89570... Loss: 0.0333... Val Loss: 0.0575\n",
      "Epoch: 1469/5000... Step: 89580... Loss: 0.0333... Val Loss: 0.0574\n",
      "Epoch: 1469/5000... Step: 89590... Loss: 0.0333... Val Loss: 0.0570\n",
      "Epoch: 1469/5000... Step: 89600... Loss: 0.0335... Val Loss: 0.0574\n",
      "Epoch: 1470/5000... Step: 89610... Loss: 0.0325... Val Loss: 0.0573\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_length = 160 #max length verses\n",
    "n_epochs = 5000 # start smaller if you are just testing initial behavior\n",
    "\n",
    "# train the model\n",
    "train(net, encoded, epochs=n_epochs, batch_size=batch_size, seq_length=seq_length, lr=0.001, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbSGCJO4ewpi"
   },
   "outputs": [],
   "source": [
    "model_dante = 'rnn_20_epoch.net'\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "with open(model_dante, 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65NVMnmmewpm"
   },
   "outputs": [],
   "source": [
    "def predict(net, char, h=None, top_k=None):\n",
    "        ''' Given a character, predict the next character.\n",
    "            Returns the predicted character and the hidden state.\n",
    "        '''\n",
    "        \n",
    "        # tensor inputs\n",
    "        x = np.array([[net.char2int[char]]])\n",
    "        x = one_hot_encoder(x, len(net.chars))\n",
    "        inputs = torch.from_numpy(x)\n",
    "        \n",
    "        if(train_on_gpu):\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # detach hidden state from history\n",
    "        h = tuple([each.data for each in h])\n",
    "        # get the output of the model\n",
    "        out, h = net(inputs, h)\n",
    "\n",
    "        # get the character probabilities\n",
    "        # apply softmax to get p probabilities for the likely next character giving x\n",
    "        p = F.softmax(out, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "        \n",
    "        # get top characters\n",
    "        # considering the k most probable characters with topk method\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(net.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next character with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        # return the encoded value of the predicted char and the hidden state\n",
    "        return net.int2char[char], h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cQz9pJnewps"
   },
   "outputs": [],
   "source": [
    "def sample(net, size, prime='Il', top_k=None):\n",
    "        \n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.cpu()\n",
    "    \n",
    "    net.eval() # eval mode\n",
    "    \n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = net.init_hidden(1)\n",
    "    for ch in prime:\n",
    "        char, h = predict(net, ch, h, top_k=top_k)\n",
    "\n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = predict(net, chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "ko1gyKMIewpv",
    "outputId": "2c1356c1-fde5-4932-f3b3-128f73459aaa"
   },
   "outputs": [],
   "source": [
    "print(sample(net, 1000, prime='This ', top_k=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sH5K12reewpy",
    "outputId": "98ba7d8e-f290-407b-86eb-490264eb4cbb"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23n3y1TOewp1",
    "outputId": "5dbde076-cb3b-4593-c3a4-c2e52c22f279"
   },
   "outputs": [],
   "source": [
    "x, y = next(batches)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7MjK0kEewp5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Char-LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
